{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we train an MLP to classify images from the MNIST database.\n",
    "\n",
    "### 1. Load MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MNIST database has a training set of 60000 examples.\n",
      "The MNIST database has a test set of 10000 examples.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
    "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize the First Six Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e85e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# plot first six training images\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. View an Image in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1052c39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_input(img, ax):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    n_rows, n_cols = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    height_range = [4]\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            str_x_y = str(round(img[r][c],2))\n",
    "            ax.annotate(str_x_y, xy=(c,r),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[r][c]<thresh else 'black')\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "visualize_input(X_train[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rescale the Images by Dividing Every Pixel in Every Image by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Encode Categorical Integer Labels Using a One-Hot Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer-valued labels:\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "One-hot labels:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# print first ten (integer-valued) training labels\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print first ten (one-hot) training labels\n",
    "print('One-hot labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(activation = 'relu', dropout = 0.2, \n",
    "                 neurons = 512, optimizer = 'rmsprop'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=X_train.shape[1:], name = 'flatten1'))\n",
    "    model.add(Dense(neurons, activation=activation, name = 'dense1'))\n",
    "    model.add(Dropout(dropout, name = 'dropout1'))\n",
    "    model.add(Dense(neurons, activation=activation, name = 'activation1'))\n",
    "    model.add(Dropout(dropout, name = 'dropout2'))\n",
    "    model.add(Dense(10, activation='softmax', name = 'activation2'))\n",
    "\n",
    "    # summarize the model\n",
    "    #model.summary()\n",
    "\n",
    "    ### 7. Compile the Model\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense1/bias:0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model().layers[1].weights[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the Classification Accuracy on the Test Set (Before Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 13.2200%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "score = create_model().evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons          = [128, 512]\n",
    "dropout          = [0.0, 0.2, 0.5]\n",
    "activation       = ['linear', 'softmax', 'relu']\n",
    "optimizer        = ['rmsprop', 'sgd']\n",
    "batch_size       = [64,128]\n",
    "epochs           = [5]\n",
    "validation_split = [0.2]\n",
    "param_grid       = dict(neurons          = neurons, \n",
    "                        dropout          = dropout, \n",
    "                        epochs           = epochs, \n",
    "                        validation_split = validation_split,\n",
    "                        activation       = activation,\n",
    "                        optimizer        = optimizer, \n",
    "                        batch_size       = batch_size)\n",
    "grid             = GridSearchCV(estimator  = model, \n",
    "                                param_grid = param_grid,\n",
    "                                n_jobs     = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.4212 - acc: 0.8773 - val_loss: 0.3097 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30969, saving model to mnist.model.best.hdf5\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.3342 - acc: 0.9043 - val_loss: 0.2933 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30969 to 0.29332, saving model to mnist.model.best.hdf5\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3180 - acc: 0.9106 - val_loss: 0.3019 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3066 - acc: 0.9133 - val_loss: 0.2770 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29332 to 0.27695, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3007 - acc: 0.9130 - val_loss: 0.2805 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 29us/step\n",
      "40000/40000 [==============================] - 1s 29us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.4141 - acc: 0.8798 - val_loss: 0.2943 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3253 - acc: 0.9072 - val_loss: 0.3094 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3110 - acc: 0.9133 - val_loss: 0.3135 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3007 - acc: 0.9150 - val_loss: 0.2780 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2925 - acc: 0.9189 - val_loss: 0.2905 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 29us/step\n",
      "40000/40000 [==============================] - 1s 29us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.4111 - acc: 0.8808 - val_loss: 0.3453 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.3240 - acc: 0.9090 - val_loss: 0.3403 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3074 - acc: 0.9132 - val_loss: 0.3203 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3002 - acc: 0.9168 - val_loss: 0.3686 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2926 - acc: 0.9189 - val_loss: 0.3256 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 38us/step\n",
      "40000/40000 [==============================] - 1s 30us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.8256 - acc: 0.7789 - val_loss: 0.4344 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4339 - acc: 0.8807 - val_loss: 0.3502 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3783 - acc: 0.8936 - val_loss: 0.3248 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3528 - acc: 0.8997 - val_loss: 0.3081 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3378 - acc: 0.9042 - val_loss: 0.3012 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 29us/step\n",
      "40000/40000 [==============================] - 1s 29us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.8173 - acc: 0.7846 - val_loss: 0.4358 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4313 - acc: 0.8792 - val_loss: 0.3508 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3740 - acc: 0.8938 - val_loss: 0.3237 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3471 - acc: 0.9015 - val_loss: 0.3054 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3309 - acc: 0.9057 - val_loss: 0.2981 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 33us/step\n",
      "40000/40000 [==============================] - 1s 30us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.8105 - acc: 0.7916 - val_loss: 0.4903 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4281 - acc: 0.8825 - val_loss: 0.4024 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3733 - acc: 0.8943 - val_loss: 0.3694 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3478 - acc: 0.9008 - val_loss: 0.3556 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3316 - acc: 0.9064 - val_loss: 0.3438 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 53us/step\n",
      "40000/40000 [==============================] - 2s 39us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.4968 - acc: 0.8543 - val_loss: 0.3261 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.3900 - acc: 0.8905 - val_loss: 0.3236 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.3573 - acc: 0.8964 - val_loss: 0.3017 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.3396 - acc: 0.9017 - val_loss: 0.3115 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3278 - acc: 0.9060 - val_loss: 0.3086 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 74us/step\n",
      "40000/40000 [==============================] - 3s 81us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.4919 - acc: 0.8575 - val_loss: 0.3416 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.3789 - acc: 0.8927 - val_loss: 0.3070 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.3500 - acc: 0.9008 - val_loss: 0.3359 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 0.3307 - acc: 0.9068 - val_loss: 0.3022 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.3204 - acc: 0.9100 - val_loss: 0.3182 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 116us/step\n",
      "40000/40000 [==============================] - 4s 90us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.4908 - acc: 0.8597 - val_loss: 0.5064 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.3803 - acc: 0.8933 - val_loss: 0.4078 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.3506 - acc: 0.9008 - val_loss: 0.3526 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.3317 - acc: 0.9069 - val_loss: 0.3369 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3203 - acc: 0.9092 - val_loss: 0.3367 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 85us/step\n",
      "40000/40000 [==============================] - 3s 74us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.7169 - acc: 0.8153 - val_loss: 0.3887 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4026 - acc: 0.8884 - val_loss: 0.3268 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.3589 - acc: 0.8989 - val_loss: 0.3056 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.3383 - acc: 0.9046 - val_loss: 0.2974 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3253 - acc: 0.9082 - val_loss: 0.2876 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 70us/step\n",
      "40000/40000 [==============================] - 3s 79us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.7106 - acc: 0.8204 - val_loss: 0.3914 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.3991 - acc: 0.8892 - val_loss: 0.3312 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.3541 - acc: 0.9008 - val_loss: 0.3082 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.3322 - acc: 0.9062 - val_loss: 0.2966 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3186 - acc: 0.9102 - val_loss: 0.2892 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "40000/40000 [==============================] - 3s 76us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.7012 - acc: 0.8258 - val_loss: 0.4461 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.3996 - acc: 0.8899 - val_loss: 0.3788 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.3553 - acc: 0.9008 - val_loss: 0.3537 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3331 - acc: 0.9073 - val_loss: 0.3406 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3191 - acc: 0.9110 - val_loss: 0.3325 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 86us/step\n",
      "40000/40000 [==============================] - 3s 71us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4708 - acc: 0.8595 - val_loss: 0.3027 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3772 - acc: 0.8900 - val_loss: 0.2801 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3570 - acc: 0.8963 - val_loss: 0.2950 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3420 - acc: 0.9030 - val_loss: 0.2743 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27695 to 0.27431, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3390 - acc: 0.9048 - val_loss: 0.2706 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27431 to 0.27059, saving model to mnist.model.best.hdf5\n",
      "20000/20000 [==============================] - 1s 37us/step\n",
      "40000/40000 [==============================] - 1s 34us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4679 - acc: 0.8616 - val_loss: 0.2923 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3621 - acc: 0.8967 - val_loss: 0.2886 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3489 - acc: 0.9015 - val_loss: 0.3008 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3383 - acc: 0.9040 - val_loss: 0.2697 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27059 to 0.26966, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3280 - acc: 0.9089 - val_loss: 0.2767 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 41us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4714 - acc: 0.8625 - val_loss: 0.3540 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3687 - acc: 0.8941 - val_loss: 0.3273 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3447 - acc: 0.9028 - val_loss: 0.3296 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3337 - acc: 0.9065 - val_loss: 0.3347 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3292 - acc: 0.9091 - val_loss: 0.3390 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 36us/step\n",
      "40000/40000 [==============================] - 1s 36us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.9142 - acc: 0.7320 - val_loss: 0.4388 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.4944 - acc: 0.8558 - val_loss: 0.3532 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4308 - acc: 0.8729 - val_loss: 0.3246 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.4028 - acc: 0.8809 - val_loss: 0.3093 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3897 - acc: 0.8842 - val_loss: 0.3006 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 36us/step\n",
      "40000/40000 [==============================] - 1s 37us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.9191 - acc: 0.7363 - val_loss: 0.4444 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.4905 - acc: 0.8556 - val_loss: 0.3528 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4245 - acc: 0.8755 - val_loss: 0.3249 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3955 - acc: 0.8850 - val_loss: 0.3084 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3801 - acc: 0.8904 - val_loss: 0.2992 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 48us/step\n",
      "40000/40000 [==============================] - 2s 38us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.8718 - acc: 0.7455 - val_loss: 0.4833 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.4803 - acc: 0.8609 - val_loss: 0.3984 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4219 - acc: 0.8767 - val_loss: 0.3668 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3983 - acc: 0.8849 - val_loss: 0.3521 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.3787 - acc: 0.8890 - val_loss: 0.3428 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 36us/step\n",
      "40000/40000 [==============================] - 2s 41us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.5165 - acc: 0.8503 - val_loss: 0.3921 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.4261 - acc: 0.8811 - val_loss: 0.3402 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.3934 - acc: 0.8890 - val_loss: 0.3099 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 0.3786 - acc: 0.8929 - val_loss: 0.2943 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3640 - acc: 0.8979 - val_loss: 0.3067 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "40000/40000 [==============================] - 3s 75us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.5043 - acc: 0.8563 - val_loss: 0.3433 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.4150 - acc: 0.8841 - val_loss: 0.3388 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.3849 - acc: 0.8908 - val_loss: 0.3343 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 0.3662 - acc: 0.8987 - val_loss: 0.3423 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3584 - acc: 0.8994 - val_loss: 0.3086 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 93us/step\n",
      "40000/40000 [==============================] - 3s 86us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.5049 - acc: 0.8565 - val_loss: 0.4132 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.4136 - acc: 0.8863 - val_loss: 0.4089 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.3827 - acc: 0.8942 - val_loss: 0.3677 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.3650 - acc: 0.8994 - val_loss: 0.4008 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3551 - acc: 0.9012 - val_loss: 0.3694 - val_acc: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 77us/step\n",
      "40000/40000 [==============================] - 4s 93us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.7537 - acc: 0.7925 - val_loss: 0.3924 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4328 - acc: 0.8772 - val_loss: 0.3306 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.3849 - acc: 0.8889 - val_loss: 0.3083 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3621 - acc: 0.8957 - val_loss: 0.2960 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3484 - acc: 0.9003 - val_loss: 0.2896 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 76us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.7527 - acc: 0.7905 - val_loss: 0.3890 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.4234 - acc: 0.8776 - val_loss: 0.3303 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.3788 - acc: 0.8911 - val_loss: 0.3109 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3560 - acc: 0.8976 - val_loss: 0.2981 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3423 - acc: 0.9015 - val_loss: 0.2896 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 75us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.7549 - acc: 0.7903 - val_loss: 0.4484 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.4307 - acc: 0.8760 - val_loss: 0.3809 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.3800 - acc: 0.8901 - val_loss: 0.3558 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.3589 - acc: 0.8979 - val_loss: 0.3428 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3453 - acc: 0.9008 - val_loss: 0.3346 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 72us/step\n",
      "40000/40000 [==============================] - 4s 93us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6522 - acc: 0.7994 - val_loss: 0.3094 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.4892 - acc: 0.8596 - val_loss: 0.2868 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4539 - acc: 0.8693 - val_loss: 0.2960 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.4359 - acc: 0.8747 - val_loss: 0.2858 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.4241 - acc: 0.8817 - val_loss: 0.2790 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 34us/step\n",
      "40000/40000 [==============================] - 1s 33us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6508 - acc: 0.8022 - val_loss: 0.3011 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.4844 - acc: 0.8609 - val_loss: 0.3079 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4412 - acc: 0.8732 - val_loss: 0.2873 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.4271 - acc: 0.8795 - val_loss: 0.2766 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4118 - acc: 0.8843 - val_loss: 0.2843 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 1s 35us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6469 - acc: 0.8028 - val_loss: 0.3601 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.4865 - acc: 0.8609 - val_loss: 0.3414 - val_acc: 0.9041\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4488 - acc: 0.8731 - val_loss: 0.3429 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.4294 - acc: 0.8815 - val_loss: 0.3419 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4131 - acc: 0.8846 - val_loss: 0.3400 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 42us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.1463 - acc: 0.6245 - val_loss: 0.4705 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.6663 - acc: 0.7915 - val_loss: 0.3727 - val_acc: 0.8988\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.5786 - acc: 0.8221 - val_loss: 0.3377 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.5360 - acc: 0.8387 - val_loss: 0.3243 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4998 - acc: 0.8498 - val_loss: 0.3138 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 62us/step\n",
      "40000/40000 [==============================] - 2s 39us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.0991 - acc: 0.6365 - val_loss: 0.4436 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.6378 - acc: 0.7976 - val_loss: 0.3609 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.5620 - acc: 0.8249 - val_loss: 0.3345 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.5111 - acc: 0.8459 - val_loss: 0.3215 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4979 - acc: 0.8493 - val_loss: 0.3119 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 50us/step\n",
      "40000/40000 [==============================] - 1s 37us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.0829 - acc: 0.6425 - val_loss: 0.5122 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.6463 - acc: 0.8003 - val_loss: 0.4174 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.5701 - acc: 0.8287 - val_loss: 0.3829 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.5245 - acc: 0.8422 - val_loss: 0.3679 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4944 - acc: 0.8533 - val_loss: 0.3564 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 42us/step\n",
      "40000/40000 [==============================] - 2s 41us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.5994 - acc: 0.8297 - val_loss: 0.3294 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.5008 - acc: 0.8659 - val_loss: 0.3212 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.4659 - acc: 0.8737 - val_loss: 0.3174 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.4421 - acc: 0.8795 - val_loss: 0.3366 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.4274 - acc: 0.8827 - val_loss: 0.3071 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 80us/step\n",
      "40000/40000 [==============================] - 4s 104us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.5948 - acc: 0.8336 - val_loss: 0.3289 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.4881 - acc: 0.8685 - val_loss: 0.3201 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 11s - loss: 0.4598 - acc: 0.8792 - val_loss: 0.3134 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.4350 - acc: 0.8833 - val_loss: 0.2999 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.4164 - acc: 0.8867 - val_loss: 0.3220 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 94us/step\n",
      "40000/40000 [==============================] - 4s 111us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.5880 - acc: 0.8383 - val_loss: 0.4432 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.4913 - acc: 0.8725 - val_loss: 0.3964 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.4474 - acc: 0.8798 - val_loss: 0.4009 - val_acc: 0.9005\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.4328 - acc: 0.8854 - val_loss: 0.4216 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.4129 - acc: 0.8896 - val_loss: 0.4038 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 74us/step\n",
      "40000/40000 [==============================] - 4s 90us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.8916 - acc: 0.7166 - val_loss: 0.3927 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.5184 - acc: 0.8427 - val_loss: 0.3321 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.4561 - acc: 0.8639 - val_loss: 0.3129 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4304 - acc: 0.8704 - val_loss: 0.3040 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4094 - acc: 0.8780 - val_loss: 0.2932 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 88us/step\n",
      "40000/40000 [==============================] - 3s 71us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.8697 - acc: 0.7243 - val_loss: 0.3894 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.5016 - acc: 0.8458 - val_loss: 0.3304 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.4445 - acc: 0.8657 - val_loss: 0.3111 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4236 - acc: 0.8729 - val_loss: 0.2996 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4018 - acc: 0.8813 - val_loss: 0.2950 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 73us/step\n",
      "40000/40000 [==============================] - 3s 74us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.8743 - acc: 0.7220 - val_loss: 0.4406 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.5014 - acc: 0.8472 - val_loss: 0.3782 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.4471 - acc: 0.8675 - val_loss: 0.3556 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4202 - acc: 0.8770 - val_loss: 0.3440 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4037 - acc: 0.8818 - val_loss: 0.3326 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 73us/step\n",
      "40000/40000 [==============================] - 3s 82us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4412 - acc: 0.8706 - val_loss: 0.2970 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.3293 - acc: 0.9055 - val_loss: 0.2774 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3107 - acc: 0.9103 - val_loss: 0.2779 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3007 - acc: 0.9158 - val_loss: 0.2744 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2940 - acc: 0.9158 - val_loss: 0.2676 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26966 to 0.26763, saving model to mnist.model.best.hdf5\n",
      "20000/20000 [==============================] - 0s 22us/step\n",
      "40000/40000 [==============================] - 1s 27us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4388 - acc: 0.8701 - val_loss: 0.3155 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.3186 - acc: 0.9102 - val_loss: 0.2961 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3047 - acc: 0.9147 - val_loss: 0.2824 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.2935 - acc: 0.9166 - val_loss: 0.2816 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2866 - acc: 0.9197 - val_loss: 0.2967 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 29us/step\n",
      "40000/40000 [==============================] - 1s 30us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4330 - acc: 0.8746 - val_loss: 0.3474 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.3188 - acc: 0.9097 - val_loss: 0.3289 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3033 - acc: 0.9145 - val_loss: 0.3333 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.2917 - acc: 0.9173 - val_loss: 0.3332 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2864 - acc: 0.9204 - val_loss: 0.3263 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 0s 23us/step\n",
      "40000/40000 [==============================] - 1s 22us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.1173 - acc: 0.7075 - val_loss: 0.5979 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.5584 - acc: 0.8549 - val_loss: 0.4315 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4562 - acc: 0.8742 - val_loss: 0.3759 - val_acc: 0.8982\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4118 - acc: 0.8845 - val_loss: 0.3477 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.3862 - acc: 0.8906 - val_loss: 0.3311 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 0s 22us/step\n",
      "40000/40000 [==============================] - 1s 22us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.0858 - acc: 0.7101 - val_loss: 0.5933 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.5514 - acc: 0.8551 - val_loss: 0.4329 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4513 - acc: 0.8771 - val_loss: 0.3775 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4060 - acc: 0.8872 - val_loss: 0.3483 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.3795 - acc: 0.8949 - val_loss: 0.3319 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 0s 23us/step\n",
      "40000/40000 [==============================] - 1s 22us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.1155 - acc: 0.7107 - val_loss: 0.6646 - val_acc: 0.8353\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.5534 - acc: 0.8553 - val_loss: 0.4955 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4506 - acc: 0.8764 - val_loss: 0.4334 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.4055 - acc: 0.8858 - val_loss: 0.4017 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.3790 - acc: 0.8917 - val_loss: 0.3814 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 23us/step\n",
      "40000/40000 [==============================] - 1s 21us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.4995 - acc: 0.8510 - val_loss: 0.3256 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.3856 - acc: 0.8864 - val_loss: 0.3457 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.3624 - acc: 0.8972 - val_loss: 0.3102 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.3390 - acc: 0.9027 - val_loss: 0.2843 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.3287 - acc: 0.9058 - val_loss: 0.2963 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 55us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.4858 - acc: 0.8574 - val_loss: 0.3175 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.3772 - acc: 0.8921 - val_loss: 0.3370 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.3495 - acc: 0.9014 - val_loss: 0.3301 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.3278 - acc: 0.9063 - val_loss: 0.2754 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.3159 - acc: 0.9098 - val_loss: 0.3138 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 63us/step\n",
      "40000/40000 [==============================] - 2s 55us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.4861 - acc: 0.8554 - val_loss: 0.4335 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.3758 - acc: 0.8936 - val_loss: 0.4149 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.3460 - acc: 0.9011 - val_loss: 0.3622 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.3286 - acc: 0.9059 - val_loss: 0.3428 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.3178 - acc: 0.9118 - val_loss: 0.3702 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 54us/step\n",
      "40000/40000 [==============================] - 3s 65us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.9275 - acc: 0.7738 - val_loss: 0.5080 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.4933 - acc: 0.8685 - val_loss: 0.3958 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.4204 - acc: 0.8840 - val_loss: 0.3539 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.3865 - acc: 0.8908 - val_loss: 0.3327 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3660 - acc: 0.8957 - val_loss: 0.3189 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 55us/step\n",
      "40000/40000 [==============================] - 2s 62us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.9432 - acc: 0.7571 - val_loss: 0.5046 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.4876 - acc: 0.8689 - val_loss: 0.3917 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.4136 - acc: 0.8867 - val_loss: 0.3521 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.3794 - acc: 0.8938 - val_loss: 0.3301 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3588 - acc: 0.8990 - val_loss: 0.3168 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 56us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.9129 - acc: 0.7732 - val_loss: 0.5608 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.4859 - acc: 0.8713 - val_loss: 0.4437 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.4128 - acc: 0.8868 - val_loss: 0.3999 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.3790 - acc: 0.8941 - val_loss: 0.3762 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3586 - acc: 0.8992 - val_loss: 0.3614 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 55us/step\n",
      "40000/40000 [==============================] - 2s 53us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4975 - acc: 0.8536 - val_loss: 0.2980 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.3655 - acc: 0.8926 - val_loss: 0.2914 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3497 - acc: 0.9000 - val_loss: 0.2790 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3429 - acc: 0.9013 - val_loss: 0.2662 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26763 to 0.26621, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3328 - acc: 0.9043 - val_loss: 0.2667 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 28us/step\n",
      "40000/40000 [==============================] - 1s 27us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.4967 - acc: 0.8509 - val_loss: 0.2914 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3636 - acc: 0.8952 - val_loss: 0.2797 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3415 - acc: 0.9019 - val_loss: 0.2833 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3317 - acc: 0.9063 - val_loss: 0.2725 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3245 - acc: 0.9081 - val_loss: 0.2663 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 25us/step\n",
      "40000/40000 [==============================] - 1s 23us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 0.4777 - acc: 0.8582 - val_loss: 0.3603 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.3583 - acc: 0.8984 - val_loss: 0.3381 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.3411 - acc: 0.9049 - val_loss: 0.3203 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3306 - acc: 0.9073 - val_loss: 0.3304 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3218 - acc: 0.9108 - val_loss: 0.3210 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 0s 24us/step\n",
      "40000/40000 [==============================] - 1s 23us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.1870 - acc: 0.6418 - val_loss: 0.6082 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.6274 - acc: 0.8173 - val_loss: 0.4395 - val_acc: 0.8859\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5188 - acc: 0.8462 - val_loss: 0.3814 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4663 - acc: 0.8606 - val_loss: 0.3503 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4404 - acc: 0.8684 - val_loss: 0.3324 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 0s 24us/step\n",
      "40000/40000 [==============================] - 1s 23us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.1656 - acc: 0.6585 - val_loss: 0.5810 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.6068 - acc: 0.8271 - val_loss: 0.4233 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.5047 - acc: 0.8525 - val_loss: 0.3717 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4593 - acc: 0.8645 - val_loss: 0.3455 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4296 - acc: 0.8741 - val_loss: 0.3295 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 28us/step\n",
      "40000/40000 [==============================] - 1s 27us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.1806 - acc: 0.6503 - val_loss: 0.6537 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.6096 - acc: 0.8279 - val_loss: 0.4882 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5019 - acc: 0.8577 - val_loss: 0.4290 - val_acc: 0.8815\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4583 - acc: 0.8675 - val_loss: 0.3980 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4281 - acc: 0.8762 - val_loss: 0.3802 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 25us/step\n",
      "40000/40000 [==============================] - 1s 24us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.5246 - acc: 0.8454 - val_loss: 0.3265 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4049 - acc: 0.8841 - val_loss: 0.3088 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.3794 - acc: 0.8913 - val_loss: 0.3332 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3658 - acc: 0.8951 - val_loss: 0.3021 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3512 - acc: 0.8998 - val_loss: 0.3090 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 67us/step\n",
      "40000/40000 [==============================] - 2s 56us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.5028 - acc: 0.8528 - val_loss: 0.3269 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4015 - acc: 0.8852 - val_loss: 0.3313 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.3730 - acc: 0.8935 - val_loss: 0.3650 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3579 - acc: 0.8986 - val_loss: 0.3030 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3422 - acc: 0.9035 - val_loss: 0.3226 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 84us/step\n",
      "40000/40000 [==============================] - 2s 61us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.5052 - acc: 0.8517 - val_loss: 0.3720 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.4024 - acc: 0.8852 - val_loss: 0.4022 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.3720 - acc: 0.8951 - val_loss: 0.3546 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3553 - acc: 0.8991 - val_loss: 0.4051 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3416 - acc: 0.9056 - val_loss: 0.3973 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 98us/step\n",
      "40000/40000 [==============================] - 3s 68us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.9626 - acc: 0.7329 - val_loss: 0.4925 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.5174 - acc: 0.8549 - val_loss: 0.3863 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.4440 - acc: 0.8707 - val_loss: 0.3465 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4099 - acc: 0.8809 - val_loss: 0.3267 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.3866 - acc: 0.8871 - val_loss: 0.3153 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 62us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.9653 - acc: 0.7329 - val_loss: 0.4957 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.5146 - acc: 0.8568 - val_loss: 0.3880 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.4432 - acc: 0.8725 - val_loss: 0.3484 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.4058 - acc: 0.8824 - val_loss: 0.3289 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3860 - acc: 0.8894 - val_loss: 0.3169 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 58us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.9608 - acc: 0.7373 - val_loss: 0.5584 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.5125 - acc: 0.8547 - val_loss: 0.4429 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.4383 - acc: 0.8764 - val_loss: 0.3999 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4042 - acc: 0.8842 - val_loss: 0.3767 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3827 - acc: 0.8884 - val_loss: 0.3619 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 61us/step\n",
      "40000/40000 [==============================] - 3s 75us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6852 - acc: 0.7857 - val_loss: 0.3035 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4831 - acc: 0.8579 - val_loss: 0.2951 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4432 - acc: 0.8706 - val_loss: 0.2882 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4330 - acc: 0.8773 - val_loss: 0.2924 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4150 - acc: 0.8809 - val_loss: 0.2822 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 30us/step\n",
      "40000/40000 [==============================] - 1s 27us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6721 - acc: 0.7907 - val_loss: 0.2999 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4725 - acc: 0.8622 - val_loss: 0.2936 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4417 - acc: 0.8741 - val_loss: 0.2847 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4285 - acc: 0.8783 - val_loss: 0.2720 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.4082 - acc: 0.8841 - val_loss: 0.2879 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 27us/step\n",
      "40000/40000 [==============================] - 1s 25us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 0.6616 - acc: 0.7972 - val_loss: 0.3601 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4823 - acc: 0.8618 - val_loss: 0.3446 - val_acc: 0.8988\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4440 - acc: 0.8738 - val_loss: 0.3363 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4205 - acc: 0.8814 - val_loss: 0.3259 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4012 - acc: 0.8878 - val_loss: 0.3304 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 25us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 26us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.4303 - acc: 0.5229 - val_loss: 0.6278 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.8145 - acc: 0.7384 - val_loss: 0.4594 - val_acc: 0.8824\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.6763 - acc: 0.7831 - val_loss: 0.3959 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.6202 - acc: 0.8068 - val_loss: 0.3664 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5799 - acc: 0.8218 - val_loss: 0.3503 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 32us/step\n",
      "40000/40000 [==============================] - 1s 32us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.4528 - acc: 0.5183 - val_loss: 0.6569 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.8205 - acc: 0.7378 - val_loss: 0.4667 - val_acc: 0.8810\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.6864 - acc: 0.7859 - val_loss: 0.4027 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.6172 - acc: 0.8085 - val_loss: 0.3683 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5740 - acc: 0.8250 - val_loss: 0.3488 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 25us/step\n",
      "40000/40000 [==============================] - 1s 25us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 5s - loss: 1.4185 - acc: 0.5265 - val_loss: 0.6842 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.8113 - acc: 0.7376 - val_loss: 0.5136 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.6789 - acc: 0.7869 - val_loss: 0.4487 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.6187 - acc: 0.8081 - val_loss: 0.4166 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5737 - acc: 0.8246 - val_loss: 0.3967 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 34us/step\n",
      "40000/40000 [==============================] - 2s 41us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.5747 - acc: 0.8317 - val_loss: 0.3414 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4660 - acc: 0.8685 - val_loss: 0.3011 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.4373 - acc: 0.8791 - val_loss: 0.3020 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.4144 - acc: 0.8836 - val_loss: 0.3202 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3950 - acc: 0.8881 - val_loss: 0.3276 - val_acc: 0.9090\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 62us/step\n",
      "40000/40000 [==============================] - 2s 56us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.5678 - acc: 0.8339 - val_loss: 0.3318 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4569 - acc: 0.8709 - val_loss: 0.3379 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.4274 - acc: 0.8808 - val_loss: 0.3162 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.4056 - acc: 0.8888 - val_loss: 0.3143 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.3892 - acc: 0.8918 - val_loss: 0.3518 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 78us/step\n",
      "40000/40000 [==============================] - 2s 61us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.5701 - acc: 0.8333 - val_loss: 0.3614 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4538 - acc: 0.8743 - val_loss: 0.3905 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.4259 - acc: 0.8824 - val_loss: 0.3719 - val_acc: 0.8995\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4004 - acc: 0.8895 - val_loss: 0.3664 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3864 - acc: 0.8920 - val_loss: 0.3582 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 56us/step\n",
      "40000/40000 [==============================] - 2s 55us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 1.1365 - acc: 0.6318 - val_loss: 0.5119 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.6206 - acc: 0.8096 - val_loss: 0.3962 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.5325 - acc: 0.8381 - val_loss: 0.3554 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.4835 - acc: 0.8513 - val_loss: 0.3335 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.4614 - acc: 0.8593 - val_loss: 0.3211 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 2s 58us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 1.1161 - acc: 0.6429 - val_loss: 0.4916 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.6063 - acc: 0.8148 - val_loss: 0.3862 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.5193 - acc: 0.8415 - val_loss: 0.3483 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.4762 - acc: 0.8575 - val_loss: 0.3291 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.4534 - acc: 0.8620 - val_loss: 0.3181 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 2s 62us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 1.1383 - acc: 0.6334 - val_loss: 0.5667 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.6169 - acc: 0.8115 - val_loss: 0.4488 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.5257 - acc: 0.8404 - val_loss: 0.4069 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4782 - acc: 0.8568 - val_loss: 0.3815 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.4609 - acc: 0.8612 - val_loss: 0.3665 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 68us/step\n",
      "40000/40000 [==============================] - 3s 64us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.2637 - acc: 0.2473 - val_loss: 2.1884 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.0374 - acc: 0.8026 - val_loss: 1.8438 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 1.6311 - acc: 0.8328 - val_loss: 1.3954 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.1975 - acc: 0.8390 - val_loss: 0.9853 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.8452 - acc: 0.8440 - val_loss: 0.6935 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 47us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.2638 - acc: 0.1954 - val_loss: 2.1875 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.0294 - acc: 0.7710 - val_loss: 1.8299 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 1.6099 - acc: 0.7760 - val_loss: 1.3750 - val_acc: 0.7691\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1.1802 - acc: 0.7694 - val_loss: 0.9885 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.8619 - acc: 0.7917 - val_loss: 0.7405 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 47us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.2642 - acc: 0.1895 - val_loss: 2.1919 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.0355 - acc: 0.8436 - val_loss: 1.8477 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 1.6191 - acc: 0.9163 - val_loss: 1.3912 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.1650 - acc: 0.9242 - val_loss: 0.9637 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.7838 - acc: 0.9300 - val_loss: 0.6494 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 47us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.3023 - acc: 0.1055 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 46us/step\n",
      "40000/40000 [==============================] - 2s 46us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.3020 - acc: 0.1092 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3014 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3010 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 47us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 2.3022 - acc: 0.1093 - val_loss: 2.3018 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3013 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 50us/step\n",
      "40000/40000 [==============================] - 2s 48us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.2812 - acc: 0.1175 - val_loss: 2.2268 - val_acc: 0.2634\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 2.0905 - acc: 0.6174 - val_loss: 1.9139 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 1.7140 - acc: 0.6688 - val_loss: 1.4986 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 1.3155 - acc: 0.6767 - val_loss: 1.1306 - val_acc: 0.6751\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 1.0081 - acc: 0.6787 - val_loss: 0.8849 - val_acc: 0.6890\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 122us/step\n",
      "40000/40000 [==============================] - 4s 98us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.2801 - acc: 0.1567 - val_loss: 2.2240 - val_acc: 0.3920\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 2.0860 - acc: 0.6487 - val_loss: 1.9085 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 1.7040 - acc: 0.7464 - val_loss: 1.4844 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 1.2935 - acc: 0.7538 - val_loss: 1.0974 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.9582 - acc: 0.7634 - val_loss: 0.8168 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "40000/40000 [==============================] - 4s 107us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.2809 - acc: 0.1267 - val_loss: 2.2287 - val_acc: 0.2861\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 2.0919 - acc: 0.6449 - val_loss: 1.9217 - val_acc: 0.7461\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 1.7093 - acc: 0.7568 - val_loss: 1.4968 - val_acc: 0.7585\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 1.2871 - acc: 0.7625 - val_loss: 1.1034 - val_acc: 0.7625\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.9443 - acc: 0.7675 - val_loss: 0.8279 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 90us/step\n",
      "40000/40000 [==============================] - 4s 99us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 2.3022 - acc: 0.1106 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3016 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 90us/step\n",
      "40000/40000 [==============================] - 4s 104us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 2.3021 - acc: 0.1103 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3010 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 110us/step\n",
      "40000/40000 [==============================] - 5s 116us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.3020 - acc: 0.1131 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3013 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 100us/step\n",
      "40000/40000 [==============================] - 4s 96us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.2697 - acc: 0.1897 - val_loss: 2.2040 - val_acc: 0.6011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.0796 - acc: 0.5500 - val_loss: 1.8950 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 1.7719 - acc: 0.5577 - val_loss: 1.5098 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.4927 - acc: 0.5635 - val_loss: 1.1889 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.2912 - acc: 0.5664 - val_loss: 0.9721 - val_acc: 0.6907\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 52us/step\n",
      "40000/40000 [==============================] - 2s 52us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.2708 - acc: 0.2422 - val_loss: 2.2087 - val_acc: 0.5369\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.0913 - acc: 0.6087 - val_loss: 1.9132 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 1.7781 - acc: 0.6360 - val_loss: 1.5144 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.4696 - acc: 0.6373 - val_loss: 1.1480 - val_acc: 0.7784\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.2259 - acc: 0.6425 - val_loss: 0.8827 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 53us/step\n",
      "40000/40000 [==============================] - 2s 50us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.2698 - acc: 0.2172 - val_loss: 2.2093 - val_acc: 0.3755\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.0893 - acc: 0.6479 - val_loss: 1.9205 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 1.7760 - acc: 0.6927 - val_loss: 1.5205 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.4514 - acc: 0.6977 - val_loss: 1.1417 - val_acc: 0.8401\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.1968 - acc: 0.7035 - val_loss: 0.8591 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 55us/step\n",
      "40000/40000 [==============================] - 2s 56us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.3021 - acc: 0.1107 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.3016 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 53us/step\n",
      "40000/40000 [==============================] - 2s 52us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.3023 - acc: 0.1069 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 52us/step\n",
      "40000/40000 [==============================] - 2s 54us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.3019 - acc: 0.1107 - val_loss: 2.3016 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 52us/step\n",
      "40000/40000 [==============================] - 3s 64us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 2.2838 - acc: 0.1307 - val_loss: 2.2362 - val_acc: 0.2059\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 2.1244 - acc: 0.4561 - val_loss: 1.9580 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 1.8362 - acc: 0.4885 - val_loss: 1.5961 - val_acc: 0.5865\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.5669 - acc: 0.4897 - val_loss: 1.2951 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 1.3861 - acc: 0.4899 - val_loss: 1.0951 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 105us/step\n",
      "40000/40000 [==============================] - 5s 137us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2855 - acc: 0.1425 - val_loss: 2.2427 - val_acc: 0.3352\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 2.1371 - acc: 0.4651 - val_loss: 1.9786 - val_acc: 0.5814\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 1.8469 - acc: 0.4951 - val_loss: 1.6115 - val_acc: 0.5821\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.5619 - acc: 0.4981 - val_loss: 1.2868 - val_acc: 0.6082\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 1.3608 - acc: 0.5060 - val_loss: 1.0708 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 103us/step\n",
      "40000/40000 [==============================] - 5s 123us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2844 - acc: 0.1371 - val_loss: 2.2399 - val_acc: 0.2014\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 2.1304 - acc: 0.4554 - val_loss: 1.9740 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 1.8480 - acc: 0.4873 - val_loss: 1.6252 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.5752 - acc: 0.4905 - val_loss: 1.3197 - val_acc: 0.5734\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 1.3789 - acc: 0.4956 - val_loss: 1.1155 - val_acc: 0.5774\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 115us/step\n",
      "40000/40000 [==============================] - 4s 102us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.3022 - acc: 0.1118 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3016 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 103us/step\n",
      "40000/40000 [==============================] - 4s 108us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.3021 - acc: 0.1105 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3014 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 120us/step\n",
      "40000/40000 [==============================] - 5s 133us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.3020 - acc: 0.1135 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3013 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 141us/step\n",
      "40000/40000 [==============================] - 4s 104us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.2816 - acc: 0.1898 - val_loss: 2.2416 - val_acc: 0.1960\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.1744 - acc: 0.3784 - val_loss: 2.0539 - val_acc: 0.6597\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.0070 - acc: 0.4011 - val_loss: 1.7891 - val_acc: 0.6824\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.8485 - acc: 0.4103 - val_loss: 1.5286 - val_acc: 0.6924\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.7186 - acc: 0.4190 - val_loss: 1.3100 - val_acc: 0.7238\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 59us/step\n",
      "40000/40000 [==============================] - 3s 68us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.2826 - acc: 0.2044 - val_loss: 2.2448 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.1808 - acc: 0.4196 - val_loss: 2.0650 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.0121 - acc: 0.4420 - val_loss: 1.7992 - val_acc: 0.7606\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.8490 - acc: 0.4500 - val_loss: 1.5305 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.7120 - acc: 0.4643 - val_loss: 1.2986 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 59us/step\n",
      "40000/40000 [==============================] - 2s 61us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.2811 - acc: 0.1716 - val_loss: 2.2429 - val_acc: 0.2575\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.1786 - acc: 0.3761 - val_loss: 2.0622 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.0133 - acc: 0.3963 - val_loss: 1.8020 - val_acc: 0.6679\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 1.8705 - acc: 0.3960 - val_loss: 1.5531 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 1.7730 - acc: 0.3947 - val_loss: 1.3613 - val_acc: 0.6780\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 56us/step\n",
      "40000/40000 [==============================] - 2s 55us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.3022 - acc: 0.1107 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 85us/step\n",
      "40000/40000 [==============================] - 3s 67us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3021 - acc: 0.1084 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.3015 - acc: 0.1122 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.3012 - acc: 0.1127 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 63us/step\n",
      "40000/40000 [==============================] - 3s 70us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3022 - acc: 0.1039 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 2.3014 - acc: 0.1142 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 58us/step\n",
      "40000/40000 [==============================] - 2s 57us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 2.2910 - acc: 0.1218 - val_loss: 2.2637 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 2.2045 - acc: 0.3827 - val_loss: 2.0973 - val_acc: 0.6764\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 2.0479 - acc: 0.3940 - val_loss: 1.8403 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.8912 - acc: 0.3938 - val_loss: 1.5762 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 1.7609 - acc: 0.4000 - val_loss: 1.3478 - val_acc: 0.7019\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 120us/step\n",
      "40000/40000 [==============================] - 4s 105us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2911 - acc: 0.1318 - val_loss: 2.2643 - val_acc: 0.2009\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 2.2047 - acc: 0.3378 - val_loss: 2.0950 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 12s - loss: 2.0497 - acc: 0.3485 - val_loss: 1.8451 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.9132 - acc: 0.3467 - val_loss: 1.6057 - val_acc: 0.5877\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 1.8007 - acc: 0.3527 - val_loss: 1.4097 - val_acc: 0.5895\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 106us/step\n",
      "40000/40000 [==============================] - 4s 112us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2913 - acc: 0.1257 - val_loss: 2.2659 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 2.2050 - acc: 0.2869 - val_loss: 2.1014 - val_acc: 0.4836\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 2.0527 - acc: 0.3443 - val_loss: 1.8582 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 1.9047 - acc: 0.3490 - val_loss: 1.6209 - val_acc: 0.5737\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 1.7845 - acc: 0.3519 - val_loss: 1.4196 - val_acc: 0.5757\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 118us/step\n",
      "40000/40000 [==============================] - 6s 149us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.3023 - acc: 0.1087 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 127us/step\n",
      "40000/40000 [==============================] - 6s 142us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 2.3020 - acc: 0.1093 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3014 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 10s - loss: 2.3011 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 2.3010 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 106us/step\n",
      "40000/40000 [==============================] - 4s 103us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.3021 - acc: 0.1108 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.3013 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3009 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 115us/step\n",
      "40000/40000 [==============================] - 5s 123us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.2873 - acc: 0.1153 - val_loss: 2.2625 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.2153 - acc: 0.4467 - val_loss: 2.1517 - val_acc: 0.7445\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.0691 - acc: 0.7482 - val_loss: 1.9701 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 1.8652 - acc: 0.7589 - val_loss: 1.7465 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 1.6345 - acc: 0.7639 - val_loss: 1.5102 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 45us/step\n",
      "40000/40000 [==============================] - 1s 35us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.2873 - acc: 0.1336 - val_loss: 2.2632 - val_acc: 0.2047\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.2164 - acc: 0.4278 - val_loss: 2.1528 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.0690 - acc: 0.7727 - val_loss: 1.9690 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 1.8620 - acc: 0.8294 - val_loss: 1.7403 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 1.6259 - acc: 0.8359 - val_loss: 1.4982 - val_acc: 0.8465\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 43us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.2882 - acc: 0.1142 - val_loss: 2.2659 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.2203 - acc: 0.3448 - val_loss: 2.1626 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.0794 - acc: 0.7212 - val_loss: 1.9887 - val_acc: 0.7415\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 1.8804 - acc: 0.7453 - val_loss: 1.7711 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 1.6535 - acc: 0.7513 - val_loss: 1.5402 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 35us/step\n",
      "40000/40000 [==============================] - 1s 35us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 2.3025 - acc: 0.1060 - val_loss: 2.3023 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.3020 - acc: 0.1126 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 2.3016 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 37us/step\n",
      "40000/40000 [==============================] - 1s 36us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.3025 - acc: 0.0964 - val_loss: 2.3022 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.3019 - acc: 0.1125 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 2.3013 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 44us/step\n",
      "40000/40000 [==============================] - 1s 37us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3025 - acc: 0.1028 - val_loss: 2.3023 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.3018 - acc: 0.1143 - val_loss: 2.3018 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.3014 - acc: 0.1143 - val_loss: 2.3016 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 43us/step\n",
      "40000/40000 [==============================] - 2s 38us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.2963 - acc: 0.1118 - val_loss: 2.2830 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.2468 - acc: 0.1966 - val_loss: 2.1955 - val_acc: 0.5694\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.1231 - acc: 0.5720 - val_loss: 2.0372 - val_acc: 0.5824\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 1.9450 - acc: 0.5842 - val_loss: 1.8420 - val_acc: 0.5817\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8190s - loss: 1.7457 - acc: 0.5837 - val_loss: 1.6398 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 86us/step\n",
      "40000/40000 [==============================] - 3s 87us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.2962 - acc: 0.1111 - val_loss: 2.2831 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2480 - acc: 0.2411 - val_loss: 2.1989 - val_acc: 0.4854\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.1277 - acc: 0.5635 - val_loss: 2.0418 - val_acc: 0.6605\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 1.9476 - acc: 0.6620 - val_loss: 1.8401 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 1.7376 - acc: 0.6651 - val_loss: 1.6227 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 84us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 87us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2959 - acc: 0.1135 - val_loss: 2.2828 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.2465 - acc: 0.2096 - val_loss: 2.1976 - val_acc: 0.5309\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.1229 - acc: 0.6399 - val_loss: 2.0407 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 1.9392 - acc: 0.6676 - val_loss: 1.8383 - val_acc: 0.6763\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 1.7236 - acc: 0.6757 - val_loss: 1.6190 - val_acc: 0.6616\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 91us/step\n",
      "40000/40000 [==============================] - 4s 90us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 2.3024 - acc: 0.1092 - val_loss: 2.3022 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3020 - acc: 0.1126 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 100us/step\n",
      "40000/40000 [==============================] - 4s 96us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.3023 - acc: 0.1090 - val_loss: 2.3021 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3018 - acc: 0.1125 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 2.3013 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 87us/step\n",
      "40000/40000 [==============================] - 3s 85us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.3022 - acc: 0.1125 - val_loss: 2.3020 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3017 - acc: 0.1143 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 86us/step\n",
      "40000/40000 [==============================] - 4s 96us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 2.2900 - acc: 0.1183 - val_loss: 2.2696 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.2323 - acc: 0.3689 - val_loss: 2.1775 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.1118 - acc: 0.6152 - val_loss: 2.0161 - val_acc: 0.7585\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.9467 - acc: 0.6212 - val_loss: 1.8093 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.7657 - acc: 0.6257 - val_loss: 1.5888 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 52us/step\n",
      "40000/40000 [==============================] - 2s 38us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.2882 - acc: 0.1348 - val_loss: 2.2658 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 2.2244 - acc: 0.4394 - val_loss: 2.1659 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 2.0984 - acc: 0.6780 - val_loss: 1.9973 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.9264 - acc: 0.6923 - val_loss: 1.7845 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.7374 - acc: 0.6994 - val_loss: 1.5557 - val_acc: 0.8511\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 41us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.2894 - acc: 0.1154 - val_loss: 2.2692 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.2284 - acc: 0.3423 - val_loss: 2.1735 - val_acc: 0.6196\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.1028 - acc: 0.6031 - val_loss: 2.0091 - val_acc: 0.7459\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.9328 - acc: 0.6264 - val_loss: 1.8020 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.7474 - acc: 0.6345 - val_loss: 1.5817 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 41us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3024 - acc: 0.1059 - val_loss: 2.3022 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3019 - acc: 0.1122 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3018 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 38us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3027 - acc: 0.0999 - val_loss: 2.3024 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3020 - acc: 0.1120 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3016 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3014 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3013 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 43us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3021 - acc: 0.1090 - val_loss: 2.3020 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3016 - acc: 0.1144 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3013 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 41us/step\n",
      "40000/40000 [==============================] - 2s 46us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2973 - acc: 0.1123 - val_loss: 2.2860 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2558 - acc: 0.2105 - val_loss: 2.2106 - val_acc: 0.3795\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.1538 - acc: 0.4126 - val_loss: 2.0697 - val_acc: 0.5015\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 2.0107 - acc: 0.4174 - val_loss: 1.8930 - val_acc: 0.4986\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 1.8577 - acc: 0.4201 - val_loss: 1.7110 - val_acc: 0.4995\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 100us/step\n",
      "40000/40000 [==============================] - 3s 86us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2974 - acc: 0.1118 - val_loss: 2.2870 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2582 - acc: 0.2235 - val_loss: 2.2151 - val_acc: 0.4376\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.1561 - acc: 0.4847 - val_loss: 2.0714 - val_acc: 0.5783\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 2.0034 - acc: 0.5475 - val_loss: 1.8797 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 1.8325 - acc: 0.5516 - val_loss: 1.6687 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 84us/step\n",
      "40000/40000 [==============================] - 4s 96us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.2970 - acc: 0.1142 - val_loss: 2.2864 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2566 - acc: 0.1750 - val_loss: 2.2142 - val_acc: 0.3221\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.1530 - acc: 0.5695 - val_loss: 2.0697 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 1.9947 - acc: 0.6368 - val_loss: 1.8753 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 1.8175 - acc: 0.6331 - val_loss: 1.6606 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "40000/40000 [==============================] - 3s 82us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 2.3023 - acc: 0.1112 - val_loss: 2.3022 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.3019 - acc: 0.1126 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 93us/step\n",
      "40000/40000 [==============================] - 4s 92us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.3023 - acc: 0.1112 - val_loss: 2.3021 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.3018 - acc: 0.1125 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3013 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 91us/step\n",
      "40000/40000 [==============================] - 4s 94us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 2.3023 - acc: 0.1116 - val_loss: 2.3020 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.3017 - acc: 0.1143 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.3014 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 2.3010 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 92us/step\n",
      "40000/40000 [==============================] - 4s 99us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.2925 - acc: 0.1353 - val_loss: 2.2770 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.2512 - acc: 0.2995 - val_loss: 2.2100 - val_acc: 0.5369\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.1722 - acc: 0.3781 - val_loss: 2.0944 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.0720 - acc: 0.3937 - val_loss: 1.9460 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.9676 - acc: 0.4035 - val_loss: 1.7842 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 39us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.2923 - acc: 0.1365 - val_loss: 2.2772 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.2513 - acc: 0.3154 - val_loss: 2.2118 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.1740 - acc: 0.4211 - val_loss: 2.0978 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.0726 - acc: 0.4380 - val_loss: 1.9503 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.9656 - acc: 0.4453 - val_loss: 1.7816 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 41us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.2926 - acc: 0.1188 - val_loss: 2.2781 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.2523 - acc: 0.2854 - val_loss: 2.2147 - val_acc: 0.5184\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.1733 - acc: 0.4056 - val_loss: 2.1023 - val_acc: 0.6596\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.0718 - acc: 0.4542 - val_loss: 1.9542 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.9613 - acc: 0.4719 - val_loss: 1.7840 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 42us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 2.3026 - acc: 0.1018 - val_loss: 2.3022 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3020 - acc: 0.1109 - val_loss: 2.3020 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3018 - acc: 0.1124 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 2.3016 - acc: 0.1127 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 43us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 2.3024 - acc: 0.1044 - val_loss: 2.3021 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3018 - acc: 0.1108 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3016 - acc: 0.1116 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3013 - acc: 0.1121 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1126 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 55us/step\n",
      "40000/40000 [==============================] - 2s 42us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 2.3022 - acc: 0.1053 - val_loss: 2.3020 - val_acc: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 2.3016 - acc: 0.1140 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 2.3013 - acc: 0.1145 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 42us/step\n",
      "40000/40000 [==============================] - 2s 43us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 2.2988 - acc: 0.1121 - val_loss: 2.2916 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 2.2737 - acc: 0.1942 - val_loss: 2.2448 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.2129 - acc: 0.3393 - val_loss: 2.1494 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 2.1230 - acc: 0.3613 - val_loss: 2.0173 - val_acc: 0.5874\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 2.0292 - acc: 0.3659 - val_loss: 1.8686 - val_acc: 0.5903\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 95us/step\n",
      "40000/40000 [==============================] - 4s 98us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 2.2985 - acc: 0.1117 - val_loss: 2.2911 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2724 - acc: 0.2066 - val_loss: 2.2425 - val_acc: 0.2717\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.2095 - acc: 0.3453 - val_loss: 2.1450 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 2.1221 - acc: 0.3462 - val_loss: 2.0131 - val_acc: 0.5791\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 2.0285 - acc: 0.3521 - val_loss: 1.8635 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 86us/step\n",
      "40000/40000 [==============================] - 4s 94us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 2.2983 - acc: 0.1126 - val_loss: 2.2908 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 2.2716 - acc: 0.1757 - val_loss: 2.2423 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 2.2061 - acc: 0.3777 - val_loss: 2.1433 - val_acc: 0.6492\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 2.1130 - acc: 0.3939 - val_loss: 2.0055 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 2.0098 - acc: 0.3995 - val_loss: 1.8453 - val_acc: 0.6659\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 94us/step\n",
      "40000/40000 [==============================] - 3s 83us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 2.3023 - acc: 0.1115 - val_loss: 2.3021 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.3019 - acc: 0.1126 - val_loss: 2.3019 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.3017 - acc: 0.1126 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3015 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 108us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.3023 - acc: 0.1105 - val_loss: 2.3021 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 2.3017 - acc: 0.1125 - val_loss: 2.3018 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 2.3015 - acc: 0.1125 - val_loss: 2.3017 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 2.3013 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 2.3012 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 101us/step\n",
      "40000/40000 [==============================] - 3s 87us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 2.3023 - acc: 0.1104 - val_loss: 2.3020 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 2.3017 - acc: 0.1143 - val_loss: 2.3017 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 2.3014 - acc: 0.1143 - val_loss: 2.3015 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 2.3012 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 2.3011 - acc: 0.1143 - val_loss: 2.3014 - val_acc: 0.1130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 104us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.3453 - acc: 0.8988 - val_loss: 0.1664 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26621 to 0.16640, saving model to mnist.model.best.hdf5\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.1543 - acc: 0.9530 - val_loss: 0.1295 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16640 to 0.12945, saving model to mnist.model.best.hdf5\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.1094 - acc: 0.9658 - val_loss: 0.1089 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12945 to 0.10886, saving model to mnist.model.best.hdf5\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.0802 - acc: 0.9754 - val_loss: 0.0991 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10886 to 0.09906, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.0626 - acc: 0.9806 - val_loss: 0.1006 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 61us/step\n",
      "40000/40000 [==============================] - 2s 59us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.3409 - acc: 0.9012 - val_loss: 0.1591 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.1478 - acc: 0.9563 - val_loss: 0.1162 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.1000 - acc: 0.9703 - val_loss: 0.1123 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.0749 - acc: 0.9767 - val_loss: 0.1181 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.0573 - acc: 0.9827 - val_loss: 0.1123 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 63us/step\n",
      "40000/40000 [==============================] - 2s 59us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.3351 - acc: 0.9039 - val_loss: 0.1968 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.1405 - acc: 0.9577 - val_loss: 0.1473 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.0972 - acc: 0.9699 - val_loss: 0.1237 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.0707 - acc: 0.9781 - val_loss: 0.1192 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.0551 - acc: 0.9836 - val_loss: 0.1087 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 69us/step\n",
      "40000/40000 [==============================] - 3s 66us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.2112 - acc: 0.6957 - val_loss: 0.5325 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.4820 - acc: 0.8712 - val_loss: 0.3652 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.3845 - acc: 0.8912 - val_loss: 0.3172 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3423 - acc: 0.9026 - val_loss: 0.2901 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.3150 - acc: 0.9094 - val_loss: 0.2703 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 63us/step\n",
      "40000/40000 [==============================] - 3s 69us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 1.2591 - acc: 0.6777 - val_loss: 0.5832 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.5038 - acc: 0.8697 - val_loss: 0.3808 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3872 - acc: 0.8938 - val_loss: 0.3197 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.3392 - acc: 0.9046 - val_loss: 0.2935 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.3098 - acc: 0.9122 - val_loss: 0.2722 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 3s 65us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.2176 - acc: 0.6868 - val_loss: 0.5983 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.4777 - acc: 0.8738 - val_loss: 0.4135 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.3738 - acc: 0.8955 - val_loss: 0.3543 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3294 - acc: 0.9071 - val_loss: 0.3245 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.3017 - acc: 0.9138 - val_loss: 0.3012 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 2s 59us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.2670 - acc: 0.9168 - val_loss: 0.1341 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.1042 - acc: 0.9688 - val_loss: 0.1222 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.0683 - acc: 0.9791 - val_loss: 0.1267 - val_acc: 0.9676\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.0486 - acc: 0.9853 - val_loss: 0.1046 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.0381 - acc: 0.9886 - val_loss: 0.0934 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09906 to 0.09338, saving model to mnist.model.best.hdf5\n",
      "20000/20000 [==============================] - 2s 99us/step\n",
      "40000/40000 [==============================] - 4s 101us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.2583 - acc: 0.9199 - val_loss: 0.1266 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.1009 - acc: 0.9695 - val_loss: 0.0994 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.0667 - acc: 0.9804 - val_loss: 0.0906 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09338 to 0.09060, saving model to mnist.model.best.hdf5\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.0474 - acc: 0.9848 - val_loss: 0.1036 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.0367 - acc: 0.9885 - val_loss: 0.1165 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 97us/step\n",
      "40000/40000 [==============================] - 4s 108us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.2627 - acc: 0.9181 - val_loss: 0.1283 - val_acc: 0.9601\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.1008 - acc: 0.9696 - val_loss: 0.1090 - val_acc: 0.9699\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.0640 - acc: 0.9806 - val_loss: 0.1241 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.0447 - acc: 0.9869 - val_loss: 0.1184 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.0330 - acc: 0.9898 - val_loss: 0.1248 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 95us/step\n",
      "40000/40000 [==============================] - 4s 101us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.1039 - acc: 0.7511 - val_loss: 0.4867 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.4481 - acc: 0.8826 - val_loss: 0.3366 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.3589 - acc: 0.8994 - val_loss: 0.2928 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.3181 - acc: 0.9096 - val_loss: 0.2667 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.2915 - acc: 0.9169 - val_loss: 0.2491 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 4s 202us/step\n",
      "40000/40000 [==============================] - 6s 149us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 1.0760 - acc: 0.7561 - val_loss: 0.4830 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.4415 - acc: 0.8851 - val_loss: 0.3390 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.3540 - acc: 0.9029 - val_loss: 0.2958 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3139 - acc: 0.9129 - val_loss: 0.2741 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.2873 - acc: 0.9198 - val_loss: 0.2535 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 100us/step\n",
      "40000/40000 [==============================] - 4s 101us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.0492 - acc: 0.7608 - val_loss: 0.5300 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.4373 - acc: 0.8857 - val_loss: 0.3885 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.3523 - acc: 0.9024 - val_loss: 0.3358 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.3122 - acc: 0.9121 - val_loss: 0.3072 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.2860 - acc: 0.9194 - val_loss: 0.2876 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 134us/step\n",
      "40000/40000 [==============================] - 4s 106us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.4376 - acc: 0.8667 - val_loss: 0.1799 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.2046 - acc: 0.9390 - val_loss: 0.1234 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.1568 - acc: 0.9533 - val_loss: 0.1212 - val_acc: 0.9649\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.1304 - acc: 0.9614 - val_loss: 0.0972 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.1100 - acc: 0.9658 - val_loss: 0.0996 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.4315 - acc: 0.8699 - val_loss: 0.1657 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.2040 - acc: 0.9391 - val_loss: 0.1300 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.1525 - acc: 0.9544 - val_loss: 0.1113 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.1293 - acc: 0.9615 - val_loss: 0.1025 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.1096 - acc: 0.9676 - val_loss: 0.1015 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 1s 60us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.4203 - acc: 0.8739 - val_loss: 0.2137 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.2009 - acc: 0.9401 - val_loss: 0.1461 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.1473 - acc: 0.9548 - val_loss: 0.1345 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.1225 - acc: 0.9634 - val_loss: 0.1207 - val_acc: 0.9664\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.1035 - acc: 0.9687 - val_loss: 0.1258 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 59us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 1.4237 - acc: 0.5789 - val_loss: 0.6266 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.6829 - acc: 0.7957 - val_loss: 0.4034 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.5337 - acc: 0.8421 - val_loss: 0.3370 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.4646 - acc: 0.8621 - val_loss: 0.3011 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.4206 - acc: 0.8755 - val_loss: 0.2771 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 61us/step\n",
      "40000/40000 [==============================] - 2s 61us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.4861 - acc: 0.5577 - val_loss: 0.6629 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7019 - acc: 0.7923 - val_loss: 0.4110 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.5416 - acc: 0.8382 - val_loss: 0.3430 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.4685 - acc: 0.8621 - val_loss: 0.3041 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.4253 - acc: 0.8753 - val_loss: 0.2802 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 66us/step\n",
      "40000/40000 [==============================] - 3s 64us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 1.4714 - acc: 0.5475 - val_loss: 0.6979 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.6891 - acc: 0.7936 - val_loss: 0.4554 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.5326 - acc: 0.8406 - val_loss: 0.3851 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.4605 - acc: 0.8643 - val_loss: 0.3443 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.4190 - acc: 0.8791 - val_loss: 0.3196 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 63us/step\n",
      "40000/40000 [==============================] - 3s 63us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 21s - loss: 0.2971 - acc: 0.9094 - val_loss: 0.1275 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.1314 - acc: 0.9611 - val_loss: 0.1219 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 13s - loss: 0.0970 - acc: 0.9709 - val_loss: 0.1022 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.0805 - acc: 0.9773 - val_loss: 0.1032 - val_acc: 0.9699\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.0635 - acc: 0.9817 - val_loss: 0.0993 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 102us/step\n",
      "40000/40000 [==============================] - 5s 123us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 19s - loss: 0.2922 - acc: 0.9098 - val_loss: 0.1422 - val_acc: 0.9575\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.1290 - acc: 0.9611 - val_loss: 0.1080 - val_acc: 0.9701\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.0930 - acc: 0.9727 - val_loss: 0.1130 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.0781 - acc: 0.9776 - val_loss: 0.1058 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.0644 - acc: 0.9810 - val_loss: 0.1157 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 116us/step\n",
      "40000/40000 [==============================] - 5s 130us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.2907 - acc: 0.9110 - val_loss: 0.1829 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.1239 - acc: 0.9634 - val_loss: 0.1230 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.0910 - acc: 0.9726 - val_loss: 0.1265 - val_acc: 0.9666\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.0718 - acc: 0.9791 - val_loss: 0.1454 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.0586 - acc: 0.9831 - val_loss: 0.1234 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 115us/step\n",
      "40000/40000 [==============================] - 5s 123us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 1.2192 - acc: 0.6793 - val_loss: 0.5150 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.5350 - acc: 0.8498 - val_loss: 0.3527 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.4330 - acc: 0.8743 - val_loss: 0.3035 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.3781 - acc: 0.8892 - val_loss: 0.2740 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3433 - acc: 0.8995 - val_loss: 0.2550 - val_acc: 0.9285\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 103us/step\n",
      "40000/40000 [==============================] - 4s 94us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.2158 - acc: 0.6800 - val_loss: 0.5151 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.5367 - acc: 0.8465 - val_loss: 0.3560 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.4288 - acc: 0.8757 - val_loss: 0.3032 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.3754 - acc: 0.8910 - val_loss: 0.2734 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.3434 - acc: 0.8996 - val_loss: 0.2552 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 151us/step\n",
      "40000/40000 [==============================] - 5s 115us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 1.1790 - acc: 0.6929 - val_loss: 0.5552 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.5209 - acc: 0.8520 - val_loss: 0.3936 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.4160 - acc: 0.8787 - val_loss: 0.3415 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.3667 - acc: 0.8955 - val_loss: 0.3124 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.3344 - acc: 0.9030 - val_loss: 0.2880 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 145us/step\n",
      "40000/40000 [==============================] - 5s 118us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.6956 - acc: 0.7807 - val_loss: 0.2200 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.3601 - acc: 0.8949 - val_loss: 0.1805 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.3033 - acc: 0.9136 - val_loss: 0.1586 - val_acc: 0.9551\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.2745 - acc: 0.9223 - val_loss: 0.1463 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2576 - acc: 0.9292 - val_loss: 0.1407 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 66us/step\n",
      "40000/40000 [==============================] - 3s 65us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.6921 - acc: 0.7852 - val_loss: 0.2223 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.3538 - acc: 0.8980 - val_loss: 0.1754 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.2922 - acc: 0.9177 - val_loss: 0.1579 - val_acc: 0.9566\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.2688 - acc: 0.9266 - val_loss: 0.1550 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2494 - acc: 0.9327 - val_loss: 0.1515 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 66us/step\n",
      "40000/40000 [==============================] - 3s 65us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.7025 - acc: 0.7778 - val_loss: 0.2717 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.3624 - acc: 0.8952 - val_loss: 0.2114 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.3024 - acc: 0.9152 - val_loss: 0.1862 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.2667 - acc: 0.9248 - val_loss: 0.1777 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2473 - acc: 0.9335 - val_loss: 0.1697 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 66us/step\n",
      "40000/40000 [==============================] - 3s 66us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.8539 - acc: 0.3629 - val_loss: 1.0047 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 1.1357 - acc: 0.6246 - val_loss: 0.5745 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.8605 - acc: 0.7228 - val_loss: 0.4412 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.7308 - acc: 0.7702 - val_loss: 0.3713 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.6448 - acc: 0.8002 - val_loss: 0.3309 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 80us/step\n",
      "40000/40000 [==============================] - 3s 77us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.7948 - acc: 0.3949 - val_loss: 0.9065 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 1.0625 - acc: 0.6567 - val_loss: 0.5295 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.8194 - acc: 0.7373 - val_loss: 0.4233 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.7026 - acc: 0.7793 - val_loss: 0.3667 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.6335 - acc: 0.8039 - val_loss: 0.3283 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 59us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.7862 - acc: 0.3959 - val_loss: 0.9602 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 4s - loss: 1.0633 - acc: 0.6538 - val_loss: 0.5931 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.8084 - acc: 0.7447 - val_loss: 0.4705 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.6913 - acc: 0.7844 - val_loss: 0.4121 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.6127 - acc: 0.8163 - val_loss: 0.3767 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 76us/step\n",
      "40000/40000 [==============================] - 3s 76us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 21s - loss: 0.4061 - acc: 0.8752 - val_loss: 0.1369 - val_acc: 0.9585\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.2076 - acc: 0.9397 - val_loss: 0.1255 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.1691 - acc: 0.9527 - val_loss: 0.1100 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 13s - loss: 0.1533 - acc: 0.9579 - val_loss: 0.1092 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.1384 - acc: 0.9634 - val_loss: 0.1074 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 120us/step\n",
      "40000/40000 [==============================] - 6s 158us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.3941 - acc: 0.8780 - val_loss: 0.1498 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.2025 - acc: 0.9422 - val_loss: 0.1258 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.1656 - acc: 0.9518 - val_loss: 0.1078 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 13s - loss: 0.1502 - acc: 0.9583 - val_loss: 0.1115 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.1379 - acc: 0.9625 - val_loss: 0.1066 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 120us/step\n",
      "40000/40000 [==============================] - 5s 116us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 21s - loss: 0.3977 - acc: 0.8759 - val_loss: 0.1704 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.2005 - acc: 0.9403 - val_loss: 0.1461 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.1649 - acc: 0.9530 - val_loss: 0.1463 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.1452 - acc: 0.9598 - val_loss: 0.1283 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.1285 - acc: 0.9658 - val_loss: 0.1441 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 116us/step\n",
      "40000/40000 [==============================] - 6s 149us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 1.4412 - acc: 0.5504 - val_loss: 0.5877 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.7251 - acc: 0.7741 - val_loss: 0.3882 - val_acc: 0.8972\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.5639 - acc: 0.8270 - val_loss: 0.3284 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.4886 - acc: 0.8523 - val_loss: 0.2921 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.4459 - acc: 0.8667 - val_loss: 0.2692 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 133us/step\n",
      "40000/40000 [==============================] - 6s 141us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 1.4260 - acc: 0.5484 - val_loss: 0.5837 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.7074 - acc: 0.7816 - val_loss: 0.3888 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.5578 - acc: 0.8309 - val_loss: 0.3263 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.4812 - acc: 0.8551 - val_loss: 0.2903 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.4291 - acc: 0.8727 - val_loss: 0.2675 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 3s 144us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 148us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 22s - loss: 1.4442 - acc: 0.5505 - val_loss: 0.6462 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.7166 - acc: 0.7778 - val_loss: 0.4434 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.5659 - acc: 0.8283 - val_loss: 0.3766 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.4889 - acc: 0.8542 - val_loss: 0.3378 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.4445 - acc: 0.8680 - val_loss: 0.3120 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 118us/step\n",
      "40000/40000 [==============================] - 5s 116us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.4038 - acc: 0.8841 - val_loss: 0.2023 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.1834 - acc: 0.9448 - val_loss: 0.1449 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.1272 - acc: 0.9614 - val_loss: 0.1179 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.0950 - acc: 0.9708 - val_loss: 0.1076 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.0752 - acc: 0.9770 - val_loss: 0.1204 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 51us/step\n",
      "40000/40000 [==============================] - 2s 45us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 0.3973 - acc: 0.8865 - val_loss: 0.2110 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.1760 - acc: 0.9473 - val_loss: 0.1383 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.1233 - acc: 0.9630 - val_loss: 0.1254 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.0908 - acc: 0.9723 - val_loss: 0.1050 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.0702 - acc: 0.9781 - val_loss: 0.1029 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 38us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 0.4006 - acc: 0.8847 - val_loss: 0.2247 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.1786 - acc: 0.9464 - val_loss: 0.1640 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.1232 - acc: 0.9635 - val_loss: 0.1343 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.0912 - acc: 0.9718 - val_loss: 0.1243 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.0718 - acc: 0.9782 - val_loss: 0.1134 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 41us/step\n",
      "40000/40000 [==============================] - 2s 42us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.6588 - acc: 0.5894 - val_loss: 1.0085 - val_acc: 0.8116\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.7782 - acc: 0.8234 - val_loss: 0.5533 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5326 - acc: 0.8657 - val_loss: 0.4222 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4423 - acc: 0.8817 - val_loss: 0.3670 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3953 - acc: 0.8920 - val_loss: 0.3347 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 45us/step\n",
      "40000/40000 [==============================] - 2s 40us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 10s - loss: 1.7157 - acc: 0.5326 - val_loss: 1.0764 - val_acc: 0.7833\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.8126 - acc: 0.8151 - val_loss: 0.5817 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5474 - acc: 0.8620 - val_loss: 0.4418 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4516 - acc: 0.8809 - val_loss: 0.3804 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4021 - acc: 0.8902 - val_loss: 0.3459 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 47us/step\n",
      "40000/40000 [==============================] - 2s 42us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.6703 - acc: 0.5815 - val_loss: 1.0237 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7473 - acc: 0.8327 - val_loss: 0.5936 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5157 - acc: 0.8711 - val_loss: 0.4717 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4320 - acc: 0.8854 - val_loss: 0.4148 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.3882 - acc: 0.8948 - val_loss: 0.3846 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 40us/step\n",
      "40000/40000 [==============================] - 2s 50us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 0.3056 - acc: 0.9052 - val_loss: 0.1261 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.1149 - acc: 0.9644 - val_loss: 0.0960 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.0672 - acc: 0.9789 - val_loss: 0.1192 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.0459 - acc: 0.9851 - val_loss: 0.0871 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09060 to 0.08710, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.0332 - acc: 0.9892 - val_loss: 0.1016 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 84us/step\n",
      "40000/40000 [==============================] - 3s 82us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 0.3010 - acc: 0.9085 - val_loss: 0.1237 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.1104 - acc: 0.9658 - val_loss: 0.1076 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.0684 - acc: 0.9786 - val_loss: 0.0959 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.0454 - acc: 0.9852 - val_loss: 0.0836 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08710 to 0.08364, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.0338 - acc: 0.9894 - val_loss: 0.1003 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 80us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 0.2902 - acc: 0.9093 - val_loss: 0.1536 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 8s - loss: 0.1057 - acc: 0.9672 - val_loss: 0.1294 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.0642 - acc: 0.9799 - val_loss: 0.1221 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.0440 - acc: 0.9858 - val_loss: 0.1056 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.0306 - acc: 0.9908 - val_loss: 0.1312 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 85us/step\n",
      "40000/40000 [==============================] - 3s 84us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 1.5404 - acc: 0.6513 - val_loss: 0.8412 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.6683 - acc: 0.8512 - val_loss: 0.4826 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.4752 - acc: 0.8781 - val_loss: 0.3824 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4036 - acc: 0.8910 - val_loss: 0.3362 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.3646 - acc: 0.9003 - val_loss: 0.3116 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 86us/step\n",
      "40000/40000 [==============================] - 4s 112us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.4999 - acc: 0.6747 - val_loss: 0.8253 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.6573 - acc: 0.8531 - val_loss: 0.4789 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.4700 - acc: 0.8816 - val_loss: 0.3836 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.3988 - acc: 0.8937 - val_loss: 0.3380 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.3599 - acc: 0.9026 - val_loss: 0.3108 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 91us/step\n",
      "40000/40000 [==============================] - 4s 89us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 1.5080 - acc: 0.6564 - val_loss: 0.8842 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.6669 - acc: 0.8491 - val_loss: 0.5411 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.4766 - acc: 0.8790 - val_loss: 0.4382 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.4044 - acc: 0.8920 - val_loss: 0.3870 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.3644 - acc: 0.9002 - val_loss: 0.3555 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 121us/step\n",
      "40000/40000 [==============================] - 4s 109us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.5011 - acc: 0.8499 - val_loss: 0.1877 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.2343 - acc: 0.9305 - val_loss: 0.1376 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.1755 - acc: 0.9476 - val_loss: 0.1150 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.1431 - acc: 0.9567 - val_loss: 0.1090 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.1201 - acc: 0.9633 - val_loss: 0.0953 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 59us/step\n",
      "40000/40000 [==============================] - 2s 60us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 0.4907 - acc: 0.8538 - val_loss: 0.1978 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.2275 - acc: 0.9309 - val_loss: 0.1421 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.1676 - acc: 0.9503 - val_loss: 0.1238 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.1353 - acc: 0.9589 - val_loss: 0.1070 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.1120 - acc: 0.9656 - val_loss: 0.0981 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 58us/step\n",
      "40000/40000 [==============================] - 2s 56us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.4992 - acc: 0.8518 - val_loss: 0.2371 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.2343 - acc: 0.9293 - val_loss: 0.1692 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.1713 - acc: 0.9483 - val_loss: 0.1419 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.1353 - acc: 0.9587 - val_loss: 0.1245 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.1179 - acc: 0.9639 - val_loss: 0.1207 - val_acc: 0.9646\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 52us/step\n",
      "40000/40000 [==============================] - 2s 52us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 1.8302 - acc: 0.4473 - val_loss: 1.1593 - val_acc: 0.7710\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 1.0407 - acc: 0.6999 - val_loss: 0.6364 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.7452 - acc: 0.7801 - val_loss: 0.4732 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.6232 - acc: 0.8137 - val_loss: 0.3991 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5505 - acc: 0.8359 - val_loss: 0.3569 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 58us/step\n",
      "40000/40000 [==============================] - 3s 71us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 11s - loss: 1.8089 - acc: 0.4428 - val_loss: 1.1529 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 1.0468 - acc: 0.6972 - val_loss: 0.6551 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.7669 - acc: 0.7682 - val_loss: 0.4970 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.6432 - acc: 0.8057 - val_loss: 0.4204 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.5704 - acc: 0.8305 - val_loss: 0.3762 - val_acc: 0.9005\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 49us/step\n",
      "40000/40000 [==============================] - 3s 69us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 1.7718 - acc: 0.4627 - val_loss: 1.1347 - val_acc: 0.7579\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.9909 - acc: 0.7137 - val_loss: 0.6526 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.7239 - acc: 0.7848 - val_loss: 0.5087 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.6082 - acc: 0.8179 - val_loss: 0.4441 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5405 - acc: 0.8387 - val_loss: 0.4039 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 53us/step\n",
      "40000/40000 [==============================] - 3s 76us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 0.3354 - acc: 0.8950 - val_loss: 0.1236 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.1383 - acc: 0.9580 - val_loss: 0.1169 - val_acc: 0.9664\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.0943 - acc: 0.9698 - val_loss: 0.1180 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.0695 - acc: 0.9776 - val_loss: 0.0988 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.0568 - acc: 0.9824 - val_loss: 0.0877 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 105us/step\n",
      "40000/40000 [==============================] - 4s 110us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.3284 - acc: 0.8983 - val_loss: 0.1477 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.1336 - acc: 0.9604 - val_loss: 0.1069 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.0890 - acc: 0.9722 - val_loss: 0.1137 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 8s - loss: 0.0676 - acc: 0.9794 - val_loss: 0.0910 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 8s - loss: 0.0502 - acc: 0.9842 - val_loss: 0.0971 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 113us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 5s 129us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.3283 - acc: 0.8981 - val_loss: 0.1691 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.1315 - acc: 0.9592 - val_loss: 0.1124 - val_acc: 0.9646\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.0879 - acc: 0.9725 - val_loss: 0.0987 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.0647 - acc: 0.9793 - val_loss: 0.1145 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.0527 - acc: 0.9837 - val_loss: 0.1032 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 111us/step\n",
      "40000/40000 [==============================] - 5s 121us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.6413 - acc: 0.5619 - val_loss: 0.8993 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.7842 - acc: 0.8018 - val_loss: 0.5035 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.5685 - acc: 0.8423 - val_loss: 0.3970 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4861 - acc: 0.8613 - val_loss: 0.3475 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4403 - acc: 0.8742 - val_loss: 0.3179 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 114us/step\n",
      "40000/40000 [==============================] - 4s 107us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.6052 - acc: 0.5774 - val_loss: 0.8660 - val_acc: 0.8464\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.7602 - acc: 0.8053 - val_loss: 0.4925 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.5551 - acc: 0.8448 - val_loss: 0.3904 - val_acc: 0.8972\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4792 - acc: 0.8610 - val_loss: 0.3440 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4323 - acc: 0.8773 - val_loss: 0.3154 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 90us/step\n",
      "40000/40000 [==============================] - 5s 117us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.6254 - acc: 0.5707 - val_loss: 0.9418 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.7741 - acc: 0.8029 - val_loss: 0.5580 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.5635 - acc: 0.8417 - val_loss: 0.4496 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.4823 - acc: 0.8642 - val_loss: 0.3964 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4355 - acc: 0.8744 - val_loss: 0.3661 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 111us/step\n",
      "40000/40000 [==============================] - 5s 115us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 13s - loss: 0.8054 - acc: 0.7421 - val_loss: 0.2484 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3939 - acc: 0.8851 - val_loss: 0.1880 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3148 - acc: 0.9103 - val_loss: 0.1588 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.2772 - acc: 0.9215 - val_loss: 0.1499 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2513 - acc: 0.9277 - val_loss: 0.1360 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 57us/step\n",
      "40000/40000 [==============================] - 2s 45us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.7964 - acc: 0.7456 - val_loss: 0.2495 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3923 - acc: 0.8842 - val_loss: 0.1929 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3122 - acc: 0.9095 - val_loss: 0.1636 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.2769 - acc: 0.9208 - val_loss: 0.1491 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2525 - acc: 0.9283 - val_loss: 0.1404 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 56us/step\n",
      "40000/40000 [==============================] - 3s 71us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 0.7856 - acc: 0.7514 - val_loss: 0.2842 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.3851 - acc: 0.8880 - val_loss: 0.2206 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.3105 - acc: 0.9127 - val_loss: 0.1873 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.2706 - acc: 0.9217 - val_loss: 0.1798 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2460 - acc: 0.9313 - val_loss: 0.1617 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 57us/step\n",
      "40000/40000 [==============================] - 2s 55us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.0765 - acc: 0.2694 - val_loss: 1.5479 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 1.5146 - acc: 0.5084 - val_loss: 0.9349 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 1.1616 - acc: 0.6198 - val_loss: 0.6671 - val_acc: 0.8562\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.9793 - acc: 0.6820 - val_loss: 0.5408 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.8621 - acc: 0.7234 - val_loss: 0.4698 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 65us/step\n",
      "40000/40000 [==============================] - 3s 63us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.1211 - acc: 0.2445 - val_loss: 1.6726 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 2s - loss: 1.6001 - acc: 0.4898 - val_loss: 1.0206 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 2s - loss: 1.2212 - acc: 0.6075 - val_loss: 0.7091 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.0142 - acc: 0.6760 - val_loss: 0.5652 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.8859 - acc: 0.7177 - val_loss: 0.4815 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 53us/step\n",
      "40000/40000 [==============================] - 2s 53us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.1455 - acc: 0.2350 - val_loss: 1.7538 - val_acc: 0.6586\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 3s - loss: 1.6400 - acc: 0.4640 - val_loss: 1.0983 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 3s - loss: 1.2520 - acc: 0.5917 - val_loss: 0.7830 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 3s - loss: 1.0373 - acc: 0.6643 - val_loss: 0.6324 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.9071 - acc: 0.7082 - val_loss: 0.5449 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 1s 49us/step\n",
      "40000/40000 [==============================] - 3s 72us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.4353 - acc: 0.8616 - val_loss: 0.1546 - val_acc: 0.9543\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.2093 - acc: 0.9374 - val_loss: 0.1173 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.1631 - acc: 0.9515 - val_loss: 0.1009 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 0.1379 - acc: 0.9590 - val_loss: 0.1049 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.1186 - acc: 0.9650 - val_loss: 0.1001 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 96us/step\n",
      "40000/40000 [==============================] - 5s 114us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 18s - loss: 0.4319 - acc: 0.8668 - val_loss: 0.1659 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.2034 - acc: 0.9383 - val_loss: 0.1180 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.1565 - acc: 0.9523 - val_loss: 0.1065 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.1307 - acc: 0.9614 - val_loss: 0.1022 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.1154 - acc: 0.9663 - val_loss: 0.1019 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 117us/step\n",
      "40000/40000 [==============================] - 5s 116us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 19s - loss: 0.4368 - acc: 0.8648 - val_loss: 0.2007 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.2039 - acc: 0.9392 - val_loss: 0.1381 - val_acc: 0.9596\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.1577 - acc: 0.9520 - val_loss: 0.1185 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.1301 - acc: 0.9608 - val_loss: 0.1113 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.1133 - acc: 0.9666 - val_loss: 0.1224 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 113us/step\n",
      "40000/40000 [==============================] - 4s 105us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 17s - loss: 1.8236 - acc: 0.4044 - val_loss: 1.0531 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 1.0526 - acc: 0.6837 - val_loss: 0.5871 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.7832 - acc: 0.7560 - val_loss: 0.4506 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.6569 - acc: 0.7971 - val_loss: 0.3884 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.5867 - acc: 0.8192 - val_loss: 0.3499 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 125us/step\n",
      "40000/40000 [==============================] - 4s 111us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.8315 - acc: 0.4088 - val_loss: 1.0546 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 1.0426 - acc: 0.6909 - val_loss: 0.5828 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.7728 - acc: 0.7621 - val_loss: 0.4498 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.6514 - acc: 0.7985 - val_loss: 0.3866 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.5790 - acc: 0.8223 - val_loss: 0.3486 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 83us/step\n",
      "40000/40000 [==============================] - 4s 96us/step\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      " - 16s - loss: 1.8174 - acc: 0.4179 - val_loss: 1.0885 - val_acc: 0.8021\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 7s - loss: 1.0450 - acc: 0.6852 - val_loss: 0.6317 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.7700 - acc: 0.7645 - val_loss: 0.4955 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.6559 - acc: 0.7991 - val_loss: 0.4296 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.5715 - acc: 0.8284 - val_loss: 0.3921 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "20000/20000 [==============================] - 2s 81us/step\n",
      "40000/40000 [==============================] - 3s 85us/step\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " - 27s - loss: 0.2190 - acc: 0.9328 - val_loss: 0.1174 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/5\n",
      " - 18s - loss: 0.0896 - acc: 0.9729 - val_loss: 0.1258 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 16s - loss: 0.0623 - acc: 0.9821 - val_loss: 0.1026 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 16s - loss: 0.0473 - acc: 0.9857 - val_loss: 0.1122 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 16s - loss: 0.0379 - acc: 0.9891 - val_loss: 0.1153 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "CPU times: user 4h 19min 14s, sys: 25min 3s, total: 4h 44min 18s\n",
      "Wall time: 4h 35min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath = 'mnist.model.best.hdf5',\n",
    "                               verbose = 1, \n",
    "                               save_best_only = True)\n",
    "grid_result  = grid.fit(X_train, y_train, \n",
    "                        callbacks = [checkpointer],\n",
    "                        verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.973500 using {'activation': 'relu', 'batch_size': 64, 'dropout': 0.0, 'epochs': 5, 'neurons': 512, 'optimizer': 'rmsprop', 'validation_split': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Load the Model with the Best Classification Accuracy on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_weights\n",
      "optimizer_weights\n",
      "training_212\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_name = 'mnist.model.best.hdf5'\n",
    "f = h5py.File(file_name, 'r')\n",
    "for key in f.keys():\n",
    "    print(key)\n",
    "    \n",
    "# List all groups\n",
    "group = f[key]\n",
    "#Checkout what keys are inside that group.\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Get the data\n",
    "data = group['training_212']\n",
    "#Do whatever you want with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "c_m = create_model(activation = 'relu', dropout = 0.0, \n",
    "                 neurons = 512, optimizer = 'rmsprop')\n",
    "c_m.load_weights('mnist.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the Classification Accuracy on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.7000%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "score = c_m.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
