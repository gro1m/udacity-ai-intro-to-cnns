
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{mnist\_mlp}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Artificial Intelligence
Nanodegree}\label{artificial-intelligence-nanodegree}

\subsection{Convolutional Neural
Networks}\label{convolutional-neural-networks}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

In this notebook, we train an MLP to classify images from the MNIST
database.

\subsubsection{1. Load MNIST Database}\label{load-mnist-database}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{mnist}
        
        \PY{c+c1}{\PYZsh{} use Keras to import pre\PYZhy{}shuffled MNIST database}
        \PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)} \PY{o}{=} \PY{n}{mnist}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The MNIST database has a training set of }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s2}{ examples.}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The MNIST database has a test set of }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s2}{ examples.}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/anaconda3/lib/python3.6/site-packages/h5py/\_\_init\_\_.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from .\_conv import register\_converters as \_register\_converters
Using TensorFlow backend.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
The MNIST database has a training set of 60000 examples.
The MNIST database has a test set of 10000 examples.

    \end{Verbatim}

    \subsubsection{2. Visualize the First Six Training
Images}\label{visualize-the-first-six-training-images}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{cm} \PY{k}{as} \PY{n+nn}{cm}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{c+c1}{\PYZsh{} plot first six training images}
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
            \PY{n}{ax} \PY{o}{=} \PY{n}{fig}\PY{o}{.}\PY{n}{add\PYZus{}subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{xticks}\PY{o}{=}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{n}{yticks}\PY{o}{=}\PY{p}{[}\PY{p}{]}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_3_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{3. View an Image in More
Detail}\label{view-an-image-in-more-detail}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k}{def} \PY{n+nf}{visualize\PYZus{}input}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{ax}\PY{p}{)}\PY{p}{:}
            \PY{n}{ax}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{n\PYZus{}rows}\PY{p}{,} \PY{n}{n\PYZus{}cols} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{shape}
            \PY{n}{thresh} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}\PY{o}{/}\PY{l+m+mf}{2.5}
            \PY{n}{height\PYZus{}range} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}
            \PY{k}{for} \PY{n}{r} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}rows}\PY{p}{)}\PY{p}{:}
                \PY{k}{for} \PY{n}{c} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}cols}\PY{p}{)}\PY{p}{:}
                    \PY{n}{str\PYZus{}x\PYZus{}y} \PY{o}{=} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{img}\PY{p}{[}\PY{n}{r}\PY{p}{]}\PY{p}{[}\PY{n}{c}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
                    \PY{n}{ax}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{n}{str\PYZus{}x\PYZus{}y}\PY{p}{,} \PY{n}{xy}\PY{o}{=}\PY{p}{(}\PY{n}{c}\PY{p}{,}\PY{n}{r}\PY{p}{)}\PY{p}{,}
                                \PY{n}{horizontalalignment}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                \PY{n}{verticalalignment}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{white}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{img}\PY{p}{[}\PY{n}{r}\PY{p}{]}\PY{p}{[}\PY{n}{c}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{n}{thresh} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{)} 
        \PY{n}{ax} \PY{o}{=} \PY{n}{fig}\PY{o}{.}\PY{n}{add\PYZus{}subplot}\PY{p}{(}\PY{l+m+mi}{111}\PY{p}{)}
        \PY{n}{visualize\PYZus{}input}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{ax}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{4. Rescale the Images by Dividing Every Pixel in Every
Image by
255}\label{rescale-the-images-by-dividing-every-pixel-in-every-image-by-255}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} rescale [0,255] \PYZhy{}\PYZhy{}\PYZgt{} [0,1]}
        \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{255}
        \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{255} 
\end{Verbatim}


    \subsubsection{5. Encode Categorical Integer Labels Using a One-Hot
Scheme}\label{encode-categorical-integer-labels-using-a-one-hot-scheme}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{np\PYZus{}utils}
        
        \PY{c+c1}{\PYZsh{} print first ten (integer\PYZhy{}valued) training labels}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Integer\PYZhy{}valued labels:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} one\PYZhy{}hot encode the labels}
        \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{np\PYZus{}utils}\PY{o}{.}\PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
        \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{np\PYZus{}utils}\PY{o}{.}\PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} print first ten (one\PYZhy{}hot) training labels}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{One\PYZhy{}hot labels:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Integer-valued labels:
[5 0 4 1 9 2 1 3 1 4]
One-hot labels:
[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]

    \end{Verbatim}

    \subsubsection{6. Define the Model
Architecture}\label{define-the-model-architecture}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}\PY{p}{,} \PY{n}{Flatten}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{wrappers}\PY{n+nn}{.}\PY{n+nn}{scikit\PYZus{}learn} \PY{k}{import} \PY{n}{KerasClassifier}
        
        \PY{k}{def} \PY{n+nf}{create\PYZus{}model}\PY{p}{(}\PY{n}{activation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{dropout} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{,} 
                         \PY{n}{neurons} \PY{o}{=} \PY{l+m+mi}{512}\PY{p}{,} \PY{n}{optimizer} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} define the model}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{flatten1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{neurons}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{activation}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dense1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{n}{dropout}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dropout1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{neurons}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{activation}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{activation1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{n}{dropout}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dropout2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{activation2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} summarize the model}
            \PY{c+c1}{\PYZsh{}model.summary()}
        
            \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} 7. Compile the Model}
        
            \PY{c+c1}{\PYZsh{} compile the model}
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                          \PY{n}{optimizer}\PY{o}{=}\PY{n}{optimizer}\PY{p}{,} 
                          \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{model}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{create\PYZus{}model}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{layers}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{weights}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{name}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}10}]:} 'dense1/bias:0'
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{model} \PY{o}{=} \PY{n}{KerasClassifier}\PY{p}{(}\PY{n}{build\PYZus{}fn} \PY{o}{=} \PY{n}{create\PYZus{}model}\PY{p}{)}
\end{Verbatim}


    \subsubsection{8. Calculate the Classification Accuracy on the Test Set
(Before
Training)}\label{calculate-the-classification-accuracy-on-the-test-set-before-training}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} evaluate test accuracy}
         \PY{n}{score} \PY{o}{=} \PY{n}{create\PYZus{}model}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{accuracy} \PY{o}{=} \PY{l+m+mi}{100}\PY{o}{*}\PY{n}{score}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} print test accuracy}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy: }\PY{l+s+si}{\PYZpc{}.4f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{accuracy}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Test accuracy: 13.2200\%

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{neurons}          \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{512}\PY{p}{]}
         \PY{n}{dropout}          \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{]}
         \PY{n}{activation}       \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{optimizer}        \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sgd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{batch\PYZus{}size}       \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+m+mi}{128}\PY{p}{]}
         \PY{n}{epochs}           \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}
         \PY{n}{validation\PYZus{}split} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.2}\PY{p}{]}
         \PY{n}{param\PYZus{}grid}       \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{neurons}          \PY{o}{=} \PY{n}{neurons}\PY{p}{,} 
                                 \PY{n}{dropout}          \PY{o}{=} \PY{n}{dropout}\PY{p}{,} 
                                 \PY{n}{epochs}           \PY{o}{=} \PY{n}{epochs}\PY{p}{,} 
                                 \PY{n}{validation\PYZus{}split} \PY{o}{=} \PY{n}{validation\PYZus{}split}\PY{p}{,}
                                 \PY{n}{activation}       \PY{o}{=} \PY{n}{activation}\PY{p}{,}
                                 \PY{n}{optimizer}        \PY{o}{=} \PY{n}{optimizer}\PY{p}{,} 
                                 \PY{n}{batch\PYZus{}size}       \PY{o}{=} \PY{n}{batch\PYZus{}size}\PY{p}{)}
         \PY{n}{grid}             \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{estimator}  \PY{o}{=} \PY{n}{model}\PY{p}{,} 
                                         \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{n}{param\PYZus{}grid}\PY{p}{,}
                                         \PY{n}{n\PYZus{}jobs}     \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{}optimizer[0].get\PYZus{}weights()}
\end{Verbatim}


    \subsubsection{9. Train the Model}\label{train-the-model}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time}
         from keras.callbacks import ModelCheckpoint   
         
         \PYZsh{} train the model
         checkpointer = ModelCheckpoint(filepath = \PYZsq{}mnist.model.best.hdf5\PYZsq{},
                                        verbose = 1, 
                                        save\PYZus{}best\PYZus{}only = True)
         grid\PYZus{}result  = grid.fit(X\PYZus{}train, y\PYZus{}train, 
                                 callbacks = [checkpointer],
                                 verbose = 2, shuffle = True)
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 3s - loss: 0.4212 - acc: 0.8773 - val\_loss: 0.3097 - val\_acc: 0.9110

Epoch 00001: val\_loss improved from inf to 0.30969, saving model to mnist.model.best.hdf5
Epoch 2/5
 - 2s - loss: 0.3342 - acc: 0.9043 - val\_loss: 0.2933 - val\_acc: 0.9149

Epoch 00002: val\_loss improved from 0.30969 to 0.29332, saving model to mnist.model.best.hdf5
Epoch 3/5
 - 2s - loss: 0.3180 - acc: 0.9106 - val\_loss: 0.3019 - val\_acc: 0.9153

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3066 - acc: 0.9133 - val\_loss: 0.2770 - val\_acc: 0.9217

Epoch 00004: val\_loss improved from 0.29332 to 0.27695, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 3s - loss: 0.3007 - acc: 0.9130 - val\_loss: 0.2805 - val\_acc: 0.9227

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 29us/step
40000/40000 [==============================] - 1s 29us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 3s - loss: 0.4141 - acc: 0.8798 - val\_loss: 0.2943 - val\_acc: 0.9179

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3253 - acc: 0.9072 - val\_loss: 0.3094 - val\_acc: 0.9114

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3110 - acc: 0.9133 - val\_loss: 0.3135 - val\_acc: 0.9154

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3007 - acc: 0.9150 - val\_loss: 0.2780 - val\_acc: 0.9210

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.2925 - acc: 0.9189 - val\_loss: 0.2905 - val\_acc: 0.9190

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 29us/step
40000/40000 [==============================] - 1s 29us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 3s - loss: 0.4111 - acc: 0.8808 - val\_loss: 0.3453 - val\_acc: 0.9015

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.3240 - acc: 0.9090 - val\_loss: 0.3403 - val\_acc: 0.9074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3074 - acc: 0.9132 - val\_loss: 0.3203 - val\_acc: 0.9100

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3002 - acc: 0.9168 - val\_loss: 0.3686 - val\_acc: 0.9001

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.2926 - acc: 0.9189 - val\_loss: 0.3256 - val\_acc: 0.9123

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 38us/step
40000/40000 [==============================] - 1s 30us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 3s - loss: 0.8256 - acc: 0.7789 - val\_loss: 0.4344 - val\_acc: 0.8881

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4339 - acc: 0.8807 - val\_loss: 0.3502 - val\_acc: 0.9030

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3783 - acc: 0.8936 - val\_loss: 0.3248 - val\_acc: 0.9076

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3528 - acc: 0.8997 - val\_loss: 0.3081 - val\_acc: 0.9120

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3378 - acc: 0.9042 - val\_loss: 0.3012 - val\_acc: 0.9139

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 29us/step
40000/40000 [==============================] - 1s 29us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 3s - loss: 0.8173 - acc: 0.7846 - val\_loss: 0.4358 - val\_acc: 0.8809

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4313 - acc: 0.8792 - val\_loss: 0.3508 - val\_acc: 0.9010

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3740 - acc: 0.8938 - val\_loss: 0.3237 - val\_acc: 0.9071

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3471 - acc: 0.9015 - val\_loss: 0.3054 - val\_acc: 0.9121

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3309 - acc: 0.9057 - val\_loss: 0.2981 - val\_acc: 0.9163

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 33us/step
40000/40000 [==============================] - 1s 30us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.8105 - acc: 0.7916 - val\_loss: 0.4903 - val\_acc: 0.8670

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4281 - acc: 0.8825 - val\_loss: 0.4024 - val\_acc: 0.8852

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3733 - acc: 0.8943 - val\_loss: 0.3694 - val\_acc: 0.8920

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3478 - acc: 0.9008 - val\_loss: 0.3556 - val\_acc: 0.8966

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.3316 - acc: 0.9064 - val\_loss: 0.3438 - val\_acc: 0.9001

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 53us/step
40000/40000 [==============================] - 2s 39us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.4968 - acc: 0.8543 - val\_loss: 0.3261 - val\_acc: 0.9060

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.3900 - acc: 0.8905 - val\_loss: 0.3236 - val\_acc: 0.9061

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.3573 - acc: 0.8964 - val\_loss: 0.3017 - val\_acc: 0.9154

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.3396 - acc: 0.9017 - val\_loss: 0.3115 - val\_acc: 0.9176

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3278 - acc: 0.9060 - val\_loss: 0.3086 - val\_acc: 0.9149

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 74us/step
40000/40000 [==============================] - 3s 81us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.4919 - acc: 0.8575 - val\_loss: 0.3416 - val\_acc: 0.9073

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.3789 - acc: 0.8927 - val\_loss: 0.3070 - val\_acc: 0.9126

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.3500 - acc: 0.9008 - val\_loss: 0.3359 - val\_acc: 0.9054

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 0.3307 - acc: 0.9068 - val\_loss: 0.3022 - val\_acc: 0.9173

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.3204 - acc: 0.9100 - val\_loss: 0.3182 - val\_acc: 0.9123

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 116us/step
40000/40000 [==============================] - 4s 90us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.4908 - acc: 0.8597 - val\_loss: 0.5064 - val\_acc: 0.8641

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.3803 - acc: 0.8933 - val\_loss: 0.4078 - val\_acc: 0.8825

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.3506 - acc: 0.9008 - val\_loss: 0.3526 - val\_acc: 0.9049

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.3317 - acc: 0.9069 - val\_loss: 0.3369 - val\_acc: 0.9071

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3203 - acc: 0.9092 - val\_loss: 0.3367 - val\_acc: 0.9126

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 85us/step
40000/40000 [==============================] - 3s 74us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.7169 - acc: 0.8153 - val\_loss: 0.3887 - val\_acc: 0.8956

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4026 - acc: 0.8884 - val\_loss: 0.3268 - val\_acc: 0.9101

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.3589 - acc: 0.8989 - val\_loss: 0.3056 - val\_acc: 0.9144

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.3383 - acc: 0.9046 - val\_loss: 0.2974 - val\_acc: 0.9171

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3253 - acc: 0.9082 - val\_loss: 0.2876 - val\_acc: 0.9200

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 70us/step
40000/40000 [==============================] - 3s 79us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.7106 - acc: 0.8204 - val\_loss: 0.3914 - val\_acc: 0.8946

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.3991 - acc: 0.8892 - val\_loss: 0.3312 - val\_acc: 0.9071

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.3541 - acc: 0.9008 - val\_loss: 0.3082 - val\_acc: 0.9135

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.3322 - acc: 0.9062 - val\_loss: 0.2966 - val\_acc: 0.9177

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3186 - acc: 0.9102 - val\_loss: 0.2892 - val\_acc: 0.9181

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 89us/step
40000/40000 [==============================] - 3s 76us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.7012 - acc: 0.8258 - val\_loss: 0.4461 - val\_acc: 0.8781

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.3996 - acc: 0.8899 - val\_loss: 0.3788 - val\_acc: 0.8926

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.3553 - acc: 0.9008 - val\_loss: 0.3537 - val\_acc: 0.8971

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3331 - acc: 0.9073 - val\_loss: 0.3406 - val\_acc: 0.9019

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3191 - acc: 0.9110 - val\_loss: 0.3325 - val\_acc: 0.9066

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 86us/step
40000/40000 [==============================] - 3s 71us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4708 - acc: 0.8595 - val\_loss: 0.3027 - val\_acc: 0.9117

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3772 - acc: 0.8900 - val\_loss: 0.2801 - val\_acc: 0.9223

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3570 - acc: 0.8963 - val\_loss: 0.2950 - val\_acc: 0.9174

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3420 - acc: 0.9030 - val\_loss: 0.2743 - val\_acc: 0.9234

Epoch 00004: val\_loss improved from 0.27695 to 0.27431, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 3s - loss: 0.3390 - acc: 0.9048 - val\_loss: 0.2706 - val\_acc: 0.9266

Epoch 00005: val\_loss improved from 0.27431 to 0.27059, saving model to mnist.model.best.hdf5
20000/20000 [==============================] - 1s 37us/step
40000/40000 [==============================] - 1s 34us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4679 - acc: 0.8616 - val\_loss: 0.2923 - val\_acc: 0.9165

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3621 - acc: 0.8967 - val\_loss: 0.2886 - val\_acc: 0.9207

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3489 - acc: 0.9015 - val\_loss: 0.3008 - val\_acc: 0.9160

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3383 - acc: 0.9040 - val\_loss: 0.2697 - val\_acc: 0.9251

Epoch 00004: val\_loss improved from 0.27059 to 0.26966, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 3s - loss: 0.3280 - acc: 0.9089 - val\_loss: 0.2767 - val\_acc: 0.9263

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 41us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4714 - acc: 0.8625 - val\_loss: 0.3540 - val\_acc: 0.9006

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3687 - acc: 0.8941 - val\_loss: 0.3273 - val\_acc: 0.9109

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3447 - acc: 0.9028 - val\_loss: 0.3296 - val\_acc: 0.9119

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3337 - acc: 0.9065 - val\_loss: 0.3347 - val\_acc: 0.9106

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.3292 - acc: 0.9091 - val\_loss: 0.3390 - val\_acc: 0.9032

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 36us/step
40000/40000 [==============================] - 1s 36us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.9142 - acc: 0.7320 - val\_loss: 0.4388 - val\_acc: 0.8835

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.4944 - acc: 0.8558 - val\_loss: 0.3532 - val\_acc: 0.9008

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4308 - acc: 0.8729 - val\_loss: 0.3246 - val\_acc: 0.9085

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.4028 - acc: 0.8809 - val\_loss: 0.3093 - val\_acc: 0.9115

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.3897 - acc: 0.8842 - val\_loss: 0.3006 - val\_acc: 0.9149

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 36us/step
40000/40000 [==============================] - 1s 37us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.9191 - acc: 0.7363 - val\_loss: 0.4444 - val\_acc: 0.8850

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.4905 - acc: 0.8556 - val\_loss: 0.3528 - val\_acc: 0.9025

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4245 - acc: 0.8755 - val\_loss: 0.3249 - val\_acc: 0.9071

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3955 - acc: 0.8850 - val\_loss: 0.3084 - val\_acc: 0.9135

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.3801 - acc: 0.8904 - val\_loss: 0.2992 - val\_acc: 0.9145

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 48us/step
40000/40000 [==============================] - 2s 38us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.8718 - acc: 0.7455 - val\_loss: 0.4833 - val\_acc: 0.8732

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.4803 - acc: 0.8609 - val\_loss: 0.3984 - val\_acc: 0.8886

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4219 - acc: 0.8767 - val\_loss: 0.3668 - val\_acc: 0.8969

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.3983 - acc: 0.8849 - val\_loss: 0.3521 - val\_acc: 0.9006

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.3787 - acc: 0.8890 - val\_loss: 0.3428 - val\_acc: 0.9038

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 36us/step
40000/40000 [==============================] - 2s 41us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.5165 - acc: 0.8503 - val\_loss: 0.3921 - val\_acc: 0.8969

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 0.4261 - acc: 0.8811 - val\_loss: 0.3402 - val\_acc: 0.9075

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.3934 - acc: 0.8890 - val\_loss: 0.3099 - val\_acc: 0.9175

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 0.3786 - acc: 0.8929 - val\_loss: 0.2943 - val\_acc: 0.9173

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3640 - acc: 0.8979 - val\_loss: 0.3067 - val\_acc: 0.9183

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 89us/step
40000/40000 [==============================] - 3s 75us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.5043 - acc: 0.8563 - val\_loss: 0.3433 - val\_acc: 0.9028

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 0.4150 - acc: 0.8841 - val\_loss: 0.3388 - val\_acc: 0.9070

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.3849 - acc: 0.8908 - val\_loss: 0.3343 - val\_acc: 0.9079

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 0.3662 - acc: 0.8987 - val\_loss: 0.3423 - val\_acc: 0.9055

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3584 - acc: 0.8994 - val\_loss: 0.3086 - val\_acc: 0.9176

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 93us/step
40000/40000 [==============================] - 3s 86us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.5049 - acc: 0.8565 - val\_loss: 0.4132 - val\_acc: 0.8870

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 0.4136 - acc: 0.8863 - val\_loss: 0.4089 - val\_acc: 0.8909

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.3827 - acc: 0.8942 - val\_loss: 0.3677 - val\_acc: 0.8994

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.3650 - acc: 0.8994 - val\_loss: 0.4008 - val\_acc: 0.8914

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3551 - acc: 0.9012 - val\_loss: 0.3694 - val\_acc: 0.9002

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 77us/step
40000/40000 [==============================] - 4s 93us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.7537 - acc: 0.7925 - val\_loss: 0.3924 - val\_acc: 0.8938

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4328 - acc: 0.8772 - val\_loss: 0.3306 - val\_acc: 0.9079

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.3849 - acc: 0.8889 - val\_loss: 0.3083 - val\_acc: 0.9121

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3621 - acc: 0.8957 - val\_loss: 0.2960 - val\_acc: 0.9171

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3484 - acc: 0.9003 - val\_loss: 0.2896 - val\_acc: 0.9165

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 76us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.7527 - acc: 0.7905 - val\_loss: 0.3890 - val\_acc: 0.8980

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.4234 - acc: 0.8776 - val\_loss: 0.3303 - val\_acc: 0.9095

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.3788 - acc: 0.8911 - val\_loss: 0.3109 - val\_acc: 0.9125

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3560 - acc: 0.8976 - val\_loss: 0.2981 - val\_acc: 0.9144

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3423 - acc: 0.9015 - val\_loss: 0.2896 - val\_acc: 0.9187

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 75us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.7549 - acc: 0.7903 - val\_loss: 0.4484 - val\_acc: 0.8751

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.4307 - acc: 0.8760 - val\_loss: 0.3809 - val\_acc: 0.8911

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.3800 - acc: 0.8901 - val\_loss: 0.3558 - val\_acc: 0.8951

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.3589 - acc: 0.8979 - val\_loss: 0.3428 - val\_acc: 0.8984

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3453 - acc: 0.9008 - val\_loss: 0.3346 - val\_acc: 0.9016

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 72us/step
40000/40000 [==============================] - 4s 93us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6522 - acc: 0.7994 - val\_loss: 0.3094 - val\_acc: 0.9140

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.4892 - acc: 0.8596 - val\_loss: 0.2868 - val\_acc: 0.9189

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4539 - acc: 0.8693 - val\_loss: 0.2960 - val\_acc: 0.9179

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.4359 - acc: 0.8747 - val\_loss: 0.2858 - val\_acc: 0.9181

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.4241 - acc: 0.8817 - val\_loss: 0.2790 - val\_acc: 0.9227

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 34us/step
40000/40000 [==============================] - 1s 33us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6508 - acc: 0.8022 - val\_loss: 0.3011 - val\_acc: 0.9144

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.4844 - acc: 0.8609 - val\_loss: 0.3079 - val\_acc: 0.9151

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4412 - acc: 0.8732 - val\_loss: 0.2873 - val\_acc: 0.9203

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.4271 - acc: 0.8795 - val\_loss: 0.2766 - val\_acc: 0.9234

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4118 - acc: 0.8843 - val\_loss: 0.2843 - val\_acc: 0.9199

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 1s 35us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6469 - acc: 0.8028 - val\_loss: 0.3601 - val\_acc: 0.8974

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.4865 - acc: 0.8609 - val\_loss: 0.3414 - val\_acc: 0.9041

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.4488 - acc: 0.8731 - val\_loss: 0.3429 - val\_acc: 0.9034

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.4294 - acc: 0.8815 - val\_loss: 0.3419 - val\_acc: 0.9029

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4131 - acc: 0.8846 - val\_loss: 0.3400 - val\_acc: 0.9032

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 42us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.1463 - acc: 0.6245 - val\_loss: 0.4705 - val\_acc: 0.8799

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.6663 - acc: 0.7915 - val\_loss: 0.3727 - val\_acc: 0.8988

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.5786 - acc: 0.8221 - val\_loss: 0.3377 - val\_acc: 0.9046

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.5360 - acc: 0.8387 - val\_loss: 0.3243 - val\_acc: 0.9069

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4998 - acc: 0.8498 - val\_loss: 0.3138 - val\_acc: 0.9110

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 62us/step
40000/40000 [==============================] - 2s 39us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.0991 - acc: 0.6365 - val\_loss: 0.4436 - val\_acc: 0.8831

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.6378 - acc: 0.7976 - val\_loss: 0.3609 - val\_acc: 0.9011

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.5620 - acc: 0.8249 - val\_loss: 0.3345 - val\_acc: 0.9070

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.5111 - acc: 0.8459 - val\_loss: 0.3215 - val\_acc: 0.9095

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4979 - acc: 0.8493 - val\_loss: 0.3119 - val\_acc: 0.9135

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 50us/step
40000/40000 [==============================] - 1s 37us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.0829 - acc: 0.6425 - val\_loss: 0.5122 - val\_acc: 0.8629

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.6463 - acc: 0.8003 - val\_loss: 0.4174 - val\_acc: 0.8825

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.5701 - acc: 0.8287 - val\_loss: 0.3829 - val\_acc: 0.8891

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.5245 - acc: 0.8422 - val\_loss: 0.3679 - val\_acc: 0.8942

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4944 - acc: 0.8533 - val\_loss: 0.3564 - val\_acc: 0.8960

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 42us/step
40000/40000 [==============================] - 2s 41us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 0.5994 - acc: 0.8297 - val\_loss: 0.3294 - val\_acc: 0.9097

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.5008 - acc: 0.8659 - val\_loss: 0.3212 - val\_acc: 0.9190

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.4659 - acc: 0.8737 - val\_loss: 0.3174 - val\_acc: 0.9126

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.4421 - acc: 0.8795 - val\_loss: 0.3366 - val\_acc: 0.9094

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.4274 - acc: 0.8827 - val\_loss: 0.3071 - val\_acc: 0.9165

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 80us/step
40000/40000 [==============================] - 4s 104us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.5948 - acc: 0.8336 - val\_loss: 0.3289 - val\_acc: 0.9126

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.4881 - acc: 0.8685 - val\_loss: 0.3201 - val\_acc: 0.9163

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.4598 - acc: 0.8792 - val\_loss: 0.3134 - val\_acc: 0.9137

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.4350 - acc: 0.8833 - val\_loss: 0.2999 - val\_acc: 0.9161

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.4164 - acc: 0.8867 - val\_loss: 0.3220 - val\_acc: 0.9114

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 94us/step
40000/40000 [==============================] - 4s 111us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 0.5880 - acc: 0.8383 - val\_loss: 0.4432 - val\_acc: 0.8820

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.4913 - acc: 0.8725 - val\_loss: 0.3964 - val\_acc: 0.9000

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.4474 - acc: 0.8798 - val\_loss: 0.4009 - val\_acc: 0.9005

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.4328 - acc: 0.8854 - val\_loss: 0.4216 - val\_acc: 0.8871

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.4129 - acc: 0.8896 - val\_loss: 0.4038 - val\_acc: 0.8950

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 74us/step
40000/40000 [==============================] - 4s 90us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.8916 - acc: 0.7166 - val\_loss: 0.3927 - val\_acc: 0.8966

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.5184 - acc: 0.8427 - val\_loss: 0.3321 - val\_acc: 0.9084

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.4561 - acc: 0.8639 - val\_loss: 0.3129 - val\_acc: 0.9077

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4304 - acc: 0.8704 - val\_loss: 0.3040 - val\_acc: 0.9144

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4094 - acc: 0.8780 - val\_loss: 0.2932 - val\_acc: 0.9163

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 88us/step
40000/40000 [==============================] - 3s 71us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.8697 - acc: 0.7243 - val\_loss: 0.3894 - val\_acc: 0.8905

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.5016 - acc: 0.8458 - val\_loss: 0.3304 - val\_acc: 0.9050

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.4445 - acc: 0.8657 - val\_loss: 0.3111 - val\_acc: 0.9093

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4236 - acc: 0.8729 - val\_loss: 0.2996 - val\_acc: 0.9125

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4018 - acc: 0.8813 - val\_loss: 0.2950 - val\_acc: 0.9160

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 73us/step
40000/40000 [==============================] - 3s 74us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.8743 - acc: 0.7220 - val\_loss: 0.4406 - val\_acc: 0.8778

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.5014 - acc: 0.8472 - val\_loss: 0.3782 - val\_acc: 0.8914

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.4471 - acc: 0.8675 - val\_loss: 0.3556 - val\_acc: 0.8964

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4202 - acc: 0.8770 - val\_loss: 0.3440 - val\_acc: 0.8994

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4037 - acc: 0.8818 - val\_loss: 0.3326 - val\_acc: 0.9031

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 73us/step
40000/40000 [==============================] - 3s 82us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4412 - acc: 0.8706 - val\_loss: 0.2970 - val\_acc: 0.9126

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 1s - loss: 0.3293 - acc: 0.9055 - val\_loss: 0.2774 - val\_acc: 0.9230

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3107 - acc: 0.9103 - val\_loss: 0.2779 - val\_acc: 0.9215

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3007 - acc: 0.9158 - val\_loss: 0.2744 - val\_acc: 0.9209

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.2940 - acc: 0.9158 - val\_loss: 0.2676 - val\_acc: 0.9246

Epoch 00005: val\_loss improved from 0.26966 to 0.26763, saving model to mnist.model.best.hdf5
20000/20000 [==============================] - 0s 22us/step
40000/40000 [==============================] - 1s 27us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4388 - acc: 0.8701 - val\_loss: 0.3155 - val\_acc: 0.9116

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 1s - loss: 0.3186 - acc: 0.9102 - val\_loss: 0.2961 - val\_acc: 0.9174

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3047 - acc: 0.9147 - val\_loss: 0.2824 - val\_acc: 0.9239

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.2935 - acc: 0.9166 - val\_loss: 0.2816 - val\_acc: 0.9243

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.2866 - acc: 0.9197 - val\_loss: 0.2967 - val\_acc: 0.9164

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 29us/step
40000/40000 [==============================] - 1s 30us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4330 - acc: 0.8746 - val\_loss: 0.3474 - val\_acc: 0.9055

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.3188 - acc: 0.9097 - val\_loss: 0.3289 - val\_acc: 0.9081

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3033 - acc: 0.9145 - val\_loss: 0.3333 - val\_acc: 0.9073

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.2917 - acc: 0.9173 - val\_loss: 0.3332 - val\_acc: 0.9076

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.2864 - acc: 0.9204 - val\_loss: 0.3263 - val\_acc: 0.9096

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 23us/step
40000/40000 [==============================] - 1s 22us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 1.1173 - acc: 0.7075 - val\_loss: 0.5979 - val\_acc: 0.8621

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 1s - loss: 0.5584 - acc: 0.8549 - val\_loss: 0.4315 - val\_acc: 0.8858

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4562 - acc: 0.8742 - val\_loss: 0.3759 - val\_acc: 0.8982

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4118 - acc: 0.8845 - val\_loss: 0.3477 - val\_acc: 0.9045

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 1s - loss: 0.3862 - acc: 0.8906 - val\_loss: 0.3311 - val\_acc: 0.9064

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 22us/step
40000/40000 [==============================] - 1s 22us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 1.0858 - acc: 0.7101 - val\_loss: 0.5933 - val\_acc: 0.8564

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.5514 - acc: 0.8551 - val\_loss: 0.4329 - val\_acc: 0.8900

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4513 - acc: 0.8771 - val\_loss: 0.3775 - val\_acc: 0.9001

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4060 - acc: 0.8872 - val\_loss: 0.3483 - val\_acc: 0.9058

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 1s - loss: 0.3795 - acc: 0.8949 - val\_loss: 0.3319 - val\_acc: 0.9097

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 23us/step
40000/40000 [==============================] - 1s 22us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 1.1155 - acc: 0.7107 - val\_loss: 0.6646 - val\_acc: 0.8353

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.5534 - acc: 0.8553 - val\_loss: 0.4955 - val\_acc: 0.8652

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4506 - acc: 0.8764 - val\_loss: 0.4334 - val\_acc: 0.8801

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 1s - loss: 0.4055 - acc: 0.8858 - val\_loss: 0.4017 - val\_acc: 0.8878

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 1s - loss: 0.3790 - acc: 0.8917 - val\_loss: 0.3814 - val\_acc: 0.8926

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 23us/step
40000/40000 [==============================] - 1s 21us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.4995 - acc: 0.8510 - val\_loss: 0.3256 - val\_acc: 0.9055

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.3856 - acc: 0.8864 - val\_loss: 0.3457 - val\_acc: 0.8998

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.3624 - acc: 0.8972 - val\_loss: 0.3102 - val\_acc: 0.9143

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.3390 - acc: 0.9027 - val\_loss: 0.2843 - val\_acc: 0.9189

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.3287 - acc: 0.9058 - val\_loss: 0.2963 - val\_acc: 0.9193

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 55us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.4858 - acc: 0.8574 - val\_loss: 0.3175 - val\_acc: 0.9131

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.3772 - acc: 0.8921 - val\_loss: 0.3370 - val\_acc: 0.9039

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.3495 - acc: 0.9014 - val\_loss: 0.3301 - val\_acc: 0.9104

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.3278 - acc: 0.9063 - val\_loss: 0.2754 - val\_acc: 0.9211

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.3159 - acc: 0.9098 - val\_loss: 0.3138 - val\_acc: 0.9096

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 63us/step
40000/40000 [==============================] - 2s 55us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.4861 - acc: 0.8554 - val\_loss: 0.4335 - val\_acc: 0.8829

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.3758 - acc: 0.8936 - val\_loss: 0.4149 - val\_acc: 0.8756

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.3460 - acc: 0.9011 - val\_loss: 0.3622 - val\_acc: 0.9019

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.3286 - acc: 0.9059 - val\_loss: 0.3428 - val\_acc: 0.9073

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.3178 - acc: 0.9118 - val\_loss: 0.3702 - val\_acc: 0.8921

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 54us/step
40000/40000 [==============================] - 3s 65us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 0.9275 - acc: 0.7738 - val\_loss: 0.5080 - val\_acc: 0.8764

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.4933 - acc: 0.8685 - val\_loss: 0.3958 - val\_acc: 0.8950

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.4204 - acc: 0.8840 - val\_loss: 0.3539 - val\_acc: 0.9018

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.3865 - acc: 0.8908 - val\_loss: 0.3327 - val\_acc: 0.9055

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.3660 - acc: 0.8957 - val\_loss: 0.3189 - val\_acc: 0.9076

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 55us/step
40000/40000 [==============================] - 2s 62us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 0.9432 - acc: 0.7571 - val\_loss: 0.5046 - val\_acc: 0.8731

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.4876 - acc: 0.8689 - val\_loss: 0.3917 - val\_acc: 0.8936

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.4136 - acc: 0.8867 - val\_loss: 0.3521 - val\_acc: 0.9014

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.3794 - acc: 0.8938 - val\_loss: 0.3301 - val\_acc: 0.9080

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.3588 - acc: 0.8990 - val\_loss: 0.3168 - val\_acc: 0.9115

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 56us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 0.9129 - acc: 0.7732 - val\_loss: 0.5608 - val\_acc: 0.8592

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.4859 - acc: 0.8713 - val\_loss: 0.4437 - val\_acc: 0.8771

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.4128 - acc: 0.8868 - val\_loss: 0.3999 - val\_acc: 0.8882

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.3790 - acc: 0.8941 - val\_loss: 0.3762 - val\_acc: 0.8926

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.3586 - acc: 0.8992 - val\_loss: 0.3614 - val\_acc: 0.8944

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 55us/step
40000/40000 [==============================] - 2s 53us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4975 - acc: 0.8536 - val\_loss: 0.2980 - val\_acc: 0.9151

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.3655 - acc: 0.8926 - val\_loss: 0.2914 - val\_acc: 0.9136

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3497 - acc: 0.9000 - val\_loss: 0.2790 - val\_acc: 0.9214

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3429 - acc: 0.9013 - val\_loss: 0.2662 - val\_acc: 0.9256

Epoch 00004: val\_loss improved from 0.26763 to 0.26621, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 2s - loss: 0.3328 - acc: 0.9043 - val\_loss: 0.2667 - val\_acc: 0.9261

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 28us/step
40000/40000 [==============================] - 1s 27us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.4967 - acc: 0.8509 - val\_loss: 0.2914 - val\_acc: 0.9187

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3636 - acc: 0.8952 - val\_loss: 0.2797 - val\_acc: 0.9233

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3415 - acc: 0.9019 - val\_loss: 0.2833 - val\_acc: 0.9190

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3317 - acc: 0.9063 - val\_loss: 0.2725 - val\_acc: 0.9265

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3245 - acc: 0.9081 - val\_loss: 0.2663 - val\_acc: 0.9271

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 25us/step
40000/40000 [==============================] - 1s 23us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 0.4777 - acc: 0.8582 - val\_loss: 0.3603 - val\_acc: 0.8975

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.3583 - acc: 0.8984 - val\_loss: 0.3381 - val\_acc: 0.9062

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.3411 - acc: 0.9049 - val\_loss: 0.3203 - val\_acc: 0.9093

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.3306 - acc: 0.9073 - val\_loss: 0.3304 - val\_acc: 0.9077

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3218 - acc: 0.9108 - val\_loss: 0.3210 - val\_acc: 0.9105

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 24us/step
40000/40000 [==============================] - 1s 23us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.1870 - acc: 0.6418 - val\_loss: 0.6082 - val\_acc: 0.8522

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.6274 - acc: 0.8173 - val\_loss: 0.4395 - val\_acc: 0.8859

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5188 - acc: 0.8462 - val\_loss: 0.3814 - val\_acc: 0.8966

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4663 - acc: 0.8606 - val\_loss: 0.3503 - val\_acc: 0.9031

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4404 - acc: 0.8684 - val\_loss: 0.3324 - val\_acc: 0.9079

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 0s 24us/step
40000/40000 [==============================] - 1s 23us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.1656 - acc: 0.6585 - val\_loss: 0.5810 - val\_acc: 0.8678

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.6068 - acc: 0.8271 - val\_loss: 0.4233 - val\_acc: 0.8892

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5047 - acc: 0.8525 - val\_loss: 0.3717 - val\_acc: 0.8984

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4593 - acc: 0.8645 - val\_loss: 0.3455 - val\_acc: 0.9045

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4296 - acc: 0.8741 - val\_loss: 0.3295 - val\_acc: 0.9074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 28us/step
40000/40000 [==============================] - 1s 27us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 4s - loss: 1.1806 - acc: 0.6503 - val\_loss: 0.6537 - val\_acc: 0.8403

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.6096 - acc: 0.8279 - val\_loss: 0.4882 - val\_acc: 0.8676

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5019 - acc: 0.8577 - val\_loss: 0.4290 - val\_acc: 0.8815

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4583 - acc: 0.8675 - val\_loss: 0.3980 - val\_acc: 0.8892

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4281 - acc: 0.8762 - val\_loss: 0.3802 - val\_acc: 0.8906

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 25us/step
40000/40000 [==============================] - 1s 24us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.5246 - acc: 0.8454 - val\_loss: 0.3265 - val\_acc: 0.9080

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4049 - acc: 0.8841 - val\_loss: 0.3088 - val\_acc: 0.9124

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.3794 - acc: 0.8913 - val\_loss: 0.3332 - val\_acc: 0.9015

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3658 - acc: 0.8951 - val\_loss: 0.3021 - val\_acc: 0.9157

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3512 - acc: 0.8998 - val\_loss: 0.3090 - val\_acc: 0.9139

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 67us/step
40000/40000 [==============================] - 2s 56us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.5028 - acc: 0.8528 - val\_loss: 0.3269 - val\_acc: 0.9105

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4015 - acc: 0.8852 - val\_loss: 0.3313 - val\_acc: 0.9085

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.3730 - acc: 0.8935 - val\_loss: 0.3650 - val\_acc: 0.9014

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3579 - acc: 0.8986 - val\_loss: 0.3030 - val\_acc: 0.9163

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3422 - acc: 0.9035 - val\_loss: 0.3226 - val\_acc: 0.9080

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 84us/step
40000/40000 [==============================] - 2s 61us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.5052 - acc: 0.8517 - val\_loss: 0.3720 - val\_acc: 0.8971

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.4024 - acc: 0.8852 - val\_loss: 0.4022 - val\_acc: 0.8934

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.3720 - acc: 0.8951 - val\_loss: 0.3546 - val\_acc: 0.9040

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3553 - acc: 0.8991 - val\_loss: 0.4051 - val\_acc: 0.8904

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3416 - acc: 0.9056 - val\_loss: 0.3973 - val\_acc: 0.8888

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 98us/step
40000/40000 [==============================] - 3s 68us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 0.9626 - acc: 0.7329 - val\_loss: 0.4925 - val\_acc: 0.8812

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.5174 - acc: 0.8549 - val\_loss: 0.3863 - val\_acc: 0.8950

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.4440 - acc: 0.8707 - val\_loss: 0.3465 - val\_acc: 0.9044

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.4099 - acc: 0.8809 - val\_loss: 0.3267 - val\_acc: 0.9070

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.3866 - acc: 0.8871 - val\_loss: 0.3153 - val\_acc: 0.9123

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 62us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.9653 - acc: 0.7329 - val\_loss: 0.4957 - val\_acc: 0.8781

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.5146 - acc: 0.8568 - val\_loss: 0.3880 - val\_acc: 0.8966

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.4432 - acc: 0.8725 - val\_loss: 0.3484 - val\_acc: 0.9044

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.4058 - acc: 0.8824 - val\_loss: 0.3289 - val\_acc: 0.9084

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.3860 - acc: 0.8894 - val\_loss: 0.3169 - val\_acc: 0.9113

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 58us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 0.9608 - acc: 0.7373 - val\_loss: 0.5584 - val\_acc: 0.8579

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.5125 - acc: 0.8547 - val\_loss: 0.4429 - val\_acc: 0.8790

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.4383 - acc: 0.8764 - val\_loss: 0.3999 - val\_acc: 0.8862

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.4042 - acc: 0.8842 - val\_loss: 0.3767 - val\_acc: 0.8912

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.3827 - acc: 0.8884 - val\_loss: 0.3619 - val\_acc: 0.8956

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 61us/step
40000/40000 [==============================] - 3s 75us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6852 - acc: 0.7857 - val\_loss: 0.3035 - val\_acc: 0.9125

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4831 - acc: 0.8579 - val\_loss: 0.2951 - val\_acc: 0.9163

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4432 - acc: 0.8706 - val\_loss: 0.2882 - val\_acc: 0.9175

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4330 - acc: 0.8773 - val\_loss: 0.2924 - val\_acc: 0.9157

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4150 - acc: 0.8809 - val\_loss: 0.2822 - val\_acc: 0.9201

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 30us/step
40000/40000 [==============================] - 1s 27us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6721 - acc: 0.7907 - val\_loss: 0.2999 - val\_acc: 0.9141

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4725 - acc: 0.8622 - val\_loss: 0.2936 - val\_acc: 0.9185

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4417 - acc: 0.8741 - val\_loss: 0.2847 - val\_acc: 0.9204

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4285 - acc: 0.8783 - val\_loss: 0.2720 - val\_acc: 0.9239

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.4082 - acc: 0.8841 - val\_loss: 0.2879 - val\_acc: 0.9199

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 27us/step
40000/40000 [==============================] - 1s 25us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 0.6616 - acc: 0.7972 - val\_loss: 0.3601 - val\_acc: 0.8974

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.4823 - acc: 0.8618 - val\_loss: 0.3446 - val\_acc: 0.8988

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.4440 - acc: 0.8738 - val\_loss: 0.3363 - val\_acc: 0.9052

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4205 - acc: 0.8814 - val\_loss: 0.3259 - val\_acc: 0.9075

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4012 - acc: 0.8878 - val\_loss: 0.3304 - val\_acc: 0.9051

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 25us/step
40000/40000 [==============================] - 1s 26us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.4303 - acc: 0.5229 - val\_loss: 0.6278 - val\_acc: 0.8570

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.8145 - acc: 0.7384 - val\_loss: 0.4594 - val\_acc: 0.8824

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.6763 - acc: 0.7831 - val\_loss: 0.3959 - val\_acc: 0.8945

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.6202 - acc: 0.8068 - val\_loss: 0.3664 - val\_acc: 0.8998

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.5799 - acc: 0.8218 - val\_loss: 0.3503 - val\_acc: 0.9039

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 32us/step
40000/40000 [==============================] - 1s 32us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.4528 - acc: 0.5183 - val\_loss: 0.6569 - val\_acc: 0.8496

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.8205 - acc: 0.7378 - val\_loss: 0.4667 - val\_acc: 0.8810

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.6864 - acc: 0.7859 - val\_loss: 0.4027 - val\_acc: 0.8958

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.6172 - acc: 0.8085 - val\_loss: 0.3683 - val\_acc: 0.8998

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.5740 - acc: 0.8250 - val\_loss: 0.3488 - val\_acc: 0.9046

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 25us/step
40000/40000 [==============================] - 1s 25us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 5s - loss: 1.4185 - acc: 0.5265 - val\_loss: 0.6842 - val\_acc: 0.8295

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.8113 - acc: 0.7376 - val\_loss: 0.5136 - val\_acc: 0.8620

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.6789 - acc: 0.7869 - val\_loss: 0.4487 - val\_acc: 0.8760

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.6187 - acc: 0.8081 - val\_loss: 0.4166 - val\_acc: 0.8838

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.5737 - acc: 0.8246 - val\_loss: 0.3967 - val\_acc: 0.8889

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 34us/step
40000/40000 [==============================] - 2s 41us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.5747 - acc: 0.8317 - val\_loss: 0.3414 - val\_acc: 0.9008

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4660 - acc: 0.8685 - val\_loss: 0.3011 - val\_acc: 0.9124

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.4373 - acc: 0.8791 - val\_loss: 0.3020 - val\_acc: 0.9189

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.4144 - acc: 0.8836 - val\_loss: 0.3202 - val\_acc: 0.9091

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3950 - acc: 0.8881 - val\_loss: 0.3276 - val\_acc: 0.9090

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 62us/step
40000/40000 [==============================] - 2s 56us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.5678 - acc: 0.8339 - val\_loss: 0.3318 - val\_acc: 0.9089

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4569 - acc: 0.8709 - val\_loss: 0.3379 - val\_acc: 0.9120

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.4274 - acc: 0.8808 - val\_loss: 0.3162 - val\_acc: 0.9159

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.4056 - acc: 0.8888 - val\_loss: 0.3143 - val\_acc: 0.9145

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.3892 - acc: 0.8918 - val\_loss: 0.3518 - val\_acc: 0.9024

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 78us/step
40000/40000 [==============================] - 2s 61us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.5701 - acc: 0.8333 - val\_loss: 0.3614 - val\_acc: 0.9058

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.4538 - acc: 0.8743 - val\_loss: 0.3905 - val\_acc: 0.8976

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.4259 - acc: 0.8824 - val\_loss: 0.3719 - val\_acc: 0.8995

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.4004 - acc: 0.8895 - val\_loss: 0.3664 - val\_acc: 0.9009

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3864 - acc: 0.8920 - val\_loss: 0.3582 - val\_acc: 0.9028

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 56us/step
40000/40000 [==============================] - 2s 55us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 1.1365 - acc: 0.6318 - val\_loss: 0.5119 - val\_acc: 0.8722

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.6206 - acc: 0.8096 - val\_loss: 0.3962 - val\_acc: 0.8931

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.5325 - acc: 0.8381 - val\_loss: 0.3554 - val\_acc: 0.9009

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.4835 - acc: 0.8513 - val\_loss: 0.3335 - val\_acc: 0.9070

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.4614 - acc: 0.8593 - val\_loss: 0.3211 - val\_acc: 0.9096

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 2s 58us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 1.1161 - acc: 0.6429 - val\_loss: 0.4916 - val\_acc: 0.8800

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.6063 - acc: 0.8148 - val\_loss: 0.3862 - val\_acc: 0.8959

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.5193 - acc: 0.8415 - val\_loss: 0.3483 - val\_acc: 0.9036

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.4762 - acc: 0.8575 - val\_loss: 0.3291 - val\_acc: 0.9069

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.4534 - acc: 0.8620 - val\_loss: 0.3181 - val\_acc: 0.9107

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 2s 62us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 1.1383 - acc: 0.6334 - val\_loss: 0.5667 - val\_acc: 0.8519

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 5s - loss: 0.6169 - acc: 0.8115 - val\_loss: 0.4488 - val\_acc: 0.8762

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.5257 - acc: 0.8404 - val\_loss: 0.4069 - val\_acc: 0.8832

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.4782 - acc: 0.8568 - val\_loss: 0.3815 - val\_acc: 0.8899

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.4609 - acc: 0.8612 - val\_loss: 0.3665 - val\_acc: 0.8930

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 68us/step
40000/40000 [==============================] - 3s 64us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.2637 - acc: 0.2473 - val\_loss: 2.1884 - val\_acc: 0.7288

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.0374 - acc: 0.8026 - val\_loss: 1.8438 - val\_acc: 0.8416

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 1.6311 - acc: 0.8328 - val\_loss: 1.3954 - val\_acc: 0.8475

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.1975 - acc: 0.8390 - val\_loss: 0.9853 - val\_acc: 0.8526

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.8452 - acc: 0.8440 - val\_loss: 0.6935 - val\_acc: 0.8548

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 47us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.2638 - acc: 0.1954 - val\_loss: 2.1875 - val\_acc: 0.6610

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.0294 - acc: 0.7710 - val\_loss: 1.8299 - val\_acc: 0.7806

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 1.6099 - acc: 0.7760 - val\_loss: 1.3750 - val\_acc: 0.7691

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.1802 - acc: 0.7694 - val\_loss: 0.9885 - val\_acc: 0.7929

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.8619 - acc: 0.7917 - val\_loss: 0.7405 - val\_acc: 0.7937

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 47us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.2642 - acc: 0.1895 - val\_loss: 2.1919 - val\_acc: 0.6946

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.0355 - acc: 0.8436 - val\_loss: 1.8477 - val\_acc: 0.9076

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 1.6191 - acc: 0.9163 - val\_loss: 1.3912 - val\_acc: 0.9166

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.1650 - acc: 0.9242 - val\_loss: 0.9637 - val\_acc: 0.9199

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.7838 - acc: 0.9300 - val\_loss: 0.6494 - val\_acc: 0.9223

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 47us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.3023 - acc: 0.1055 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 46us/step
40000/40000 [==============================] - 2s 46us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.3020 - acc: 0.1092 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3014 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3010 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 47us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 6s - loss: 2.3022 - acc: 0.1093 - val\_loss: 2.3018 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3013 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 50us/step
40000/40000 [==============================] - 2s 48us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.2812 - acc: 0.1175 - val\_loss: 2.2268 - val\_acc: 0.2634

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 2.0905 - acc: 0.6174 - val\_loss: 1.9139 - val\_acc: 0.6704

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 1.7140 - acc: 0.6688 - val\_loss: 1.4986 - val\_acc: 0.6903

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 1.3155 - acc: 0.6767 - val\_loss: 1.1306 - val\_acc: 0.6751

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 1.0081 - acc: 0.6787 - val\_loss: 0.8849 - val\_acc: 0.6890

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 122us/step
40000/40000 [==============================] - 4s 98us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.2801 - acc: 0.1567 - val\_loss: 2.2240 - val\_acc: 0.3920

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 2.0860 - acc: 0.6487 - val\_loss: 1.9085 - val\_acc: 0.7465

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 1.7040 - acc: 0.7464 - val\_loss: 1.4844 - val\_acc: 0.7548

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 1.2935 - acc: 0.7538 - val\_loss: 1.0974 - val\_acc: 0.7586

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.9582 - acc: 0.7634 - val\_loss: 0.8168 - val\_acc: 0.7920

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 89us/step
40000/40000 [==============================] - 4s 107us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.2809 - acc: 0.1267 - val\_loss: 2.2287 - val\_acc: 0.2861

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 2.0919 - acc: 0.6449 - val\_loss: 1.9217 - val\_acc: 0.7461

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 1.7093 - acc: 0.7568 - val\_loss: 1.4968 - val\_acc: 0.7585

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 1.2871 - acc: 0.7625 - val\_loss: 1.1034 - val\_acc: 0.7625

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.9443 - acc: 0.7675 - val\_loss: 0.8279 - val\_acc: 0.7628

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 90us/step
40000/40000 [==============================] - 4s 99us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 2.3022 - acc: 0.1106 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3016 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 90us/step
40000/40000 [==============================] - 4s 104us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 2.3021 - acc: 0.1103 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3014 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3010 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 110us/step
40000/40000 [==============================] - 5s 116us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.3020 - acc: 0.1131 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3013 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 100us/step
40000/40000 [==============================] - 4s 96us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.2697 - acc: 0.1897 - val\_loss: 2.2040 - val\_acc: 0.6011

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.0796 - acc: 0.5500 - val\_loss: 1.8950 - val\_acc: 0.6710

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 1.7719 - acc: 0.5577 - val\_loss: 1.5098 - val\_acc: 0.6725

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.4927 - acc: 0.5635 - val\_loss: 1.1889 - val\_acc: 0.6876

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.2912 - acc: 0.5664 - val\_loss: 0.9721 - val\_acc: 0.6907

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 52us/step
40000/40000 [==============================] - 2s 52us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.2708 - acc: 0.2422 - val\_loss: 2.2087 - val\_acc: 0.5369

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.0913 - acc: 0.6087 - val\_loss: 1.9132 - val\_acc: 0.7538

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 1.7781 - acc: 0.6360 - val\_loss: 1.5144 - val\_acc: 0.7900

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.4696 - acc: 0.6373 - val\_loss: 1.1480 - val\_acc: 0.7784

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.2259 - acc: 0.6425 - val\_loss: 0.8827 - val\_acc: 0.7761

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 53us/step
40000/40000 [==============================] - 2s 50us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.2698 - acc: 0.2172 - val\_loss: 2.2093 - val\_acc: 0.3755

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.0893 - acc: 0.6479 - val\_loss: 1.9205 - val\_acc: 0.8325

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 1.7760 - acc: 0.6927 - val\_loss: 1.5205 - val\_acc: 0.8374

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.4514 - acc: 0.6977 - val\_loss: 1.1417 - val\_acc: 0.8401

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.1968 - acc: 0.7035 - val\_loss: 0.8591 - val\_acc: 0.8431

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 55us/step
40000/40000 [==============================] - 2s 56us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.3021 - acc: 0.1107 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.3016 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 53us/step
40000/40000 [==============================] - 2s 52us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.3023 - acc: 0.1069 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 52us/step
40000/40000 [==============================] - 2s 54us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.3019 - acc: 0.1107 - val\_loss: 2.3016 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 52us/step
40000/40000 [==============================] - 3s 64us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 2.2838 - acc: 0.1307 - val\_loss: 2.2362 - val\_acc: 0.2059

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 2.1244 - acc: 0.4561 - val\_loss: 1.9580 - val\_acc: 0.5845

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 1.8362 - acc: 0.4885 - val\_loss: 1.5961 - val\_acc: 0.5865

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.5669 - acc: 0.4897 - val\_loss: 1.2951 - val\_acc: 0.5889

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 1.3861 - acc: 0.4899 - val\_loss: 1.0951 - val\_acc: 0.5899

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 105us/step
40000/40000 [==============================] - 5s 137us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2855 - acc: 0.1425 - val\_loss: 2.2427 - val\_acc: 0.3352

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 2.1371 - acc: 0.4651 - val\_loss: 1.9786 - val\_acc: 0.5814

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 1.8469 - acc: 0.4951 - val\_loss: 1.6115 - val\_acc: 0.5821

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.5619 - acc: 0.4981 - val\_loss: 1.2868 - val\_acc: 0.6082

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 1.3608 - acc: 0.5060 - val\_loss: 1.0708 - val\_acc: 0.6008

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 103us/step
40000/40000 [==============================] - 5s 123us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2844 - acc: 0.1371 - val\_loss: 2.2399 - val\_acc: 0.2014

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 2.1304 - acc: 0.4554 - val\_loss: 1.9740 - val\_acc: 0.5711

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 1.8480 - acc: 0.4873 - val\_loss: 1.6252 - val\_acc: 0.5700

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.5752 - acc: 0.4905 - val\_loss: 1.3197 - val\_acc: 0.5734

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 1.3789 - acc: 0.4956 - val\_loss: 1.1155 - val\_acc: 0.5774

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 115us/step
40000/40000 [==============================] - 4s 102us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.3022 - acc: 0.1118 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3016 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 103us/step
40000/40000 [==============================] - 4s 108us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.3021 - acc: 0.1105 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3014 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 120us/step
40000/40000 [==============================] - 5s 133us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.3020 - acc: 0.1135 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3013 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 141us/step
40000/40000 [==============================] - 4s 104us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.2816 - acc: 0.1898 - val\_loss: 2.2416 - val\_acc: 0.1960

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.1744 - acc: 0.3784 - val\_loss: 2.0539 - val\_acc: 0.6597

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.0070 - acc: 0.4011 - val\_loss: 1.7891 - val\_acc: 0.6824

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.8485 - acc: 0.4103 - val\_loss: 1.5286 - val\_acc: 0.6924

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.7186 - acc: 0.4190 - val\_loss: 1.3100 - val\_acc: 0.7238

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 59us/step
40000/40000 [==============================] - 3s 68us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.2826 - acc: 0.2044 - val\_loss: 2.2448 - val\_acc: 0.4270

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.1808 - acc: 0.4196 - val\_loss: 2.0650 - val\_acc: 0.7478

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.0121 - acc: 0.4420 - val\_loss: 1.7992 - val\_acc: 0.7606

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.8490 - acc: 0.4500 - val\_loss: 1.5305 - val\_acc: 0.7619

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.7120 - acc: 0.4643 - val\_loss: 1.2986 - val\_acc: 0.7660

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 59us/step
40000/40000 [==============================] - 2s 61us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.2811 - acc: 0.1716 - val\_loss: 2.2429 - val\_acc: 0.2575

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.1786 - acc: 0.3761 - val\_loss: 2.0622 - val\_acc: 0.6615

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.0133 - acc: 0.3963 - val\_loss: 1.8020 - val\_acc: 0.6679

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 1.8705 - acc: 0.3960 - val\_loss: 1.5531 - val\_acc: 0.6720

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 1.7730 - acc: 0.3947 - val\_loss: 1.3613 - val\_acc: 0.6780

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 56us/step
40000/40000 [==============================] - 2s 55us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.3022 - acc: 0.1107 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 85us/step
40000/40000 [==============================] - 3s 67us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3021 - acc: 0.1084 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.3015 - acc: 0.1122 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.3012 - acc: 0.1127 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 63us/step
40000/40000 [==============================] - 3s 70us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3022 - acc: 0.1039 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 2.3014 - acc: 0.1142 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 58us/step
40000/40000 [==============================] - 2s 57us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 2.2910 - acc: 0.1218 - val\_loss: 2.2637 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 2.2045 - acc: 0.3827 - val\_loss: 2.0973 - val\_acc: 0.6764

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 2.0479 - acc: 0.3940 - val\_loss: 1.8403 - val\_acc: 0.6819

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.8912 - acc: 0.3938 - val\_loss: 1.5762 - val\_acc: 0.7173

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 1.7609 - acc: 0.4000 - val\_loss: 1.3478 - val\_acc: 0.7019

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 120us/step
40000/40000 [==============================] - 4s 105us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2911 - acc: 0.1318 - val\_loss: 2.2643 - val\_acc: 0.2009

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 2.2047 - acc: 0.3378 - val\_loss: 2.0950 - val\_acc: 0.5800

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 12s - loss: 2.0497 - acc: 0.3485 - val\_loss: 1.8451 - val\_acc: 0.5864

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.9132 - acc: 0.3467 - val\_loss: 1.6057 - val\_acc: 0.5877

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 1.8007 - acc: 0.3527 - val\_loss: 1.4097 - val\_acc: 0.5895

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 106us/step
40000/40000 [==============================] - 4s 112us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2913 - acc: 0.1257 - val\_loss: 2.2659 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 2.2050 - acc: 0.2869 - val\_loss: 2.1014 - val\_acc: 0.4836

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 2.0527 - acc: 0.3443 - val\_loss: 1.8582 - val\_acc: 0.5723

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 1.9047 - acc: 0.3490 - val\_loss: 1.6209 - val\_acc: 0.5737

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 1.7845 - acc: 0.3519 - val\_loss: 1.4196 - val\_acc: 0.5757

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 118us/step
40000/40000 [==============================] - 6s 149us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.3023 - acc: 0.1087 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 127us/step
40000/40000 [==============================] - 6s 142us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 2.3020 - acc: 0.1093 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3014 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 10s - loss: 2.3011 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 2.3010 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 106us/step
40000/40000 [==============================] - 4s 103us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.3021 - acc: 0.1108 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.3013 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3009 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 115us/step
40000/40000 [==============================] - 5s 123us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.2873 - acc: 0.1153 - val\_loss: 2.2625 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.2153 - acc: 0.4467 - val\_loss: 2.1517 - val\_acc: 0.7445

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.0691 - acc: 0.7482 - val\_loss: 1.9701 - val\_acc: 0.7578

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 1.8652 - acc: 0.7589 - val\_loss: 1.7465 - val\_acc: 0.7778

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 1.6345 - acc: 0.7639 - val\_loss: 1.5102 - val\_acc: 0.7762

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 45us/step
40000/40000 [==============================] - 1s 35us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.2873 - acc: 0.1336 - val\_loss: 2.2632 - val\_acc: 0.2047

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.2164 - acc: 0.4278 - val\_loss: 2.1528 - val\_acc: 0.7319

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.0690 - acc: 0.7727 - val\_loss: 1.9690 - val\_acc: 0.8321

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 1.8620 - acc: 0.8294 - val\_loss: 1.7403 - val\_acc: 0.8442

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 1.6259 - acc: 0.8359 - val\_loss: 1.4982 - val\_acc: 0.8465

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 43us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.2882 - acc: 0.1142 - val\_loss: 2.2659 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.2203 - acc: 0.3448 - val\_loss: 2.1626 - val\_acc: 0.6408

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.0794 - acc: 0.7212 - val\_loss: 1.9887 - val\_acc: 0.7415

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 1.8804 - acc: 0.7453 - val\_loss: 1.7711 - val\_acc: 0.7475

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 1.6535 - acc: 0.7513 - val\_loss: 1.5402 - val\_acc: 0.7596

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 35us/step
40000/40000 [==============================] - 1s 35us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 7s - loss: 2.3025 - acc: 0.1060 - val\_loss: 2.3023 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.3020 - acc: 0.1126 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 2.3016 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 37us/step
40000/40000 [==============================] - 1s 36us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.3025 - acc: 0.0964 - val\_loss: 2.3022 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.3019 - acc: 0.1125 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 2.3013 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 44us/step
40000/40000 [==============================] - 1s 37us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3025 - acc: 0.1028 - val\_loss: 2.3023 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.3018 - acc: 0.1143 - val\_loss: 2.3018 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.3014 - acc: 0.1143 - val\_loss: 2.3016 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 43us/step
40000/40000 [==============================] - 2s 38us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.2963 - acc: 0.1118 - val\_loss: 2.2830 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.2468 - acc: 0.1966 - val\_loss: 2.1955 - val\_acc: 0.5694

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.1231 - acc: 0.5720 - val\_loss: 2.0372 - val\_acc: 0.5824

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 1.9450 - acc: 0.5842 - val\_loss: 1.8420 - val\_acc: 0.5817

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8190s - loss: 1.7457 - acc: 0.5837 - val\_loss: 1.6398 - val\_acc: 0.5857

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 86us/step
40000/40000 [==============================] - 3s 87us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.2962 - acc: 0.1111 - val\_loss: 2.2831 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2480 - acc: 0.2411 - val\_loss: 2.1989 - val\_acc: 0.4854

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.1277 - acc: 0.5635 - val\_loss: 2.0418 - val\_acc: 0.6605

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 1.9476 - acc: 0.6620 - val\_loss: 1.8401 - val\_acc: 0.6644

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 1.7376 - acc: 0.6651 - val\_loss: 1.6227 - val\_acc: 0.6685

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 84us/step
40000/40000 [==============================] - 3s 87us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2959 - acc: 0.1135 - val\_loss: 2.2828 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.2465 - acc: 0.2096 - val\_loss: 2.1976 - val\_acc: 0.5309

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.1229 - acc: 0.6399 - val\_loss: 2.0407 - val\_acc: 0.6591

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 1.9392 - acc: 0.6676 - val\_loss: 1.8383 - val\_acc: 0.6763

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 1.7236 - acc: 0.6757 - val\_loss: 1.6190 - val\_acc: 0.6616

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 91us/step
40000/40000 [==============================] - 4s 90us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 2.3024 - acc: 0.1092 - val\_loss: 2.3022 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3020 - acc: 0.1126 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 100us/step
40000/40000 [==============================] - 4s 96us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.3023 - acc: 0.1090 - val\_loss: 2.3021 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3018 - acc: 0.1125 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 2.3013 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 87us/step
40000/40000 [==============================] - 3s 85us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.3022 - acc: 0.1125 - val\_loss: 2.3020 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3017 - acc: 0.1143 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3014 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 86us/step
40000/40000 [==============================] - 4s 96us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 8s - loss: 2.2900 - acc: 0.1183 - val\_loss: 2.2696 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.2323 - acc: 0.3689 - val\_loss: 2.1775 - val\_acc: 0.7312

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.1118 - acc: 0.6152 - val\_loss: 2.0161 - val\_acc: 0.7585

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.9467 - acc: 0.6212 - val\_loss: 1.8093 - val\_acc: 0.7630

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.7657 - acc: 0.6257 - val\_loss: 1.5888 - val\_acc: 0.7616

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 52us/step
40000/40000 [==============================] - 2s 38us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.2882 - acc: 0.1348 - val\_loss: 2.2658 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 2.2244 - acc: 0.4394 - val\_loss: 2.1659 - val\_acc: 0.8071

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 2.0984 - acc: 0.6780 - val\_loss: 1.9973 - val\_acc: 0.8440

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.9264 - acc: 0.6923 - val\_loss: 1.7845 - val\_acc: 0.8470

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.7374 - acc: 0.6994 - val\_loss: 1.5557 - val\_acc: 0.8511

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 41us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.2894 - acc: 0.1154 - val\_loss: 2.2692 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.2284 - acc: 0.3423 - val\_loss: 2.1735 - val\_acc: 0.6196

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.1028 - acc: 0.6031 - val\_loss: 2.0091 - val\_acc: 0.7459

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.9328 - acc: 0.6264 - val\_loss: 1.8020 - val\_acc: 0.7538

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.7474 - acc: 0.6345 - val\_loss: 1.5817 - val\_acc: 0.7588

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 41us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3024 - acc: 0.1059 - val\_loss: 2.3022 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3019 - acc: 0.1122 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3018 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 38us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3027 - acc: 0.0999 - val\_loss: 2.3024 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3020 - acc: 0.1120 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3016 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3014 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3013 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 43us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3021 - acc: 0.1090 - val\_loss: 2.3020 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3016 - acc: 0.1144 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3013 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 41us/step
40000/40000 [==============================] - 2s 46us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2973 - acc: 0.1123 - val\_loss: 2.2860 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2558 - acc: 0.2105 - val\_loss: 2.2106 - val\_acc: 0.3795

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.1538 - acc: 0.4126 - val\_loss: 2.0697 - val\_acc: 0.5015

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.0107 - acc: 0.4174 - val\_loss: 1.8930 - val\_acc: 0.4986

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 1.8577 - acc: 0.4201 - val\_loss: 1.7110 - val\_acc: 0.4995

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 100us/step
40000/40000 [==============================] - 3s 86us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2974 - acc: 0.1118 - val\_loss: 2.2870 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2582 - acc: 0.2235 - val\_loss: 2.2151 - val\_acc: 0.4376

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.1561 - acc: 0.4847 - val\_loss: 2.0714 - val\_acc: 0.5783

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.0034 - acc: 0.5475 - val\_loss: 1.8797 - val\_acc: 0.6567

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 1.8325 - acc: 0.5516 - val\_loss: 1.6687 - val\_acc: 0.6613

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 84us/step
40000/40000 [==============================] - 4s 96us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.2970 - acc: 0.1142 - val\_loss: 2.2864 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2566 - acc: 0.1750 - val\_loss: 2.2142 - val\_acc: 0.3221

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.1530 - acc: 0.5695 - val\_loss: 2.0697 - val\_acc: 0.7321

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 1.9947 - acc: 0.6368 - val\_loss: 1.8753 - val\_acc: 0.7665

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 1.8175 - acc: 0.6331 - val\_loss: 1.6606 - val\_acc: 0.7716

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 89us/step
40000/40000 [==============================] - 3s 82us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 2.3023 - acc: 0.1112 - val\_loss: 2.3022 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.3019 - acc: 0.1126 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 93us/step
40000/40000 [==============================] - 4s 92us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.3023 - acc: 0.1112 - val\_loss: 2.3021 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.3018 - acc: 0.1125 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3013 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 91us/step
40000/40000 [==============================] - 4s 94us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 2.3023 - acc: 0.1116 - val\_loss: 2.3020 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.3017 - acc: 0.1143 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.3014 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 2.3010 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 92us/step
40000/40000 [==============================] - 4s 99us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.2925 - acc: 0.1353 - val\_loss: 2.2770 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.2512 - acc: 0.2995 - val\_loss: 2.2100 - val\_acc: 0.5369

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.1722 - acc: 0.3781 - val\_loss: 2.0944 - val\_acc: 0.6482

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.0720 - acc: 0.3937 - val\_loss: 1.9460 - val\_acc: 0.6542

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.9676 - acc: 0.4035 - val\_loss: 1.7842 - val\_acc: 0.7181

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 39us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.2923 - acc: 0.1365 - val\_loss: 2.2772 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.2513 - acc: 0.3154 - val\_loss: 2.2118 - val\_acc: 0.4725

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.1740 - acc: 0.4211 - val\_loss: 2.0978 - val\_acc: 0.7519

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.0726 - acc: 0.4380 - val\_loss: 1.9503 - val\_acc: 0.7665

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.9656 - acc: 0.4453 - val\_loss: 1.7816 - val\_acc: 0.7679

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 41us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.2926 - acc: 0.1188 - val\_loss: 2.2781 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.2523 - acc: 0.2854 - val\_loss: 2.2147 - val\_acc: 0.5184

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.1733 - acc: 0.4056 - val\_loss: 2.1023 - val\_acc: 0.6596

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.0718 - acc: 0.4542 - val\_loss: 1.9542 - val\_acc: 0.7830

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 1.9613 - acc: 0.4719 - val\_loss: 1.7840 - val\_acc: 0.8273

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 42us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 2.3026 - acc: 0.1018 - val\_loss: 2.3022 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3020 - acc: 0.1109 - val\_loss: 2.3020 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3018 - acc: 0.1124 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 2.3016 - acc: 0.1127 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 43us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 9s - loss: 2.3024 - acc: 0.1044 - val\_loss: 2.3021 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3018 - acc: 0.1108 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3016 - acc: 0.1116 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3013 - acc: 0.1121 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3012 - acc: 0.1126 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 55us/step
40000/40000 [==============================] - 2s 42us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 2.3022 - acc: 0.1053 - val\_loss: 2.3020 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 2.3016 - acc: 0.1140 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 2.3013 - acc: 0.1145 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 42us/step
40000/40000 [==============================] - 2s 43us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 2.2988 - acc: 0.1121 - val\_loss: 2.2916 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 2.2737 - acc: 0.1942 - val\_loss: 2.2448 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.2129 - acc: 0.3393 - val\_loss: 2.1494 - val\_acc: 0.5761

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.1230 - acc: 0.3613 - val\_loss: 2.0173 - val\_acc: 0.5874

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 2.0292 - acc: 0.3659 - val\_loss: 1.8686 - val\_acc: 0.5903

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 95us/step
40000/40000 [==============================] - 4s 98us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 2.2985 - acc: 0.1117 - val\_loss: 2.2911 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2724 - acc: 0.2066 - val\_loss: 2.2425 - val\_acc: 0.2717

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.2095 - acc: 0.3453 - val\_loss: 2.1450 - val\_acc: 0.5789

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.1221 - acc: 0.3462 - val\_loss: 2.0131 - val\_acc: 0.5791

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 2.0285 - acc: 0.3521 - val\_loss: 1.8635 - val\_acc: 0.5800

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 86us/step
40000/40000 [==============================] - 4s 94us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 2.2983 - acc: 0.1126 - val\_loss: 2.2908 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 2.2716 - acc: 0.1757 - val\_loss: 2.2423 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 2.2061 - acc: 0.3777 - val\_loss: 2.1433 - val\_acc: 0.6492

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 2.1130 - acc: 0.3939 - val\_loss: 2.0055 - val\_acc: 0.6634

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 2.0098 - acc: 0.3995 - val\_loss: 1.8453 - val\_acc: 0.6659

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 94us/step
40000/40000 [==============================] - 3s 83us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 14s - loss: 2.3023 - acc: 0.1115 - val\_loss: 2.3021 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.3019 - acc: 0.1126 - val\_loss: 2.3019 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.3017 - acc: 0.1126 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3015 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 2.3014 - acc: 0.1126 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 108us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.3023 - acc: 0.1105 - val\_loss: 2.3021 - val\_acc: 0.1074

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 2.3017 - acc: 0.1125 - val\_loss: 2.3018 - val\_acc: 0.1074

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 2.3015 - acc: 0.1125 - val\_loss: 2.3017 - val\_acc: 0.1074

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 2.3013 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 2.3012 - acc: 0.1125 - val\_loss: 2.3016 - val\_acc: 0.1074

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 101us/step
40000/40000 [==============================] - 3s 87us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 2.3023 - acc: 0.1104 - val\_loss: 2.3020 - val\_acc: 0.1130

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 2.3017 - acc: 0.1143 - val\_loss: 2.3017 - val\_acc: 0.1130

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 2.3014 - acc: 0.1143 - val\_loss: 2.3015 - val\_acc: 0.1130

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 2.3012 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 2.3011 - acc: 0.1143 - val\_loss: 2.3014 - val\_acc: 0.1130

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 104us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.3453 - acc: 0.8988 - val\_loss: 0.1664 - val\_acc: 0.9509

Epoch 00001: val\_loss improved from 0.26621 to 0.16640, saving model to mnist.model.best.hdf5
Epoch 2/5
 - 4s - loss: 0.1543 - acc: 0.9530 - val\_loss: 0.1295 - val\_acc: 0.9629

Epoch 00002: val\_loss improved from 0.16640 to 0.12945, saving model to mnist.model.best.hdf5
Epoch 3/5
 - 4s - loss: 0.1094 - acc: 0.9658 - val\_loss: 0.1089 - val\_acc: 0.9681

Epoch 00003: val\_loss improved from 0.12945 to 0.10886, saving model to mnist.model.best.hdf5
Epoch 4/5
 - 4s - loss: 0.0802 - acc: 0.9754 - val\_loss: 0.0991 - val\_acc: 0.9690

Epoch 00004: val\_loss improved from 0.10886 to 0.09906, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 4s - loss: 0.0626 - acc: 0.9806 - val\_loss: 0.1006 - val\_acc: 0.9720

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 61us/step
40000/40000 [==============================] - 2s 59us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.3409 - acc: 0.9012 - val\_loss: 0.1591 - val\_acc: 0.9527

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.1478 - acc: 0.9563 - val\_loss: 0.1162 - val\_acc: 0.9661

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.1000 - acc: 0.9703 - val\_loss: 0.1123 - val\_acc: 0.9685

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.0749 - acc: 0.9767 - val\_loss: 0.1181 - val\_acc: 0.9671

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.0573 - acc: 0.9827 - val\_loss: 0.1123 - val\_acc: 0.9692

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 63us/step
40000/40000 [==============================] - 2s 59us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.3351 - acc: 0.9039 - val\_loss: 0.1968 - val\_acc: 0.9381

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.1405 - acc: 0.9577 - val\_loss: 0.1473 - val\_acc: 0.9557

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.0972 - acc: 0.9699 - val\_loss: 0.1237 - val\_acc: 0.9633

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.0707 - acc: 0.9781 - val\_loss: 0.1192 - val\_acc: 0.9649

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.0551 - acc: 0.9836 - val\_loss: 0.1087 - val\_acc: 0.9675

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 69us/step
40000/40000 [==============================] - 3s 66us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.2112 - acc: 0.6957 - val\_loss: 0.5325 - val\_acc: 0.8748

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.4820 - acc: 0.8712 - val\_loss: 0.3652 - val\_acc: 0.9024

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.3845 - acc: 0.8912 - val\_loss: 0.3172 - val\_acc: 0.9110

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.3423 - acc: 0.9026 - val\_loss: 0.2901 - val\_acc: 0.9203

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.3150 - acc: 0.9094 - val\_loss: 0.2703 - val\_acc: 0.9246

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 63us/step
40000/40000 [==============================] - 3s 69us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 1.2591 - acc: 0.6777 - val\_loss: 0.5832 - val\_acc: 0.8714

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.5038 - acc: 0.8697 - val\_loss: 0.3808 - val\_acc: 0.8999

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3872 - acc: 0.8938 - val\_loss: 0.3197 - val\_acc: 0.9105

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 5s - loss: 0.3392 - acc: 0.9046 - val\_loss: 0.2935 - val\_acc: 0.9161

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.3098 - acc: 0.9122 - val\_loss: 0.2722 - val\_acc: 0.9235

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 3s 65us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.2176 - acc: 0.6868 - val\_loss: 0.5983 - val\_acc: 0.8558

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.4777 - acc: 0.8738 - val\_loss: 0.4135 - val\_acc: 0.8864

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.3738 - acc: 0.8955 - val\_loss: 0.3543 - val\_acc: 0.9012

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.3294 - acc: 0.9071 - val\_loss: 0.3245 - val\_acc: 0.9052

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.3017 - acc: 0.9138 - val\_loss: 0.3012 - val\_acc: 0.9143

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 2s 59us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.2670 - acc: 0.9168 - val\_loss: 0.1341 - val\_acc: 0.9586

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 0.1042 - acc: 0.9688 - val\_loss: 0.1222 - val\_acc: 0.9654

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.0683 - acc: 0.9791 - val\_loss: 0.1267 - val\_acc: 0.9676

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.0486 - acc: 0.9853 - val\_loss: 0.1046 - val\_acc: 0.9749

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.0381 - acc: 0.9886 - val\_loss: 0.0934 - val\_acc: 0.9756

Epoch 00005: val\_loss improved from 0.09906 to 0.09338, saving model to mnist.model.best.hdf5
20000/20000 [==============================] - 2s 99us/step
40000/40000 [==============================] - 4s 101us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.2583 - acc: 0.9199 - val\_loss: 0.1266 - val\_acc: 0.9620

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.1009 - acc: 0.9695 - val\_loss: 0.0994 - val\_acc: 0.9708

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 12s - loss: 0.0667 - acc: 0.9804 - val\_loss: 0.0906 - val\_acc: 0.9756

Epoch 00003: val\_loss improved from 0.09338 to 0.09060, saving model to mnist.model.best.hdf5
Epoch 4/5
 - 12s - loss: 0.0474 - acc: 0.9848 - val\_loss: 0.1036 - val\_acc: 0.9739

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.0367 - acc: 0.9885 - val\_loss: 0.1165 - val\_acc: 0.9725

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 97us/step
40000/40000 [==============================] - 4s 108us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.2627 - acc: 0.9181 - val\_loss: 0.1283 - val\_acc: 0.9601

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.1008 - acc: 0.9696 - val\_loss: 0.1090 - val\_acc: 0.9699

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.0640 - acc: 0.9806 - val\_loss: 0.1241 - val\_acc: 0.9684

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.0447 - acc: 0.9869 - val\_loss: 0.1184 - val\_acc: 0.9720

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.0330 - acc: 0.9898 - val\_loss: 0.1248 - val\_acc: 0.9746

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 95us/step
40000/40000 [==============================] - 4s 101us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.1039 - acc: 0.7511 - val\_loss: 0.4867 - val\_acc: 0.8840

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.4481 - acc: 0.8826 - val\_loss: 0.3366 - val\_acc: 0.9116

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.3589 - acc: 0.8994 - val\_loss: 0.2928 - val\_acc: 0.9171

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.3181 - acc: 0.9096 - val\_loss: 0.2667 - val\_acc: 0.9250

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.2915 - acc: 0.9169 - val\_loss: 0.2491 - val\_acc: 0.9299

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 4s 202us/step
40000/40000 [==============================] - 6s 149us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 1.0760 - acc: 0.7561 - val\_loss: 0.4830 - val\_acc: 0.8850

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.4415 - acc: 0.8851 - val\_loss: 0.3390 - val\_acc: 0.9097

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.3540 - acc: 0.9029 - val\_loss: 0.2958 - val\_acc: 0.9179

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3139 - acc: 0.9129 - val\_loss: 0.2741 - val\_acc: 0.9225

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.2873 - acc: 0.9198 - val\_loss: 0.2535 - val\_acc: 0.9275

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 100us/step
40000/40000 [==============================] - 4s 101us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.0492 - acc: 0.7608 - val\_loss: 0.5300 - val\_acc: 0.8670

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.4373 - acc: 0.8857 - val\_loss: 0.3885 - val\_acc: 0.8914

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.3523 - acc: 0.9024 - val\_loss: 0.3358 - val\_acc: 0.9042

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.3122 - acc: 0.9121 - val\_loss: 0.3072 - val\_acc: 0.9095

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.2860 - acc: 0.9194 - val\_loss: 0.2876 - val\_acc: 0.9153

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 134us/step
40000/40000 [==============================] - 4s 106us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.4376 - acc: 0.8667 - val\_loss: 0.1799 - val\_acc: 0.9476

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.2046 - acc: 0.9390 - val\_loss: 0.1234 - val\_acc: 0.9629

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 5s - loss: 0.1568 - acc: 0.9533 - val\_loss: 0.1212 - val\_acc: 0.9649

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.1304 - acc: 0.9614 - val\_loss: 0.0972 - val\_acc: 0.9712

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.1100 - acc: 0.9658 - val\_loss: 0.0996 - val\_acc: 0.9720

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 0.4315 - acc: 0.8699 - val\_loss: 0.1657 - val\_acc: 0.9496

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.2040 - acc: 0.9391 - val\_loss: 0.1300 - val\_acc: 0.9613

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.1525 - acc: 0.9544 - val\_loss: 0.1113 - val\_acc: 0.9657

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.1293 - acc: 0.9615 - val\_loss: 0.1025 - val\_acc: 0.9715

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.1096 - acc: 0.9676 - val\_loss: 0.1015 - val\_acc: 0.9705

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 60us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.4203 - acc: 0.8739 - val\_loss: 0.2137 - val\_acc: 0.9346

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.2009 - acc: 0.9401 - val\_loss: 0.1461 - val\_acc: 0.9560

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.1473 - acc: 0.9548 - val\_loss: 0.1345 - val\_acc: 0.9617

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.1225 - acc: 0.9634 - val\_loss: 0.1207 - val\_acc: 0.9664

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.1035 - acc: 0.9687 - val\_loss: 0.1258 - val\_acc: 0.9689

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 59us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 1.4237 - acc: 0.5789 - val\_loss: 0.6266 - val\_acc: 0.8682

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.6829 - acc: 0.7957 - val\_loss: 0.4034 - val\_acc: 0.8966

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.5337 - acc: 0.8421 - val\_loss: 0.3370 - val\_acc: 0.9080

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.4646 - acc: 0.8621 - val\_loss: 0.3011 - val\_acc: 0.9164

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.4206 - acc: 0.8755 - val\_loss: 0.2771 - val\_acc: 0.9221

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 61us/step
40000/40000 [==============================] - 2s 61us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.4861 - acc: 0.5577 - val\_loss: 0.6629 - val\_acc: 0.8575

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.7019 - acc: 0.7923 - val\_loss: 0.4110 - val\_acc: 0.8956

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.5416 - acc: 0.8382 - val\_loss: 0.3430 - val\_acc: 0.9062

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.4685 - acc: 0.8621 - val\_loss: 0.3041 - val\_acc: 0.9126

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.4253 - acc: 0.8753 - val\_loss: 0.2802 - val\_acc: 0.9186

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 66us/step
40000/40000 [==============================] - 3s 64us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 1.4714 - acc: 0.5475 - val\_loss: 0.6979 - val\_acc: 0.8344

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.6891 - acc: 0.7936 - val\_loss: 0.4554 - val\_acc: 0.8745

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.5326 - acc: 0.8406 - val\_loss: 0.3851 - val\_acc: 0.8929

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.4605 - acc: 0.8643 - val\_loss: 0.3443 - val\_acc: 0.9015

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.4190 - acc: 0.8791 - val\_loss: 0.3196 - val\_acc: 0.9073

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 63us/step
40000/40000 [==============================] - 3s 63us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 21s - loss: 0.2971 - acc: 0.9094 - val\_loss: 0.1275 - val\_acc: 0.9620

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 0.1314 - acc: 0.9611 - val\_loss: 0.1219 - val\_acc: 0.9643

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 13s - loss: 0.0970 - acc: 0.9709 - val\_loss: 0.1022 - val\_acc: 0.9719

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.0805 - acc: 0.9773 - val\_loss: 0.1032 - val\_acc: 0.9699

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.0635 - acc: 0.9817 - val\_loss: 0.0993 - val\_acc: 0.9769

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 102us/step
40000/40000 [==============================] - 5s 123us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 19s - loss: 0.2922 - acc: 0.9098 - val\_loss: 0.1422 - val\_acc: 0.9575

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 13s - loss: 0.1290 - acc: 0.9611 - val\_loss: 0.1080 - val\_acc: 0.9701

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.0930 - acc: 0.9727 - val\_loss: 0.1130 - val\_acc: 0.9708

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.0781 - acc: 0.9776 - val\_loss: 0.1058 - val\_acc: 0.9718

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.0644 - acc: 0.9810 - val\_loss: 0.1157 - val\_acc: 0.9736

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 116us/step
40000/40000 [==============================] - 5s 130us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.2907 - acc: 0.9110 - val\_loss: 0.1829 - val\_acc: 0.9425

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.1239 - acc: 0.9634 - val\_loss: 0.1230 - val\_acc: 0.9655

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.0910 - acc: 0.9726 - val\_loss: 0.1265 - val\_acc: 0.9666

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.0718 - acc: 0.9791 - val\_loss: 0.1454 - val\_acc: 0.9663

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.0586 - acc: 0.9831 - val\_loss: 0.1234 - val\_acc: 0.9740

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 115us/step
40000/40000 [==============================] - 5s 123us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 1.2192 - acc: 0.6793 - val\_loss: 0.5150 - val\_acc: 0.8790

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.5350 - acc: 0.8498 - val\_loss: 0.3527 - val\_acc: 0.9061

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.4330 - acc: 0.8743 - val\_loss: 0.3035 - val\_acc: 0.9167

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.3781 - acc: 0.8892 - val\_loss: 0.2740 - val\_acc: 0.9235

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3433 - acc: 0.8995 - val\_loss: 0.2550 - val\_acc: 0.9285

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 103us/step
40000/40000 [==============================] - 4s 94us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.2158 - acc: 0.6800 - val\_loss: 0.5151 - val\_acc: 0.8805

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.5367 - acc: 0.8465 - val\_loss: 0.3560 - val\_acc: 0.9044

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.4288 - acc: 0.8757 - val\_loss: 0.3032 - val\_acc: 0.9166

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.3754 - acc: 0.8910 - val\_loss: 0.2734 - val\_acc: 0.9247

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.3434 - acc: 0.8996 - val\_loss: 0.2552 - val\_acc: 0.9280

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 151us/step
40000/40000 [==============================] - 5s 115us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 1.1790 - acc: 0.6929 - val\_loss: 0.5552 - val\_acc: 0.8625

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.5209 - acc: 0.8520 - val\_loss: 0.3936 - val\_acc: 0.8905

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.4160 - acc: 0.8787 - val\_loss: 0.3415 - val\_acc: 0.9018

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.3667 - acc: 0.8955 - val\_loss: 0.3124 - val\_acc: 0.9083

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.3344 - acc: 0.9030 - val\_loss: 0.2880 - val\_acc: 0.9146

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 145us/step
40000/40000 [==============================] - 5s 118us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.6956 - acc: 0.7807 - val\_loss: 0.2200 - val\_acc: 0.9361

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.3601 - acc: 0.8949 - val\_loss: 0.1805 - val\_acc: 0.9493

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.3033 - acc: 0.9136 - val\_loss: 0.1586 - val\_acc: 0.9551

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.2745 - acc: 0.9223 - val\_loss: 0.1463 - val\_acc: 0.9595

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.2576 - acc: 0.9292 - val\_loss: 0.1407 - val\_acc: 0.9633

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 66us/step
40000/40000 [==============================] - 3s 65us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.6921 - acc: 0.7852 - val\_loss: 0.2223 - val\_acc: 0.9344

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.3538 - acc: 0.8980 - val\_loss: 0.1754 - val\_acc: 0.9503

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.2922 - acc: 0.9177 - val\_loss: 0.1579 - val\_acc: 0.9566

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.2688 - acc: 0.9266 - val\_loss: 0.1550 - val\_acc: 0.9587

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.2494 - acc: 0.9327 - val\_loss: 0.1515 - val\_acc: 0.9609

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 66us/step
40000/40000 [==============================] - 3s 65us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.7025 - acc: 0.7778 - val\_loss: 0.2717 - val\_acc: 0.9179

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 0.3624 - acc: 0.8952 - val\_loss: 0.2114 - val\_acc: 0.9377

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.3024 - acc: 0.9152 - val\_loss: 0.1862 - val\_acc: 0.9476

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.2667 - acc: 0.9248 - val\_loss: 0.1777 - val\_acc: 0.9511

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.2473 - acc: 0.9335 - val\_loss: 0.1697 - val\_acc: 0.9544

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 66us/step
40000/40000 [==============================] - 3s 66us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.8539 - acc: 0.3629 - val\_loss: 1.0047 - val\_acc: 0.8041

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 1.1357 - acc: 0.6246 - val\_loss: 0.5745 - val\_acc: 0.8639

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.8605 - acc: 0.7228 - val\_loss: 0.4412 - val\_acc: 0.8899

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.7308 - acc: 0.7702 - val\_loss: 0.3713 - val\_acc: 0.9015

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.6448 - acc: 0.8002 - val\_loss: 0.3309 - val\_acc: 0.9095

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 80us/step
40000/40000 [==============================] - 3s 77us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.7948 - acc: 0.3949 - val\_loss: 0.9065 - val\_acc: 0.8189

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 1.0625 - acc: 0.6567 - val\_loss: 0.5295 - val\_acc: 0.8732

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.8194 - acc: 0.7373 - val\_loss: 0.4233 - val\_acc: 0.8934

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.7026 - acc: 0.7793 - val\_loss: 0.3667 - val\_acc: 0.9016

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 4s - loss: 0.6335 - acc: 0.8039 - val\_loss: 0.3283 - val\_acc: 0.9095

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 59us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.7862 - acc: 0.3959 - val\_loss: 0.9602 - val\_acc: 0.7989

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 4s - loss: 1.0633 - acc: 0.6538 - val\_loss: 0.5931 - val\_acc: 0.8552

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 4s - loss: 0.8084 - acc: 0.7447 - val\_loss: 0.4705 - val\_acc: 0.8744

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.6913 - acc: 0.7844 - val\_loss: 0.4121 - val\_acc: 0.8865

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 5s - loss: 0.6127 - acc: 0.8163 - val\_loss: 0.3767 - val\_acc: 0.8945

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 76us/step
40000/40000 [==============================] - 3s 76us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 21s - loss: 0.4061 - acc: 0.8752 - val\_loss: 0.1369 - val\_acc: 0.9585

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 13s - loss: 0.2076 - acc: 0.9397 - val\_loss: 0.1255 - val\_acc: 0.9655

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 12s - loss: 0.1691 - acc: 0.9527 - val\_loss: 0.1100 - val\_acc: 0.9700

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 13s - loss: 0.1533 - acc: 0.9579 - val\_loss: 0.1092 - val\_acc: 0.9711

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.1384 - acc: 0.9634 - val\_loss: 0.1074 - val\_acc: 0.9716

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 120us/step
40000/40000 [==============================] - 6s 158us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.3941 - acc: 0.8780 - val\_loss: 0.1498 - val\_acc: 0.9550

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 0.2025 - acc: 0.9422 - val\_loss: 0.1258 - val\_acc: 0.9639

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 11s - loss: 0.1656 - acc: 0.9518 - val\_loss: 0.1078 - val\_acc: 0.9710

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 13s - loss: 0.1502 - acc: 0.9583 - val\_loss: 0.1115 - val\_acc: 0.9721

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.1379 - acc: 0.9625 - val\_loss: 0.1066 - val\_acc: 0.9731

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 120us/step
40000/40000 [==============================] - 5s 116us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 21s - loss: 0.3977 - acc: 0.8759 - val\_loss: 0.1704 - val\_acc: 0.9505

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 12s - loss: 0.2005 - acc: 0.9403 - val\_loss: 0.1461 - val\_acc: 0.9584

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 12s - loss: 0.1649 - acc: 0.9530 - val\_loss: 0.1463 - val\_acc: 0.9621

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 12s - loss: 0.1452 - acc: 0.9598 - val\_loss: 0.1283 - val\_acc: 0.9706

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 12s - loss: 0.1285 - acc: 0.9658 - val\_loss: 0.1441 - val\_acc: 0.9659

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 116us/step
40000/40000 [==============================] - 6s 149us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 1.4412 - acc: 0.5504 - val\_loss: 0.5877 - val\_acc: 0.8634

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 0.7251 - acc: 0.7741 - val\_loss: 0.3882 - val\_acc: 0.8972

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.5639 - acc: 0.8270 - val\_loss: 0.3284 - val\_acc: 0.9097

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.4886 - acc: 0.8523 - val\_loss: 0.2921 - val\_acc: 0.9183

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.4459 - acc: 0.8667 - val\_loss: 0.2692 - val\_acc: 0.9233

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 133us/step
40000/40000 [==============================] - 6s 141us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 1.4260 - acc: 0.5484 - val\_loss: 0.5837 - val\_acc: 0.8634

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 10s - loss: 0.7074 - acc: 0.7816 - val\_loss: 0.3888 - val\_acc: 0.8938

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 10s - loss: 0.5578 - acc: 0.8309 - val\_loss: 0.3263 - val\_acc: 0.9095

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 11s - loss: 0.4812 - acc: 0.8551 - val\_loss: 0.2903 - val\_acc: 0.9171

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 11s - loss: 0.4291 - acc: 0.8727 - val\_loss: 0.2675 - val\_acc: 0.9221

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 3s 144us/step
40000/40000 [==============================] - 6s 148us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 22s - loss: 1.4442 - acc: 0.5505 - val\_loss: 0.6462 - val\_acc: 0.8470

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 11s - loss: 0.7166 - acc: 0.7778 - val\_loss: 0.4434 - val\_acc: 0.8800

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.5659 - acc: 0.8283 - val\_loss: 0.3766 - val\_acc: 0.8928

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.4889 - acc: 0.8542 - val\_loss: 0.3378 - val\_acc: 0.9018

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 10s - loss: 0.4445 - acc: 0.8680 - val\_loss: 0.3120 - val\_acc: 0.9075

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 118us/step
40000/40000 [==============================] - 5s 116us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.4038 - acc: 0.8841 - val\_loss: 0.2023 - val\_acc: 0.9420

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.1834 - acc: 0.9448 - val\_loss: 0.1449 - val\_acc: 0.9574

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.1272 - acc: 0.9614 - val\_loss: 0.1179 - val\_acc: 0.9635

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.0950 - acc: 0.9708 - val\_loss: 0.1076 - val\_acc: 0.9690

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.0752 - acc: 0.9770 - val\_loss: 0.1204 - val\_acc: 0.9656

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 51us/step
40000/40000 [==============================] - 2s 45us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 0.3973 - acc: 0.8865 - val\_loss: 0.2110 - val\_acc: 0.9380

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.1760 - acc: 0.9473 - val\_loss: 0.1383 - val\_acc: 0.9604

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.1233 - acc: 0.9630 - val\_loss: 0.1254 - val\_acc: 0.9641

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.0908 - acc: 0.9723 - val\_loss: 0.1050 - val\_acc: 0.9716

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.0702 - acc: 0.9781 - val\_loss: 0.1029 - val\_acc: 0.9710

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 38us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 0.4006 - acc: 0.8847 - val\_loss: 0.2247 - val\_acc: 0.9324

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.1786 - acc: 0.9464 - val\_loss: 0.1640 - val\_acc: 0.9507

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.1232 - acc: 0.9635 - val\_loss: 0.1343 - val\_acc: 0.9593

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.0912 - acc: 0.9718 - val\_loss: 0.1243 - val\_acc: 0.9650

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.0718 - acc: 0.9782 - val\_loss: 0.1134 - val\_acc: 0.9659

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 41us/step
40000/40000 [==============================] - 2s 42us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.6588 - acc: 0.5894 - val\_loss: 1.0085 - val\_acc: 0.8116

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.7782 - acc: 0.8234 - val\_loss: 0.5533 - val\_acc: 0.8731

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5326 - acc: 0.8657 - val\_loss: 0.4222 - val\_acc: 0.8909

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4423 - acc: 0.8817 - val\_loss: 0.3670 - val\_acc: 0.9018

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3953 - acc: 0.8920 - val\_loss: 0.3347 - val\_acc: 0.9080

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 45us/step
40000/40000 [==============================] - 2s 40us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 10s - loss: 1.7157 - acc: 0.5326 - val\_loss: 1.0764 - val\_acc: 0.7833

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 0.8126 - acc: 0.8151 - val\_loss: 0.5817 - val\_acc: 0.8679

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5474 - acc: 0.8620 - val\_loss: 0.4418 - val\_acc: 0.8898

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4516 - acc: 0.8809 - val\_loss: 0.3804 - val\_acc: 0.9006

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.4021 - acc: 0.8902 - val\_loss: 0.3459 - val\_acc: 0.9065

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 47us/step
40000/40000 [==============================] - 2s 42us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.6703 - acc: 0.5815 - val\_loss: 1.0237 - val\_acc: 0.7923

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.7473 - acc: 0.8327 - val\_loss: 0.5936 - val\_acc: 0.8512

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 0.5157 - acc: 0.8711 - val\_loss: 0.4717 - val\_acc: 0.8758

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.4320 - acc: 0.8854 - val\_loss: 0.4148 - val\_acc: 0.8858

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.3882 - acc: 0.8948 - val\_loss: 0.3846 - val\_acc: 0.8921

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 40us/step
40000/40000 [==============================] - 2s 50us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 0.3056 - acc: 0.9052 - val\_loss: 0.1261 - val\_acc: 0.9621

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.1149 - acc: 0.9644 - val\_loss: 0.0960 - val\_acc: 0.9692

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.0672 - acc: 0.9789 - val\_loss: 0.1192 - val\_acc: 0.9629

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.0459 - acc: 0.9851 - val\_loss: 0.0871 - val\_acc: 0.9745

Epoch 00004: val\_loss improved from 0.09060 to 0.08710, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 7s - loss: 0.0332 - acc: 0.9892 - val\_loss: 0.1016 - val\_acc: 0.9750

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 84us/step
40000/40000 [==============================] - 3s 82us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 0.3010 - acc: 0.9085 - val\_loss: 0.1237 - val\_acc: 0.9623

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.1104 - acc: 0.9658 - val\_loss: 0.1076 - val\_acc: 0.9679

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.0684 - acc: 0.9786 - val\_loss: 0.0959 - val\_acc: 0.9718

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.0454 - acc: 0.9852 - val\_loss: 0.0836 - val\_acc: 0.9758

Epoch 00004: val\_loss improved from 0.08710 to 0.08364, saving model to mnist.model.best.hdf5
Epoch 5/5
 - 8s - loss: 0.0338 - acc: 0.9894 - val\_loss: 0.1003 - val\_acc: 0.9744

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 80us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 0.2902 - acc: 0.9093 - val\_loss: 0.1536 - val\_acc: 0.9544

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 8s - loss: 0.1057 - acc: 0.9672 - val\_loss: 0.1294 - val\_acc: 0.9621

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.0642 - acc: 0.9799 - val\_loss: 0.1221 - val\_acc: 0.9657

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.0440 - acc: 0.9858 - val\_loss: 0.1056 - val\_acc: 0.9706

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.0306 - acc: 0.9908 - val\_loss: 0.1312 - val\_acc: 0.9689

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 85us/step
40000/40000 [==============================] - 3s 84us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 1.5404 - acc: 0.6513 - val\_loss: 0.8412 - val\_acc: 0.8444

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 6s - loss: 0.6683 - acc: 0.8512 - val\_loss: 0.4826 - val\_acc: 0.8872

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.4752 - acc: 0.8781 - val\_loss: 0.3824 - val\_acc: 0.9016

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.4036 - acc: 0.8910 - val\_loss: 0.3362 - val\_acc: 0.9114

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.3646 - acc: 0.9003 - val\_loss: 0.3116 - val\_acc: 0.9150

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 86us/step
40000/40000 [==============================] - 4s 112us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.4999 - acc: 0.6747 - val\_loss: 0.8253 - val\_acc: 0.8561

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.6573 - acc: 0.8531 - val\_loss: 0.4789 - val\_acc: 0.8898

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 6s - loss: 0.4700 - acc: 0.8816 - val\_loss: 0.3836 - val\_acc: 0.9014

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.3988 - acc: 0.8937 - val\_loss: 0.3380 - val\_acc: 0.9101

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.3599 - acc: 0.9026 - val\_loss: 0.3108 - val\_acc: 0.9147

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 91us/step
40000/40000 [==============================] - 4s 89us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 1.5080 - acc: 0.6564 - val\_loss: 0.8842 - val\_acc: 0.8186

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.6669 - acc: 0.8491 - val\_loss: 0.5411 - val\_acc: 0.8661

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.4766 - acc: 0.8790 - val\_loss: 0.4382 - val\_acc: 0.8866

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.4044 - acc: 0.8920 - val\_loss: 0.3870 - val\_acc: 0.8921

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.3644 - acc: 0.9002 - val\_loss: 0.3555 - val\_acc: 0.9028

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 121us/step
40000/40000 [==============================] - 4s 109us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 0.5011 - acc: 0.8499 - val\_loss: 0.1877 - val\_acc: 0.9446

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.2343 - acc: 0.9305 - val\_loss: 0.1376 - val\_acc: 0.9584

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.1755 - acc: 0.9476 - val\_loss: 0.1150 - val\_acc: 0.9670

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.1431 - acc: 0.9567 - val\_loss: 0.1090 - val\_acc: 0.9694

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.1201 - acc: 0.9633 - val\_loss: 0.0953 - val\_acc: 0.9726

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 59us/step
40000/40000 [==============================] - 2s 60us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 15s - loss: 0.4907 - acc: 0.8538 - val\_loss: 0.1978 - val\_acc: 0.9394

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.2275 - acc: 0.9309 - val\_loss: 0.1421 - val\_acc: 0.9584

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.1676 - acc: 0.9503 - val\_loss: 0.1238 - val\_acc: 0.9623

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 4s - loss: 0.1353 - acc: 0.9589 - val\_loss: 0.1070 - val\_acc: 0.9698

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.1120 - acc: 0.9656 - val\_loss: 0.0981 - val\_acc: 0.9720

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 58us/step
40000/40000 [==============================] - 2s 56us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 0.4992 - acc: 0.8518 - val\_loss: 0.2371 - val\_acc: 0.9307

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.2343 - acc: 0.9293 - val\_loss: 0.1692 - val\_acc: 0.9493

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.1713 - acc: 0.9483 - val\_loss: 0.1419 - val\_acc: 0.9607

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.1353 - acc: 0.9587 - val\_loss: 0.1245 - val\_acc: 0.9615

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.1179 - acc: 0.9639 - val\_loss: 0.1207 - val\_acc: 0.9646

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 52us/step
40000/40000 [==============================] - 2s 52us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 1.8302 - acc: 0.4473 - val\_loss: 1.1593 - val\_acc: 0.7710

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 1.0407 - acc: 0.6999 - val\_loss: 0.6364 - val\_acc: 0.8639

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.7452 - acc: 0.7801 - val\_loss: 0.4732 - val\_acc: 0.8879

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.6232 - acc: 0.8137 - val\_loss: 0.3991 - val\_acc: 0.8999

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.5505 - acc: 0.8359 - val\_loss: 0.3569 - val\_acc: 0.9062

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 58us/step
40000/40000 [==============================] - 3s 71us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 11s - loss: 1.8089 - acc: 0.4428 - val\_loss: 1.1529 - val\_acc: 0.7788

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 1.0468 - acc: 0.6972 - val\_loss: 0.6551 - val\_acc: 0.8541

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.7669 - acc: 0.7682 - val\_loss: 0.4970 - val\_acc: 0.8792

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.6432 - acc: 0.8057 - val\_loss: 0.4204 - val\_acc: 0.8941

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.5704 - acc: 0.8305 - val\_loss: 0.3762 - val\_acc: 0.9005

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 49us/step
40000/40000 [==============================] - 3s 69us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 1.7718 - acc: 0.4627 - val\_loss: 1.1347 - val\_acc: 0.7579

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.9909 - acc: 0.7137 - val\_loss: 0.6526 - val\_acc: 0.8471

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.7239 - acc: 0.7848 - val\_loss: 0.5087 - val\_acc: 0.8708

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 2s - loss: 0.6082 - acc: 0.8179 - val\_loss: 0.4441 - val\_acc: 0.8799

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.5405 - acc: 0.8387 - val\_loss: 0.4039 - val\_acc: 0.8848

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 53us/step
40000/40000 [==============================] - 3s 76us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 0.3354 - acc: 0.8950 - val\_loss: 0.1236 - val\_acc: 0.9629

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.1383 - acc: 0.9580 - val\_loss: 0.1169 - val\_acc: 0.9664

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.0943 - acc: 0.9698 - val\_loss: 0.1180 - val\_acc: 0.9655

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.0695 - acc: 0.9776 - val\_loss: 0.0988 - val\_acc: 0.9718

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.0568 - acc: 0.9824 - val\_loss: 0.0877 - val\_acc: 0.9761

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 105us/step
40000/40000 [==============================] - 4s 110us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.3284 - acc: 0.8983 - val\_loss: 0.1477 - val\_acc: 0.9533

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.1336 - acc: 0.9604 - val\_loss: 0.1069 - val\_acc: 0.9677

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.0890 - acc: 0.9722 - val\_loss: 0.1137 - val\_acc: 0.9663

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 8s - loss: 0.0676 - acc: 0.9794 - val\_loss: 0.0910 - val\_acc: 0.9732

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 8s - loss: 0.0502 - acc: 0.9842 - val\_loss: 0.0971 - val\_acc: 0.9754

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 113us/step
40000/40000 [==============================] - 5s 129us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.3283 - acc: 0.8981 - val\_loss: 0.1691 - val\_acc: 0.9493

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.1315 - acc: 0.9592 - val\_loss: 0.1124 - val\_acc: 0.9646

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 8s - loss: 0.0879 - acc: 0.9725 - val\_loss: 0.0987 - val\_acc: 0.9705

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.0647 - acc: 0.9793 - val\_loss: 0.1145 - val\_acc: 0.9686

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.0527 - acc: 0.9837 - val\_loss: 0.1032 - val\_acc: 0.9735

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 111us/step
40000/40000 [==============================] - 5s 121us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.6413 - acc: 0.5619 - val\_loss: 0.8993 - val\_acc: 0.8389

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.7842 - acc: 0.8018 - val\_loss: 0.5035 - val\_acc: 0.8812

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.5685 - acc: 0.8423 - val\_loss: 0.3970 - val\_acc: 0.8956

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4861 - acc: 0.8613 - val\_loss: 0.3475 - val\_acc: 0.9049

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4403 - acc: 0.8742 - val\_loss: 0.3179 - val\_acc: 0.9113

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 114us/step
40000/40000 [==============================] - 4s 107us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.6052 - acc: 0.5774 - val\_loss: 0.8660 - val\_acc: 0.8464

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.7602 - acc: 0.8053 - val\_loss: 0.4925 - val\_acc: 0.8825

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.5551 - acc: 0.8448 - val\_loss: 0.3904 - val\_acc: 0.8972

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4792 - acc: 0.8610 - val\_loss: 0.3440 - val\_acc: 0.9066

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4323 - acc: 0.8773 - val\_loss: 0.3154 - val\_acc: 0.9129

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 90us/step
40000/40000 [==============================] - 5s 117us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.6254 - acc: 0.5707 - val\_loss: 0.9418 - val\_acc: 0.8089

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 0.7741 - acc: 0.8029 - val\_loss: 0.5580 - val\_acc: 0.8636

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.5635 - acc: 0.8417 - val\_loss: 0.4496 - val\_acc: 0.8809

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.4823 - acc: 0.8642 - val\_loss: 0.3964 - val\_acc: 0.8931

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.4355 - acc: 0.8744 - val\_loss: 0.3661 - val\_acc: 0.8968

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 111us/step
40000/40000 [==============================] - 5s 115us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 13s - loss: 0.8054 - acc: 0.7421 - val\_loss: 0.2484 - val\_acc: 0.9271

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3939 - acc: 0.8851 - val\_loss: 0.1880 - val\_acc: 0.9450

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3148 - acc: 0.9103 - val\_loss: 0.1588 - val\_acc: 0.9544

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.2772 - acc: 0.9215 - val\_loss: 0.1499 - val\_acc: 0.9563

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.2513 - acc: 0.9277 - val\_loss: 0.1360 - val\_acc: 0.9611

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 57us/step
40000/40000 [==============================] - 2s 45us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.7964 - acc: 0.7456 - val\_loss: 0.2495 - val\_acc: 0.9249

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3923 - acc: 0.8842 - val\_loss: 0.1929 - val\_acc: 0.9440

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3122 - acc: 0.9095 - val\_loss: 0.1636 - val\_acc: 0.9544

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.2769 - acc: 0.9208 - val\_loss: 0.1491 - val\_acc: 0.9600

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.2525 - acc: 0.9283 - val\_loss: 0.1404 - val\_acc: 0.9619

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 56us/step
40000/40000 [==============================] - 3s 71us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 0.7856 - acc: 0.7514 - val\_loss: 0.2842 - val\_acc: 0.9171

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 0.3851 - acc: 0.8880 - val\_loss: 0.2206 - val\_acc: 0.9351

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 0.3105 - acc: 0.9127 - val\_loss: 0.1873 - val\_acc: 0.9465

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.2706 - acc: 0.9217 - val\_loss: 0.1798 - val\_acc: 0.9477

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.2460 - acc: 0.9313 - val\_loss: 0.1617 - val\_acc: 0.9571

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 57us/step
40000/40000 [==============================] - 2s 55us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.0765 - acc: 0.2694 - val\_loss: 1.5479 - val\_acc: 0.7027

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 1.5146 - acc: 0.5084 - val\_loss: 0.9349 - val\_acc: 0.8237

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 1.1616 - acc: 0.6198 - val\_loss: 0.6671 - val\_acc: 0.8562

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 0.9793 - acc: 0.6820 - val\_loss: 0.5408 - val\_acc: 0.8760

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.8621 - acc: 0.7234 - val\_loss: 0.4698 - val\_acc: 0.8864

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 65us/step
40000/40000 [==============================] - 3s 63us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.1211 - acc: 0.2445 - val\_loss: 1.6726 - val\_acc: 0.7097

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 2s - loss: 1.6001 - acc: 0.4898 - val\_loss: 1.0206 - val\_acc: 0.8033

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 2s - loss: 1.2212 - acc: 0.6075 - val\_loss: 0.7091 - val\_acc: 0.8479

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.0142 - acc: 0.6760 - val\_loss: 0.5652 - val\_acc: 0.8712

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 3s - loss: 0.8859 - acc: 0.7177 - val\_loss: 0.4815 - val\_acc: 0.8814

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 53us/step
40000/40000 [==============================] - 2s 53us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 12s - loss: 2.1455 - acc: 0.2350 - val\_loss: 1.7538 - val\_acc: 0.6586

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 3s - loss: 1.6400 - acc: 0.4640 - val\_loss: 1.0983 - val\_acc: 0.7771

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 3s - loss: 1.2520 - acc: 0.5917 - val\_loss: 0.7830 - val\_acc: 0.8224

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 3s - loss: 1.0373 - acc: 0.6643 - val\_loss: 0.6324 - val\_acc: 0.8455

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 2s - loss: 0.9071 - acc: 0.7082 - val\_loss: 0.5449 - val\_acc: 0.8614

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 1s 49us/step
40000/40000 [==============================] - 3s 72us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.4353 - acc: 0.8616 - val\_loss: 0.1546 - val\_acc: 0.9543

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.2093 - acc: 0.9374 - val\_loss: 0.1173 - val\_acc: 0.9641

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.1631 - acc: 0.9515 - val\_loss: 0.1009 - val\_acc: 0.9708

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.1379 - acc: 0.9590 - val\_loss: 0.1049 - val\_acc: 0.9715

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.1186 - acc: 0.9650 - val\_loss: 0.1001 - val\_acc: 0.9722

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 96us/step
40000/40000 [==============================] - 5s 114us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 18s - loss: 0.4319 - acc: 0.8668 - val\_loss: 0.1659 - val\_acc: 0.9515

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.2034 - acc: 0.9383 - val\_loss: 0.1180 - val\_acc: 0.9657

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.1565 - acc: 0.9523 - val\_loss: 0.1065 - val\_acc: 0.9696

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.1307 - acc: 0.9614 - val\_loss: 0.1022 - val\_acc: 0.9725

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.1154 - acc: 0.9663 - val\_loss: 0.1019 - val\_acc: 0.9716

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 117us/step
40000/40000 [==============================] - 5s 116us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 19s - loss: 0.4368 - acc: 0.8648 - val\_loss: 0.2007 - val\_acc: 0.9341

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 9s - loss: 0.2039 - acc: 0.9392 - val\_loss: 0.1381 - val\_acc: 0.9596

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 9s - loss: 0.1577 - acc: 0.9520 - val\_loss: 0.1185 - val\_acc: 0.9659

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 9s - loss: 0.1301 - acc: 0.9608 - val\_loss: 0.1113 - val\_acc: 0.9719

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 9s - loss: 0.1133 - acc: 0.9666 - val\_loss: 0.1224 - val\_acc: 0.9700

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 113us/step
40000/40000 [==============================] - 4s 105us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 17s - loss: 1.8236 - acc: 0.4044 - val\_loss: 1.0531 - val\_acc: 0.8167

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 1.0526 - acc: 0.6837 - val\_loss: 0.5871 - val\_acc: 0.8675

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.7832 - acc: 0.7560 - val\_loss: 0.4506 - val\_acc: 0.8844

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.6569 - acc: 0.7971 - val\_loss: 0.3884 - val\_acc: 0.8946

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 6s - loss: 0.5867 - acc: 0.8192 - val\_loss: 0.3499 - val\_acc: 0.9030

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 125us/step
40000/40000 [==============================] - 4s 111us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.8315 - acc: 0.4088 - val\_loss: 1.0546 - val\_acc: 0.8069

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 1.0426 - acc: 0.6909 - val\_loss: 0.5828 - val\_acc: 0.8660

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.7728 - acc: 0.7621 - val\_loss: 0.4498 - val\_acc: 0.8839

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 7s - loss: 0.6514 - acc: 0.7985 - val\_loss: 0.3866 - val\_acc: 0.8949

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.5790 - acc: 0.8223 - val\_loss: 0.3486 - val\_acc: 0.9014

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 83us/step
40000/40000 [==============================] - 4s 96us/step
Train on 32000 samples, validate on 8000 samples
Epoch 1/5
 - 16s - loss: 1.8174 - acc: 0.4179 - val\_loss: 1.0885 - val\_acc: 0.8021

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 7s - loss: 1.0450 - acc: 0.6852 - val\_loss: 0.6317 - val\_acc: 0.8531

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 7s - loss: 0.7700 - acc: 0.7645 - val\_loss: 0.4955 - val\_acc: 0.8729

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 6s - loss: 0.6559 - acc: 0.7991 - val\_loss: 0.4296 - val\_acc: 0.8840

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 7s - loss: 0.5715 - acc: 0.8284 - val\_loss: 0.3921 - val\_acc: 0.8891

Epoch 00005: val\_loss did not improve
20000/20000 [==============================] - 2s 81us/step
40000/40000 [==============================] - 3s 85us/step
Train on 48000 samples, validate on 12000 samples
Epoch 1/5
 - 27s - loss: 0.2190 - acc: 0.9328 - val\_loss: 0.1174 - val\_acc: 0.9660

Epoch 00001: val\_loss did not improve
Epoch 2/5
 - 18s - loss: 0.0896 - acc: 0.9729 - val\_loss: 0.1258 - val\_acc: 0.9672

Epoch 00002: val\_loss did not improve
Epoch 3/5
 - 16s - loss: 0.0623 - acc: 0.9821 - val\_loss: 0.1026 - val\_acc: 0.9718

Epoch 00003: val\_loss did not improve
Epoch 4/5
 - 16s - loss: 0.0473 - acc: 0.9857 - val\_loss: 0.1122 - val\_acc: 0.9738

Epoch 00004: val\_loss did not improve
Epoch 5/5
 - 16s - loss: 0.0379 - acc: 0.9891 - val\_loss: 0.1153 - val\_acc: 0.9768

Epoch 00005: val\_loss did not improve
CPU times: user 4h 19min 14s, sys: 25min 3s, total: 4h 44min 18s
Wall time: 4h 35min 39s

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} summarize results}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best: }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ using }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{grid\PYZus{}result}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{,} \PY{n}{grid\PYZus{}result}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best: 0.973500 using \{'activation': 'relu', 'batch\_size': 64, 'dropout': 0.0, 'epochs': 5, 'neurons': 512, 'optimizer': 'rmsprop', 'validation\_split': 0.2\}

    \end{Verbatim}

    \subsubsection{10. Load the Model with the Best Classification Accuracy
on the Validation
Set}\label{load-the-model-with-the-best-classification-accuracy-on-the-validation-set}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{k+kn}{import} \PY{n+nn}{h5py}
         \PY{n}{file\PYZus{}name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mnist.model.best.hdf5}\PY{l+s+s1}{\PYZsq{}}
         \PY{n}{f} \PY{o}{=} \PY{n}{h5py}\PY{o}{.}\PY{n}{File}\PY{p}{(}\PY{n}{file\PYZus{}name}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{f}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{key}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{} List all groups}
         \PY{n}{group} \PY{o}{=} \PY{n}{f}\PY{p}{[}\PY{n}{key}\PY{p}{]}
         \PY{c+c1}{\PYZsh{}Checkout what keys are inside that group.}
         \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{group}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{key}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Get the data}
         \PY{n}{data} \PY{o}{=} \PY{n}{group}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training\PYZus{}212}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{c+c1}{\PYZsh{}Do whatever you want with data}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
model\_weights
optimizer\_weights
training\_212

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{c+c1}{\PYZsh{} load the weights that yielded the best validation accuracy}
         \PY{n}{c\PYZus{}m} \PY{o}{=} \PY{n}{create\PYZus{}model}\PY{p}{(}\PY{n}{activation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{dropout} \PY{o}{=} \PY{l+m+mf}{0.0}\PY{p}{,} 
                          \PY{n}{neurons} \PY{o}{=} \PY{l+m+mi}{512}\PY{p}{,} \PY{n}{optimizer} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{c\PYZus{}m}\PY{o}{.}\PY{n}{load\PYZus{}weights}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mnist.model.best.hdf5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{11. Calculate the Classification Accuracy on the Test
Set}\label{calculate-the-classification-accuracy-on-the-test-set}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{c+c1}{\PYZsh{} evaluate test accuracy}
         \PY{n}{score} \PY{o}{=} \PY{n}{c\PYZus{}m}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{accuracy} \PY{o}{=} \PY{l+m+mi}{100}\PY{o}{*}\PY{n}{score}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} print test accuracy}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy: }\PY{l+s+si}{\PYZpc{}.4f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{accuracy}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Test accuracy: 97.7000\%

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
